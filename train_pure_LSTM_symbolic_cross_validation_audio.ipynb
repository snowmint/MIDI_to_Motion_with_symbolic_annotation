{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"./data_list_symbolic_cross_audio.txt\"\n",
    "dataloader = get_dataloader(dataset_name_path, batch_size=8) #[20, 512, 128], [20, 512, 102]\n",
    "dataset = AudioMotionDataSet(dataset_name_path)\n",
    "\n",
    "val_dataset_name_path = f\"./data_list_symbolic_cross_audio.txt\"\n",
    "# val_dataloader = get_val_dataloader(val_dataset_name_path, batch_size=40) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "full_data_path = None\n",
    "with open(\"./data_list_symbolic_cross_audio.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file]\n",
    "    full_data_path = np.array(lines)\n",
    "\n",
    "val_data_read = np.reshape(full_data_path, (11, 10))\n",
    "# print(val_data_read)\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "# input_size_encoder = 128 #129 #128\n",
    "# input_size_decoder = 115 #102 #24\n",
    "# output_size = 115#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2912b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model): # reset the weight every fold\n",
    "    if isinstance(model, nn.LSTM) or isinstance(model, nn.Linear):\n",
    "        model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 156 #number of features\n",
    "hidden_size = 1024 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 115 #number of output classes\n",
    "batch_size_define = 20#128\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "# model.train()\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 300#100 #10\n",
    "k_folds = 11\n",
    "cross_valid_results = {}\n",
    "torch.manual_seed(42)\n",
    "\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []\n",
    "\n",
    "#TODO: important cross val record\n",
    "val_time_loss_list = []\n",
    "val_dim_loss_list = []\n",
    "val_mse_loss_list = []\n",
    "val_per_split_list = [] #just mse loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56bd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate time-wise loss for motion (along the time axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: time loss\n",
    "    '''\n",
    "    # points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "    # points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "    # [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "    # [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "    # [30, 31], [32, 33],  #instrument\n",
    "    \n",
    "    # print(\"preds.shape\", preds.shape)\n",
    "    # print(\"labels.shape\", labels.shape)\n",
    "    \n",
    "    # print(\"preds[9*3:18*3]\", preds[:, :, 9*3:19*3].shape)\n",
    "    # print(\"labels[9*3:18*3]\", labels[:, :, 9*3:19*3].shape)\n",
    "    \n",
    "    select_joint_preds = torch.cat((preds[:, :, 9*3:19*3], preds[:, :, 31*3:35*3]), 2)\n",
    "    select_joint_labels = torch.cat((labels[:, :, 9*3:19*3], labels[:, :, 31*3:35*3]), 2)\n",
    "    \n",
    "    # print(\"select_joint_preds.shape\", select_joint_preds.shape)\n",
    "    # # print(select_joint_preds)\n",
    "    # print(\"select_joint_labels.shape\", select_joint_labels.shape)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    select_joint_preds = select_joint_preds + epsilon\n",
    "\n",
    "    labels_transpose = torch.permute(select_joint_labels, (0, 2, 1))#tf.transpose(labels, [0, 2, 1]) # [b, 3, t]\n",
    "    preds_transpose = torch.permute(select_joint_preds, (0, 2, 1))#tf.transpose(preds, [0, 2, 1]) # [b, 3, t]\n",
    "    # print(\"labels_transpose.shape\", labels_transpose.shape)\n",
    "    # print(\"preds_transpose.shape\", preds_transpose.shape)\n",
    "    # print(\"labels_transpose[:, :, :, None].shape\", labels_transpose[:, :, :, None].shape)\n",
    "    # print(\"labels_transpose[:, :, None, :].shape\", labels_transpose[:, :, None, :].shape)\n",
    "    label_diff = labels_transpose[:, :, :, None] - labels_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    \n",
    "    preds_diff = preds_transpose[:, :, :, None] - preds_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    # print(preds_diff.shape)\n",
    "    time_loss = (preds_diff - label_diff)**2 # [b, 3, t, t]\n",
    "    time_loss_value = time_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return time_loss_value\n",
    "    \n",
    "def dim_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate dimension-wise loss for motion (along the dimension axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: dimension loss\n",
    "    '''\n",
    "    select_joint_preds = torch.cat((preds[:, :, 9*3:19*3], preds[:, :, 31*3:35*3]), 2)\n",
    "    select_joint_labels = torch.cat((labels[:, :, 9*3:19*3], labels[:, :, 31*3:35*3]), 2)\n",
    "\n",
    "    epsilon = 1e-7\n",
    "    preds = preds + epsilon\n",
    "    \n",
    "    label_diff = select_joint_labels[:, :, :, None] - select_joint_labels[:, :, None, :] # [b, t, 3, 3]\n",
    "    preds_diff = select_joint_preds[:, :, :, None] - select_joint_preds[:, :, None, :] # [b, t, 3, 3]\n",
    "    dim_loss = (preds_diff - label_diff)**2 # [b, t, 3, 3]\n",
    "    dim_loss_value = dim_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return dim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df5bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def time_wise_loss_fn(preds, labels):\n",
    "#     '''\n",
    "#     calculate time-wise loss for motion (along the time axis)\n",
    "#     input: labels[batch, time, dimension(joint*xyz)]\n",
    "#     preds[batch, time , dimension(joint*xyz)]\n",
    "#     output: time loss\n",
    "#     '''\n",
    "#     epsilon = 1e-7\n",
    "#     preds = preds + epsilon\n",
    "\n",
    "#     labels_transpose = torch.permute(labels, (0, 2, 1))#tf.transpose(labels, [0, 2, 1]) # [b, 3, t]\n",
    "#     preds_transpose = torch.permute(preds, (0, 2, 1))#tf.transpose(preds, [0, 2, 1]) # [b, 3, t]\n",
    "#     # print(\"labels_transpose.shape\", labels_transpose.shape)\n",
    "#     # print(\"preds_transpose.shape\", preds_transpose.shape)\n",
    "#     # print(\"labels_transpose[:, :, :, None].shape\", labels_transpose[:, :, :, None].shape)\n",
    "#     # print(\"labels_transpose[:, :, None, :].shape\", labels_transpose[:, :, None, :].shape)\n",
    "#     label_diff = labels_transpose[:, :, :, None] - labels_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    \n",
    "#     preds_diff = preds_transpose[:, :, :, None] - preds_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "#     # print(preds_diff.shape)\n",
    "#     time_loss = (preds_diff - label_diff)**2 # [b, 3, t, t]\n",
    "#     time_loss_value = time_loss.mean() #float()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     return time_loss_value\n",
    "    \n",
    "# def dim_wise_loss_fn(preds, labels):\n",
    "#     '''\n",
    "#     calculate dimension-wise loss for motion (along the dimension axis)\n",
    "#     input: labels[batch, time, dimension(joint*xyz)]\n",
    "#     preds[batch, time , dimension(joint*xyz)]\n",
    "#     output: dimension loss\n",
    "#     '''\n",
    "#     epsilon = 1e-7\n",
    "#     preds = preds + epsilon\n",
    "    \n",
    "#     label_diff = labels[:, :, :, None] - labels[:, :, None, :] # [b, t, 3, 3]\n",
    "#     preds_diff = preds[:, :, :, None] - preds[:, :, None, :] # [b, t, 3, 3]\n",
    "#     dim_loss = (preds_diff - label_diff)**2 # [b, t, 3, 3]\n",
    "#     dim_loss_value = dim_loss.mean() #float()\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "#     return dim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target):\n",
    "    # target = target.transpose(0, 1)\n",
    "\n",
    "    # print(\"output.shape:\", output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(\"target.shape:\", target.shape) #torch.Size([20, 513, 102])\n",
    "\n",
    "    w1_time = 0.3\n",
    "    w2_dim = 0.3\n",
    "    w3_mse = 0.4\n",
    "\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    time_loss = time_wise_loss_fn(output, target)\n",
    "    dim_loss = dim_wise_loss_fn(output, target)\n",
    "\n",
    "    # print(\"time_loss:\", time_loss)\n",
    "    # print(\"dim_loss:\", dim_loss)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "    val_time_loss_list.append(time_loss.cpu().item())\n",
    "    val_dim_loss_list.append(dim_loss.cpu().item())\n",
    "    val_mse_loss_list.append(mse_loss.cpu().item())\n",
    "\n",
    "    segment_loss = (w1_time * time_loss) + (w2_dim * dim_loss) + (w3_mse * mse_loss)\n",
    "    torch.cuda.empty_cache()\n",
    "    return  segment_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_cross(model, split_count):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    \n",
    "    outputs_save = []\n",
    "    \n",
    "    np.savetxt('./temp_path.txt', val_data_read[split_count], delimiter=\"\\n\", fmt=\"%s\")\n",
    "    # print(val_data_read[split_count])\n",
    "    val_dataloader = get_audio_val_dataloader('./temp_path.txt', batch_size=11)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            # print(\"val inputs.shape:\", inputs.shape)\n",
    "            # print(\"val targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "            outputs_save.append(np.asarray(outputs.cpu()))\n",
    "\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if not os.path.exists(\"./output_eval/\"):\n",
    "        os.makedirs('./output_eval/')\n",
    "\n",
    "    # print(\"counter\", counter)\n",
    "    # print(\"val_data_read[split_count][counter]\", val_data_read[split_count][counter])\n",
    "    val_file_name = val_data_read[split_count][counter].split('/')[2].split('.')[0]\n",
    "\n",
    "    # print(\"val file_name:\", val_file_name)\n",
    "    # print(\"outputs_save length: \", len(outputs_save), \", element shape: \" , outputs_save[0].shape)\n",
    "    #                                            str(split_count)\n",
    "    eval_output = open(\"./output_eval/[split_\" + str(6) + \"][audio_with_anno][total\" + str(num_epochs) + \"_hs\" + str(hidden_size) +\"]save_\"+ str(loc_dt_format) + \"_l1_loss_\" + str(loss.cpu().item())+\".pkl\", 'wb')\n",
    "    pickle.dump(np.asarray(outputs_save), eval_output)\n",
    "    eval_output.close()\n",
    "    \n",
    "    # print(\"val counter:\", counter)\n",
    "    epoch_val_loss_f1 = valid_running_loss / counter\n",
    "    val_per_split_list.append(epoch_val_loss_f1)\n",
    "    print(\"split_count:\", split_count, \", epoch_val_loss:\", epoch_val_loss_f1)\n",
    "    os.remove(\"./temp_path.txt\")\n",
    "    return #epoch_val_loss_f1\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14342657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "random:  6\n",
      "------------fold no---------6----------------------\n",
      "train_idx: 0 ~ 10999  test_idx: 6000 ~ 6999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Starting epoch 17\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Starting epoch 26\n",
      "Starting epoch 27\n",
      "Starting epoch 28\n",
      "Starting epoch 29\n",
      "Starting epoch 30\n",
      "Starting epoch 31\n",
      "Starting epoch 32\n",
      "Starting epoch 33\n",
      "Starting epoch 34\n",
      "Starting epoch 35\n",
      "Starting epoch 36\n",
      "Starting epoch 37\n",
      "Starting epoch 38\n",
      "Starting epoch 39\n",
      "Starting epoch 40\n",
      "Starting epoch 41\n",
      "Starting epoch 42\n",
      "Starting epoch 43\n",
      "Starting epoch 44\n",
      "Starting epoch 45\n",
      "Starting epoch 46\n",
      "Starting epoch 47\n",
      "Starting epoch 48\n",
      "Starting epoch 49\n",
      "Starting epoch 50\n",
      "Starting epoch 51\n",
      "Starting epoch 52\n",
      "Starting epoch 53\n",
      "Starting epoch 54\n",
      "Starting epoch 55\n",
      "Starting epoch 56\n",
      "Starting epoch 57\n",
      "Starting epoch 58\n",
      "Starting epoch 59\n",
      "Starting epoch 60\n",
      "Starting epoch 61\n",
      "Starting epoch 62\n",
      "Starting epoch 63\n",
      "Starting epoch 64\n",
      "Starting epoch 65\n",
      "Starting epoch 66\n",
      "Starting epoch 67\n",
      "Starting epoch 68\n",
      "Starting epoch 69\n",
      "Starting epoch 70\n",
      "Starting epoch 71\n",
      "Starting epoch 72\n",
      "Starting epoch 73\n",
      "Starting epoch 74\n",
      "Starting epoch 75\n",
      "Starting epoch 76\n",
      "Starting epoch 77\n",
      "Starting epoch 78\n",
      "Starting epoch 79\n",
      "Starting epoch 80\n",
      "Starting epoch 81\n",
      "Starting epoch 82\n",
      "Starting epoch 83\n",
      "Starting epoch 84\n",
      "Starting epoch 85\n",
      "Starting epoch 86\n",
      "Starting epoch 87\n",
      "Starting epoch 88\n",
      "Starting epoch 89\n",
      "Starting epoch 90\n",
      "Starting epoch 91\n",
      "Starting epoch 92\n",
      "Starting epoch 93\n",
      "Starting epoch 94\n",
      "Starting epoch 95\n",
      "Starting epoch 96\n",
      "Starting epoch 97\n",
      "Starting epoch 98\n",
      "Starting epoch 99\n",
      "Starting epoch 100\n",
      "Starting epoch 101\n",
      "Starting epoch 102\n",
      "Starting epoch 103\n",
      "Starting epoch 104\n",
      "Starting epoch 105\n",
      "Starting epoch 106\n",
      "Starting epoch 107\n",
      "Starting epoch 108\n",
      "Starting epoch 109\n",
      "Starting epoch 110\n",
      "Starting epoch 111\n",
      "Starting epoch 112\n",
      "Starting epoch 113\n",
      "Starting epoch 114\n",
      "Starting epoch 115\n",
      "Starting epoch 116\n",
      "Starting epoch 117\n",
      "Starting epoch 118\n",
      "Starting epoch 119\n",
      "Starting epoch 120\n",
      "Starting epoch 121\n",
      "Starting epoch 122\n",
      "Starting epoch 123\n",
      "Starting epoch 124\n",
      "Starting epoch 125\n",
      "Starting epoch 126\n",
      "Starting epoch 127\n",
      "Starting epoch 128\n",
      "Starting epoch 129\n",
      "Starting epoch 130\n",
      "Starting epoch 131\n",
      "Starting epoch 132\n",
      "Starting epoch 133\n",
      "Starting epoch 134\n",
      "Starting epoch 135\n",
      "Starting epoch 136\n",
      "Starting epoch 137\n",
      "Starting epoch 138\n",
      "Starting epoch 139\n",
      "Starting epoch 140\n",
      "Starting epoch 141\n",
      "Starting epoch 142\n",
      "Starting epoch 143\n",
      "Starting epoch 144\n",
      "Starting epoch 145\n",
      "Starting epoch 146\n",
      "Starting epoch 147\n",
      "Starting epoch 148\n",
      "Starting epoch 149\n",
      "Starting epoch 150\n",
      "Starting epoch 151\n",
      "Starting epoch 152\n",
      "Starting epoch 153\n",
      "Starting epoch 154\n",
      "Starting epoch 155\n",
      "Starting epoch 156\n",
      "Starting epoch 157\n",
      "Starting epoch 158\n",
      "Starting epoch 159\n",
      "Starting epoch 160\n",
      "Starting epoch 161\n",
      "Starting epoch 162\n",
      "Starting epoch 163\n",
      "Starting epoch 164\n",
      "Starting epoch 165\n",
      "Starting epoch 166\n",
      "Starting epoch 167\n",
      "Starting epoch 168\n",
      "Starting epoch 169\n",
      "Starting epoch 170\n",
      "Starting epoch 171\n",
      "Starting epoch 172\n",
      "Starting epoch 173\n",
      "Starting epoch 174\n",
      "Starting epoch 175\n",
      "Starting epoch 176\n",
      "Starting epoch 177\n",
      "Starting epoch 178\n",
      "Starting epoch 179\n",
      "Starting epoch 180\n",
      "Starting epoch 181\n",
      "Starting epoch 182\n",
      "Starting epoch 183\n",
      "Starting epoch 184\n",
      "Starting epoch 185\n",
      "Starting epoch 186\n",
      "Starting epoch 187\n",
      "Starting epoch 188\n",
      "Starting epoch 189\n",
      "Starting epoch 190\n",
      "Starting epoch 191\n",
      "Starting epoch 192\n",
      "Starting epoch 193\n",
      "Starting epoch 194\n",
      "Starting epoch 195\n",
      "Starting epoch 196\n",
      "Starting epoch 197\n",
      "Starting epoch 198\n",
      "Starting epoch 199\n",
      "Starting epoch 200\n",
      "Starting epoch 201\n",
      "Starting epoch 202\n",
      "Starting epoch 203\n",
      "Starting epoch 204\n",
      "Starting epoch 205\n",
      "Starting epoch 206\n",
      "Starting epoch 207\n",
      "Starting epoch 208\n",
      "Starting epoch 209\n",
      "Starting epoch 210\n",
      "Starting epoch 211\n",
      "Starting epoch 212\n",
      "Starting epoch 213\n",
      "Starting epoch 214\n",
      "Starting epoch 215\n",
      "Starting epoch 216\n",
      "Starting epoch 217\n",
      "Starting epoch 218\n",
      "Starting epoch 219\n",
      "Starting epoch 220\n",
      "Starting epoch 221\n",
      "Starting epoch 222\n",
      "Starting epoch 223\n",
      "Starting epoch 224\n",
      "Starting epoch 225\n",
      "Starting epoch 226\n",
      "Starting epoch 227\n",
      "Starting epoch 228\n",
      "Starting epoch 229\n",
      "Starting epoch 230\n",
      "Starting epoch 231\n",
      "Starting epoch 232\n",
      "Starting epoch 233\n",
      "Starting epoch 234\n",
      "Starting epoch 235\n",
      "Starting epoch 236\n",
      "Starting epoch 237\n",
      "Starting epoch 238\n",
      "Starting epoch 239\n",
      "Starting epoch 240\n",
      "Starting epoch 241\n",
      "Starting epoch 242\n",
      "Starting epoch 243\n",
      "Starting epoch 244\n",
      "Starting epoch 245\n",
      "Starting epoch 246\n",
      "Starting epoch 247\n",
      "Starting epoch 248\n",
      "Starting epoch 249\n",
      "Starting epoch 250\n",
      "Starting epoch 251\n",
      "Starting epoch 252\n",
      "Starting epoch 253\n",
      "Starting epoch 254\n",
      "Starting epoch 255\n",
      "Starting epoch 256\n",
      "Starting epoch 257\n",
      "Starting epoch 258\n",
      "Starting epoch 259\n",
      "Starting epoch 260\n",
      "Starting epoch 261\n",
      "Starting epoch 262\n",
      "Starting epoch 263\n",
      "Starting epoch 264\n",
      "Starting epoch 265\n",
      "Starting epoch 266\n",
      "Starting epoch 267\n",
      "Starting epoch 268\n",
      "Starting epoch 269\n",
      "Starting epoch 270\n",
      "Starting epoch 271\n",
      "Starting epoch 272\n",
      "Starting epoch 273\n",
      "Starting epoch 274\n",
      "Starting epoch 275\n",
      "Starting epoch 276\n",
      "Starting epoch 277\n",
      "Starting epoch 278\n",
      "Starting epoch 279\n",
      "Starting epoch 280\n",
      "Starting epoch 281\n",
      "Starting epoch 282\n",
      "Starting epoch 283\n",
      "Starting epoch 284\n",
      "Starting epoch 285\n",
      "Starting epoch 286\n",
      "Starting epoch 287\n",
      "Starting epoch 288\n",
      "Starting epoch 289\n",
      "Starting epoch 290\n",
      "Starting epoch 291\n",
      "Starting epoch 292\n",
      "Starting epoch 293\n",
      "Starting epoch 294\n",
      "Starting epoch 295\n",
      "Starting epoch 296\n",
      "Starting epoch 297\n",
      "Starting epoch 298\n",
      "Starting epoch 299\n",
      "Starting epoch 300\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 1 FOLDS\n",
      "--------------------------------\n",
      "Fold loss 0: 0.013392268307507038\n",
      "Average vaildation new loss: 0.013392268307507038\n",
      "Validation\n",
      "val_dataset_len 10\n",
      "len(audio_data) 7380\n",
      "len(motion_data) 7380\n",
      "len(audio_data) 6255\n",
      "len(motion_data) 6255\n",
      "len(audio_data) 7145\n",
      "len(motion_data) 7145\n",
      "len(audio_data) 3548\n",
      "len(motion_data) 3548\n",
      "len(audio_data) 3850\n",
      "len(motion_data) 3850\n",
      "len(audio_data) 8925\n",
      "len(motion_data) 8925\n",
      "len(audio_data) 6153\n",
      "len(motion_data) 6153\n",
      "len(audio_data) 7428\n",
      "len(motion_data) 7428\n",
      "len(audio_data) 6599\n",
      "len(motion_data) 6599\n",
      "len(audio_data) 8276\n",
      "len(motion_data) 8276\n",
      "split_count: 0 , epoch_val_loss: 0.09642244875431061\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=k_folds)\n",
    "print(kf.get_n_splits(dataset))\n",
    "KFold(n_splits=k_folds, random_state=None, shuffle=False)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     #...TODO\n",
    "split_count = 0\n",
    "random_pick_fold = 6#random.randint(0, 10) #0~10\n",
    "print(\"random: \", random_pick_fold)\n",
    "# for fold,(train_idx, test_idx) in enumerate(kf.split(dataset)): #TODO: random pick 1 fold\n",
    "for (train_idx, test_idx) in itertools.islice(kf.split(dataset), random_pick_fold, random_pick_fold+1):\n",
    "    # print('------------fold no---------{}----------------------'.format(fold))\n",
    "    print('------------fold no---------{}----------------------'.format(random_pick_fold))\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    print(\"train_idx:\", train_idx[0], \"~\", train_idx[-1], \" test_idx:\", test_idx[0], \"~\", test_idx[-1])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=batch_size_define, sampler=train_subsampler) #bs=40:4.49G, bs=128:14.65G\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=batch_size_define, sampler=val_subsampler)\n",
    "    \n",
    "    model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        losses = []\n",
    "        loss = 0\n",
    "        mean_loss = 0\n",
    "        for i, (audio_batch, motion_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            \n",
    "            audio_batch = audio_batch.to(device).float()\n",
    "            motion_batch = motion_batch.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(audio_batch) #midi_batch\n",
    "            # print(\"train inputs.shape:\", midi_batch.shape, torch.isnan(midi_batch).any())\n",
    "            # # print(motion_batch)\n",
    "            # print(\"train targets.shape:\", motion_batch.shape, torch.isnan(motion_batch).any())\n",
    "            # print(\"train outputs.shape:\", output.shape, torch.isnan(output).any())\n",
    "\n",
    "            # loss =  F.mse_loss(output, motion_batch)\n",
    "            # loss = customized_mse_loss(output.cpu(), motion_batch.cpu())\n",
    "            loss = customized_mse_loss(output, motion_batch)\n",
    "            \n",
    "            losses.append(loss.cpu().item()) #.cpu().item()\n",
    "            all_loss_list.append(loss.cpu().item()) #.cpu().item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\") #.cpu().item()\n",
    "\n",
    "        # print(losses, sum(losses), len(losses))\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "        # correct, total = 0, 0\n",
    "        valid_running_loss = 0.0\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (audio_test, motion_test) in enumerate(val_loader):\n",
    "                \n",
    "                inputs = audio_test.to(device).float()\n",
    "                targets = motion_test.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                # print(\"val inputs.shape:\", inputs.shape)\n",
    "                # print(\"val targets.shape:\", targets.shape)\n",
    "                # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "                val_loss =  customized_mse_loss(outputs, targets)\n",
    "                valid_running_loss += val_loss.cpu().item() #.cpu().item()\n",
    "                counter += 1\n",
    "            \n",
    "            epoch_val_loss = valid_running_loss / counter\n",
    "            # print(f\"Epoch {epoch}: val_loss = {epoch_val_loss:.6f}\") #.cpu().item()\n",
    "\n",
    "        avg_loss_list.append(mean_loss) #.cpu().item()\n",
    "        val_loss_per_epoch_list.append(epoch_val_loss) #.cpu().item()\n",
    "\n",
    "        cross_valid_results[0] = epoch_val_loss\n",
    "        \n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        if (epoch+1)%100 == 0:\n",
    "            torch.save({\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':model.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'loss':loss\n",
    "            },  \"./model_save/[audio_with_anno][total\"+str(num_epochs)+ \"_hs\" + str(hidden_size) +\"]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {1} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum_loss = 0.0\n",
    "    for key, value in cross_valid_results.items():\n",
    "        print(f'Fold loss {key}: {value}')\n",
    "        sum_loss += value\n",
    "    print(f'Average vaildation new loss: {sum_loss/len(cross_valid_results.items())}')\n",
    "    \n",
    "    # validation result save\n",
    "    evaluate_lstm_cross(model, split_count)\n",
    "    \n",
    "    split_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f00152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessed_data_save_cross_aud/audio/vio01_Elgar_S1_T1_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Elgar_S1_T2_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Flower_S1_T1_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Flower_S1_T2_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mend_S1_T1_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mend_S1_T2_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mozart1_S1_T1_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mozart1_S1_T2_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mozart2_S1_T1_audio_data.pkl'\n",
      " 'preprocessed_data_save_cross_aud/audio/vio01_Mozart2_S1_T2_audio_data.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(val_data_read[split_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-26_23-36-38\n",
      "[0.028981424916535617, 0.027057366870343685, 0.02556221378222108, 0.02498922310397029, 0.024635498132556676, 0.02398297697491944, 0.023813755325973032, 0.02298606104031205, 0.02278897361084819, 0.022227262929081917, 0.021841420762240885, 0.021382782191038133, 0.02082525562681258, 0.02058083031140268, 0.020017879704013468, 0.019781573424115777, 0.019780084704980255, 0.018959773004055023, 0.01901441624760628, 0.018977713232859968, 0.01898939139023423, 0.018410815499722958, 0.018191521733999252, 0.018173075467348098, 0.018040549386292695, 0.01920088492333889, 0.018288108786568044, 0.018233200684189797, 0.018311400409787893, 0.01862160952948034, 0.0174190454762429, 0.01713467708416283, 0.01741631662659347, 0.0167895149551332, 0.02080209694802761, 0.019001761581748725, 0.018575513616204263, 0.018006745943799616, 0.017410305626690388, 0.017650581685826183, 0.017205424746498464, 0.017187049441039562, 0.017148209940642117, 0.017297182789072395, 0.016745508337393404, 0.017255732702091336, 0.016896019788458942, 0.016703642763197423, 0.016207393081858753, 0.016297762375324966, 0.015839377926662564, 0.015694218516349792, 0.016673045583069323, 0.016350852286443115, 0.015881229888647794, 0.0159442222956568, 0.01703358159214258, 0.01873346335813403, 0.01809478255920112, 0.01721030916273594, 0.016753791386261582, 0.01681623713672161, 0.016613686803728343, 0.015917574852705, 0.016088571159169077, 0.016135489728301762, 0.015643452448770405, 0.016483605755493045, 0.015855075683444738, 0.01543370801769197, 0.01523850143700838, 0.016195791345089673, 0.015302437523379921, 0.014767042398452758, 0.015454615119844676, 0.015194684721529484, 0.014699457995593548, 0.015011802824214101, 0.017606176303699612, 0.01590417698211968, 0.015192578360438348, 0.01571611988171935, 0.018162332816049457, 0.01624525157548487, 0.015853576555848122, 0.01641390584781766, 0.01651142694428563, 0.015454946147277951, 0.015622698659077287, 0.015376735201105475, 0.014686289297416806, 0.015393292719498276, 0.015462149133905768, 0.014589667661115528, 0.015156473185867072, 0.014381461620330811, 0.014691609870642424, 0.014310772363096476, 0.015246791243553161, 0.014024523435160518, 0.014733502395451068, 0.014880101811140776, 0.01577987532876432, 0.01401820351369679, 0.013407132636755704, 0.016139509966596962, 0.015502629734575748, 0.014816066287457942, 0.013977023614570499, 0.013429499488323927, 0.014204582672566175, 0.015494820151478052, 0.016736324347555637, 0.016954856034368276, 0.01537092163413763, 0.014928703438490629, 0.0150102962218225, 0.014983700415119528, 0.015186872584745287, 0.0144251465536654, 0.014845890384167433, 0.01576803625561297, 0.01441261726617813, 0.01376055639795959, 0.014305748080834747, 0.013106557641178369, 0.013928780302405358, 0.01444950195401907, 0.013618491061031818, 0.01427720613963902, 0.013042618224397302, 0.013062130391597747, 0.013376841070130468, 0.014238608304411173, 0.012896505711600184, 0.012896818885579706, 0.012938438165932894, 0.014221373211592435, 0.013171657653525471, 0.01317107867822051, 0.012225927114486694, 0.013821055805310607, 0.01346305400878191, 0.014100732941180468, 0.012327509872615338, 0.013989455992355944, 0.012464309431612492, 0.012445384550839662, 0.013812857169657945, 0.013897999066859484, 0.012870703319087625, 0.011953030360862612, 0.012046316290274263, 0.015117348765954376, 0.013724724737927317, 0.013757253119722009, 0.01255796123109758, 0.013457882883027196, 0.017078424669802188, 0.01496700705587864, 0.014036835096776485, 0.012806277645751834, 0.014179187072440981, 0.013355332935228944, 0.013351558614522219, 0.019167874176055193, 0.01965174584276974, 0.01786942295357585, 0.01741030738502741, 0.01652990063279867, 0.01593399283848703, 0.017068029349669812, 0.01857032513432205, 0.016886919466778637, 0.016096790986135603, 0.015296649171039463, 0.017096801659092307, 0.02081536446325481, 0.018926002070307733, 0.018527325943112374, 0.0175101152472198, 0.017617764396592975, 0.016845132512971758, 0.01684022535942495, 0.01766524547897279, 0.01663449765741825, 0.016978449119254946, 0.016516964176669716, 0.016534767035394908, 0.0157278186455369, 0.01612776903063059, 0.015691125966608523, 0.01548647427931428, 0.016942287281155585, 0.015773084053769707, 0.014685304233804345, 0.015449677925556899, 0.014841076942160726, 0.014733999669551849, 0.016936394944787027, 0.014594390794634819, 0.015112597398459911, 0.016252334721386433, 0.015748616123571993, 0.014636035453528165, 0.014659830773249269, 0.016870708169415594, 0.01713793479092419, 0.017489572867751123, 0.016913021888583898, 0.01552467386983335, 0.0156511570494622, 0.015112892089411616, 0.015052609369158745, 0.01473663797415793, 0.014682630319148302, 0.01543885744549334, 0.014734000705182552, 0.014214937955141067, 0.013977857472375035, 0.013799058992415666, 0.014449585128575564, 0.014043611666187644, 0.013701025556772948, 0.015158170027658343, 0.0161221962813288, 0.014632106369361282, 0.015251406526193024, 0.013695252230390906, 0.013744456339627504, 0.014167666904628277, 0.013501299809664488, 0.013789283894002437, 0.014045761624351144, 0.013999497342854739, 0.01336413855291903, 0.013905954467132688, 0.01387480373121798, 0.01274611660093069, 0.01382338684424758, 0.013744378287345172, 0.014759306117892265, 0.02071119421161711, 0.018569640923291445, 0.017664246052503586, 0.016406238233670593, 0.015621512819081545, 0.015553099615499378, 0.015354122839868069, 0.015086881060153245, 0.01520103178732097, 0.015774052925407886, 0.015074295837432146, 0.014331296829506755, 0.014602523623034358, 0.014420374039560556, 0.014289202805608511, 0.014080953493714332, 0.015059907956048847, 0.013633827727288007, 0.013984709145501257, 0.01424902843683958, 0.014789031183347106, 0.013632706271484494, 0.015325002860277891, 0.01440774724446237, 0.016711358830332756, 0.015595842625945806, 0.014821090737357736, 0.013950575023889541, 0.01377117221802473, 0.014576059916988016, 0.013827185465022922, 0.013796036045998335, 0.01465661077015102, 0.013950194822624325, 0.013745016427710652, 0.013167497970163823, 0.01430046728439629, 0.01376945725083351, 0.013103790089488029, 0.013263269348070025, 0.013693477349355818, 0.013460784820839762, 0.013543061895295978, 0.013360202580690385, 0.016293263809755446, 0.015780031392350794, 0.013571609389036893, 0.014676981166005135, 0.014920710111036897, 0.015143109736964106, 0.014498768426477909, 0.013568353191018104, 0.013861068669706583, 0.013489334676414728, 0.014431158680468797, 0.013643140828236937, 0.013610647685825825, 0.014055623859167098]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430c6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02642285544425249, 0.025861969105899333, 0.025658992528915407, 0.024863757826387882, 0.024580235294997692, 0.023216172009706496, 0.023129122760146857, 0.02174765333533287, 0.022259800769388674, 0.02301228679716587, 0.021990384459495544, 0.020719048641622065, 0.020075400769710542, 0.02032393030822277, 0.020158131439238787, 0.019854275360703468, 0.020550847314298154, 0.0186054821126163, 0.018922086022794247, 0.0183033037930727, 0.018050896283239127, 0.01855272728949785, 0.018481518533080818, 0.0187186399102211, 0.017974834218621255, 0.01927905734628439, 0.019678300134837626, 0.017432905808091162, 0.017554079964756965, 0.017384148817509413, 0.016878640521317722, 0.017410983927547932, 0.016709308587014676, 0.01625823438167572, 0.018481369502842425, 0.02003234166651964, 0.018358576577156782, 0.017409675773233175, 0.016994550824165344, 0.017366515062749385, 0.016678190249949695, 0.016780643556267023, 0.018081420194357635, 0.017078443318605422, 0.01696379030123353, 0.017139261923730373, 0.016177832409739495, 0.01679033152759075, 0.015572787951678038, 0.015174705125391484, 0.015954588036984206, 0.016334378961473703, 0.015369012895971536, 0.016994205936789512, 0.015616585556417704, 0.015341118425130845, 0.015821712967008354, 0.019097239933907984, 0.01857185771688819, 0.016114305928349493, 0.01711974823847413, 0.016439170371741058, 0.016459644418209792, 0.015890642181038857, 0.015677155908197165, 0.015169878117740154, 0.01537635227665305, 0.015429512616246938, 0.015255535785108805, 0.014717867188155652, 0.015142536833882331, 0.017829625457525252, 0.014998787362128497, 0.01704033214598894, 0.014339172635227443, 0.015424076858907938, 0.014904231913387776, 0.02307571854442358, 0.01610027801245451, 0.015302916057407856, 0.01450972331687808, 0.014809924140572549, 0.017010643426328898, 0.01599942872300744, 0.016422603726387024, 0.016825610883533956, 0.014972931034862995, 0.014869312867522239, 0.014491164050996303, 0.014908383153378963, 0.014769516419619322, 0.017828165777027605, 0.014511087164282798, 0.014367787521332503, 0.014526814483106136, 0.014965641312301159, 0.013881998751312494, 0.01599877778440714, 0.014581253286451101, 0.013942462988197804, 0.013540458828210832, 0.018934365082532167, 0.014750841781497001, 0.013097413461655378, 0.013326087221503257, 0.014249877389520407, 0.014709269534796477, 0.013443762678653002, 0.013279700316488743, 0.013477206714451313, 0.013443069700151682, 0.017559593040496112, 0.016395665667951108, 0.016148841343820095, 0.014543566908687354, 0.014541892223060132, 0.015191835071891546, 0.015006849933415651, 0.014379624407738448, 0.014520038180053233, 0.013998982477933169, 0.015446176994591951, 0.013889951836317778, 0.01373877365142107, 0.013203166797757149, 0.013016774747520686, 0.01311680043116212, 0.013757378160953522, 0.013751532062888145, 0.014761705882847309, 0.013596688136458398, 0.012578814439475536, 0.012633646558970212, 0.013437554910779, 0.015876448638737203, 0.012411138601601123, 0.02037629209458828, 0.013942223973572254, 0.013137235920876265, 0.012572360504418612, 0.012552346717566252, 0.01571868572384119, 0.013726141750812531, 0.012889436706900596, 0.011783465631306172, 0.012927067186683416, 0.01385378735139966, 0.01186903040856123, 0.013457692600786686, 0.013399015348404646, 0.01207069719210267, 0.01208595084026456, 0.012153746224939824, 0.013132928535342217, 0.012812600620090962, 0.013365782294422389, 0.01274115476757288, 0.01347094938158989, 0.015785640999674798, 0.014174618981778622, 0.013322036042809486, 0.01419338371604681, 0.015098779201507569, 0.012342077139765024, 0.013261888343840837, 0.021048882193863392, 0.018446285780519246, 0.01732804113999009, 0.01660809963941574, 0.016164659149944784, 0.015470960065722466, 0.020573333241045474, 0.0176904528029263, 0.01607993049547076, 0.015347456503659486, 0.01612202862277627, 0.0216983987390995, 0.02029421355575323, 0.01979774350300431, 0.017828543167561293, 0.017264224775135516, 0.016350094582885503, 0.01653854876756668, 0.016610488928854465, 0.017433097306638955, 0.015880698282271625, 0.01648948822170496, 0.016052900049835443, 0.01619076816365123, 0.015937464367598294, 0.015529267080128193, 0.015115005373954772, 0.015170441139489413, 0.015518646407872438, 0.014893325418233872, 0.01500389913097024, 0.014820104036480188, 0.013959788084030152, 0.015217741634696722, 0.014726405832916498, 0.014380840212106704, 0.014590001925826072, 0.015372745562344789, 0.014675585366785527, 0.014164459798485041, 0.014880648255348206, 0.01747447770088911, 0.015837741531431675, 0.01757157364860177, 0.015383351668715477, 0.015033204164355994, 0.015467194616794586, 0.014836015310138465, 0.014344246312975883, 0.014068817347288131, 0.01449219899252057, 0.01510340578854084, 0.014125145506113768, 0.015264317709952593, 0.013962831553071738, 0.013963663410395384, 0.013282519653439523, 0.013344979360699654, 0.014061341360211373, 0.013718866799026728, 0.014844134654849768, 0.013967798072844744, 0.014065611585974693, 0.013221815098077058, 0.013775822091847658, 0.01333426719531417, 0.014792266096919774, 0.013320424053817987, 0.01352226773276925, 0.014486761223524809, 0.012652579192072154, 0.014659680780023337, 0.012577260602265597, 0.013036097548902035, 0.013000192288309335, 0.01331078290939331, 0.02382398996502161, 0.02102951005101204, 0.018400719817727805, 0.016707800906151534, 0.016433974020183085, 0.015213296487927437, 0.015945750977844, 0.01418767089024186, 0.016001758500933647, 0.014411379266530275, 0.01504911569878459, 0.013824485335499048, 0.014444589894264937, 0.013731309175491334, 0.016703382283449173, 0.0135707051679492, 0.019268585667014122, 0.0136533422768116, 0.014744368679821492, 0.01352113053202629, 0.015383384339511395, 0.013309705834835768, 0.013667614459991454, 0.014023925624787808, 0.013600935712456703, 0.01864571398124099, 0.014207997266203165, 0.015171810202300549, 0.013998037483543158, 0.014723165575414896, 0.014616405069828033, 0.01442143440246582, 0.014181270934641362, 0.014077660385519266, 0.013509892392903566, 0.013577945288270712, 0.013135469537228345, 0.014022007044404745, 0.012726941574364901, 0.01500928496941924, 0.013591346442699432, 0.015593550875782966, 0.012731310464441776, 0.012634179443120957, 0.019018165953457355, 0.01826314453035593, 0.013838667385280133, 0.01332946227863431, 0.014299368392676115, 0.01677675101906061, 0.01486764159053564, 0.013969577550888061, 0.012784611731767655, 0.013615949209779502, 0.016090582031756638, 0.013748830407857895, 0.014172745775431395, 0.015270169544965028, 0.013392268307507038]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5ec087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165000\n",
      "165000\n"
     ]
    }
   ],
   "source": [
    "# val_time_loss_list\n",
    "# val_dim_loss_list\n",
    "# val_mse_loss_list\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_time_loss_list))\n",
    "val_time_loss_list_dataframe = pd.DataFrame(val_time_loss_list)\n",
    "plt.plot(np.array(val_time_loss_list_dataframe.index), np.array(val_time_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_time_loss_training.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_dim_loss_list))\n",
    "val_dim_loss_list_dataframe = pd.DataFrame(val_dim_loss_list)\n",
    "plt.plot(np.array(val_dim_loss_list_dataframe.index), np.array(val_dim_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_dim_loss_training.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_mse_loss_list))\n",
    "val_mse_loss_list_dataframe = pd.DataFrame(val_mse_loss_list)\n",
    "plt.plot(np.array(val_mse_loss_list_dataframe.index), np.array(val_mse_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_mse_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa7c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.014431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.013643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.014056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.028981\n",
       "1    0.027057\n",
       "2    0.025562\n",
       "3    0.024989\n",
       "4    0.024635\n",
       "..        ...\n",
       "295  0.013489\n",
       "296  0.014431\n",
       "297  0.013643\n",
       "298  0.013611\n",
       "299  0.014056\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51793ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch_list_dataframe = pd.DataFrame(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade5deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_loss_per_epoch_list_dataframe.index), np.array(val_loss_per_epoch_list_dataframe[0]))\n",
    "plt.savefig(\"training_val_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12f49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86e0a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_preprocess(audio_path, specific_fps):\n",
    "    n_fft = 4096\n",
    "    hop = int(44000/specific_fps)  # 1102.5 -> 40fps #882 -> 50fps\n",
    "    y, sr = librosa.load(audio_path, sr=44000)  # 44000 for divide 40\n",
    "    print(\"y.shape\", y.shape)\n",
    "    print(\"sample rate: \", sr)\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop, n_mfcc=13)\n",
    "    y = np.where(y == 0, 1e-10, y)\n",
    "    energy = np.log(librosa.feature.rms(\n",
    "        y=y, frame_length=n_fft, hop_length=hop, center=True))\n",
    "    mfcc_energy = np.vstack((mfcc, energy))\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_energy)\n",
    "\n",
    "    sgram = librosa.stft(y, n_fft=n_fft, hop_length=hop)\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(\n",
    "        S=sgram_mag, sr=sr)\n",
    "\n",
    "    print(\"mfcc_energy\", mfcc_energy.shape)\n",
    "    print(\"mfcc_delta\", mfcc_delta.shape)\n",
    "    print(\"mel_scale_sgram\", mel_scale_sgram.shape)\n",
    "\n",
    "    aud = np.vstack((mfcc_energy, mfcc_delta, mel_scale_sgram)).T\n",
    "\n",
    "    print(\"hop:\", hop)\n",
    "    print(\"aud:\", aud.shape)\n",
    "    return aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.wav\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape (8988979,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 8172)\n",
      "mfcc_delta (14, 8172)\n",
      "mel_scale_sgram (128, 8172)\n",
      "hop: 1100\n",
      "aud: (8172, 156)\n",
      "(8172, 156)\n",
      "str_name: ./BWV1001/vs1-3sic.wav\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.wav\n",
      "y.shape (7687297,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 6989)\n",
      "mfcc_delta (14, 6989)\n",
      "mel_scale_sgram (128, 6989)\n",
      "hop: 1100\n",
      "aud: (6989, 156)\n",
      "(6989, 156)\n",
      "str_name: ./BWV1001/vs1-2fug.wav\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.wav\n",
      "y.shape (12687134,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 11534)\n",
      "mfcc_delta (14, 11534)\n",
      "mel_scale_sgram (128, 11534)\n",
      "hop: 1100\n",
      "aud: (11534, 156)\n",
      "(11534, 156)\n",
      "str_name: ./BWV1001/vs1-4prs.wav\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.wav\n",
      "y.shape (8686945,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 7898)\n",
      "mfcc_delta (14, 7898)\n",
      "mel_scale_sgram (128, 7898)\n",
      "hop: 1100\n",
      "aud: (7898, 156)\n",
      "(7898, 156)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_audio_path_list = glob.glob(test_datapath + \"*.wav\")\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "for test_audio in test_audio_path_list:\n",
    "    str_name = test_audio\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_audio)\n",
    "    # read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_audio = audio_preprocess(test_audio, change_fps)\n",
    "    # read_audio_transpose = read_audio\n",
    "    print(read_audio.shape)\n",
    "    test_audio_len = read_audio.shape[0]\n",
    "    test_data_list.append(read_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 8172, 156)\n",
      "prediction.shape (1, 8172, 102)\n",
      "full_prediction (8172, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.09988734  0.13363674  1.10580812]\n",
      "  [ 0.03402711  0.09626903  1.12287817]\n",
      "  [ 0.14067456  0.05558139  1.10348449]\n",
      "  ...\n",
      "  [ 0.02693497  0.12217661  0.98010645]\n",
      "  [-0.15283084  0.01531582  1.13282702]\n",
      "  [ 0.06641096  0.28688464  0.82234249]]\n",
      "\n",
      " [[ 0.06672604  0.10341541  1.09074024]\n",
      "  [ 0.00379783  0.06871738  1.08750794]\n",
      "  [ 0.11069345  0.03689703  1.10705957]\n",
      "  ...\n",
      "  [ 0.02524433  0.11253261  0.95855693]\n",
      "  [-0.15412211  0.02891576  1.08207372]\n",
      "  [ 0.09527171  0.22730632  0.80568061]]\n",
      "\n",
      " [[ 0.09955096  0.11642464  1.10610948]\n",
      "  [ 0.03644545  0.08589829  1.10815618]\n",
      "  [ 0.14216803  0.04686813  1.13009069]\n",
      "  ...\n",
      "  [ 0.0473243   0.12792474  0.9651157 ]\n",
      "  [-0.14654443  0.03108923  1.09746895]\n",
      "  [ 0.10867678  0.2294811   0.8267828 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.08911625  0.1156933   1.1072757 ]\n",
      "  [ 0.03006235  0.07697234  1.11390684]\n",
      "  [ 0.14037761  0.05004148  1.12286565]\n",
      "  ...\n",
      "  [ 0.04515818  0.11576001  0.97764031]\n",
      "  [-0.09049699  0.07924838  1.08735648]\n",
      "  [ 0.14668126  0.22769609  0.72999165]]\n",
      "\n",
      " [[ 0.09204784  0.11663466  1.10692987]\n",
      "  [ 0.03277232  0.0767011   1.11503944]\n",
      "  [ 0.14373307  0.05069156  1.12058792]\n",
      "  ...\n",
      "  [ 0.04631224  0.11551199  0.97941968]\n",
      "  [-0.08796564  0.07870093  1.08800272]\n",
      "  [ 0.14960381  0.235535    0.7297729 ]]\n",
      "\n",
      " [[ 0.08624963  0.11129412  1.10720358]\n",
      "  [ 0.02769555  0.06860908  1.11272738]\n",
      "  [ 0.13951184  0.04682498  1.1181067 ]\n",
      "  ...\n",
      "  [ 0.04497308  0.11128539  0.97714452]\n",
      "  [-0.0905236   0.07456539  1.09695587]\n",
      "  [ 0.13850079  0.22388986  0.72997723]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-1ada.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-1ada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 240 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 236 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-1ada.wav':\n",
      "  Duration: 00:03:24.29, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5586138c6180] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5586138c6180] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5586138c6180] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-1ada_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=456 q=-1.0 Lsize=    3796kB time=00:03:24.31 bitrate= 152.2kbits/s speed= 117x    \n",
      "video:542kB audio:3202kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.392642%\n",
      "[aac @ 0x5586138c4a40] Qavg: 182.785\n",
      "[libx264 @ 0x5586138c6180] frame I:4     Avg QP:16.31  size: 13448\n",
      "[libx264 @ 0x5586138c6180] frame P:228   Avg QP:23.47  size:  1226\n",
      "[libx264 @ 0x5586138c6180] frame B:568   Avg QP:29.19  size:   389\n",
      "[libx264 @ 0x5586138c6180] consecutive B-frames:  2.6%  6.0%  6.4% 85.0%\n",
      "[libx264 @ 0x5586138c6180] mb I  I16..4: 26.9% 48.4% 24.7%\n",
      "[libx264 @ 0x5586138c6180] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.0%  1.8%  2.0%  0.0%  0.0%    skip:95.1%\n",
      "[libx264 @ 0x5586138c6180] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.7%  1.7%  0.9%  direct: 0.2%  skip:95.4%  L0:45.6% L1:42.2% BI:12.2%\n",
      "[libx264 @ 0x5586138c6180] 8x8 transform intra:49.6% inter:26.1%\n",
      "[libx264 @ 0x5586138c6180] coded y,uvDC,uvAC intra: 19.0% 2.6% 2.3% inter: 1.3% 0.4% 0.4%\n",
      "[libx264 @ 0x5586138c6180] i16 v,h,dc,p: 83%  4% 14%  0%\n",
      "[libx264 @ 0x5586138c6180] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 39%  8% 52%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x5586138c6180] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 31%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x5586138c6180] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x5586138c6180] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5586138c6180] ref P L0: 50.6%  7.5% 21.8% 20.1%\n",
      "[libx264 @ 0x5586138c6180] ref B L0: 78.5% 14.4%  7.0%\n",
      "[libx264 @ 0x5586138c6180] ref B L1: 92.9%  7.1%\n",
      "[libx264 @ 0x5586138c6180] kb/s:221.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 6989, 156)\n",
      "prediction.shape (1, 6989, 102)\n",
      "full_prediction (6989, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.11143525  0.14824913  1.10532568]\n",
      "  [ 0.04957245  0.1090491   1.12825618]\n",
      "  [ 0.15408263  0.07368653  1.10853539]\n",
      "  ...\n",
      "  [ 0.03372957  0.1395852   0.98962096]\n",
      "  [-0.15193698  0.03426812  1.11562643]\n",
      "  [ 0.08647226  0.30522862  0.82518378]]\n",
      "\n",
      " [[ 0.04777451  0.15457837  1.08932862]\n",
      "  [-0.01217309  0.1138586   1.09455744]\n",
      "  [ 0.09799998  0.09036286  1.1113728 ]\n",
      "  ...\n",
      "  [-0.00382505  0.13840929  0.96875612]\n",
      "  [-0.20871779  0.0285041   1.12025819]\n",
      "  [ 0.05473995  0.26188734  0.82495407]]\n",
      "\n",
      " [[ 0.09851381  0.14541137  1.10412488]\n",
      "  [ 0.03904285  0.1096011   1.11485372]\n",
      "  [ 0.1478481   0.07909512  1.1281024 ]\n",
      "  ...\n",
      "  [ 0.03505704  0.1308939   0.97772202]\n",
      "  [-0.15835473  0.0216288   1.11063526]\n",
      "  [ 0.10809526  0.27547091  0.83677099]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.08448407  0.13343447  1.10765491]\n",
      "  [ 0.02733451  0.09224141  1.11421881]\n",
      "  [ 0.13793848  0.07022493  1.12617776]\n",
      "  ...\n",
      "  [ 0.04254091  0.13006619  0.98167816]\n",
      "  [-0.11106151  0.07517272  1.08998547]\n",
      "  [ 0.12671112  0.23805781  0.75633982]]\n",
      "\n",
      " [[ 0.08680908  0.13320082  1.1076791 ]\n",
      "  [ 0.03087498  0.09084983  1.11412487]\n",
      "  [ 0.14192542  0.0714303   1.12610576]\n",
      "  ...\n",
      "  [ 0.0446502   0.13064547  0.98147533]\n",
      "  [-0.10820159  0.07502018  1.09177039]\n",
      "  [ 0.12669079  0.23552783  0.7560576 ]]\n",
      "\n",
      " [[ 0.08890408  0.13353056  1.10769448]\n",
      "  [ 0.0335086   0.09064464  1.11417994]\n",
      "  [ 0.14478758  0.0723386   1.12588367]\n",
      "  ...\n",
      "  [ 0.04601882  0.1311214   0.98107949]\n",
      "  [-0.10648248  0.07681054  1.09132264]\n",
      "  [ 0.12846147  0.23449779  0.75310866]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-3sic.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-3sic.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 226 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 222 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-3sic.wav':\n",
      "  Duration: 00:02:54.71, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55e7329f1b40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55e7329f1b40] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55e7329f1b40] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-3sic_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=493 q=-1.0 Lsize=    3288kB time=00:02:54.73 bitrate= 154.2kbits/s speed= 108x    \n",
      "video:502kB audio:2739kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.457857%\n",
      "[aac @ 0x55e7329f0400] Qavg: 180.446\n",
      "[libx264 @ 0x55e7329f1b40] frame I:4     Avg QP:16.27  size: 13498\n",
      "[libx264 @ 0x55e7329f1b40] frame P:211   Avg QP:22.97  size:  1264\n",
      "[libx264 @ 0x55e7329f1b40] frame B:585   Avg QP:29.09  size:   330\n",
      "[libx264 @ 0x55e7329f1b40] consecutive B-frames:  0.9%  3.8%  3.4% 92.0%\n",
      "[libx264 @ 0x55e7329f1b40] mb I  I16..4: 27.6% 48.4% 24.0%\n",
      "[libx264 @ 0x55e7329f1b40] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.0%  1.8%  2.0%  0.0%  0.0%    skip:95.0%\n",
      "[libx264 @ 0x55e7329f1b40] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.8%  1.6%  0.8%  direct: 0.2%  skip:95.6%  L0:44.5% L1:42.6% BI:12.8%\n",
      "[libx264 @ 0x55e7329f1b40] 8x8 transform intra:47.3% inter:27.2%\n",
      "[libx264 @ 0x55e7329f1b40] coded y,uvDC,uvAC intra: 19.8% 2.1% 1.9% inter: 1.2% 0.4% 0.3%\n",
      "[libx264 @ 0x55e7329f1b40] i16 v,h,dc,p: 84%  3% 13%  0%\n",
      "[libx264 @ 0x55e7329f1b40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 46%  8% 46%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55e7329f1b40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 31%  8%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55e7329f1b40] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55e7329f1b40] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55e7329f1b40] ref P L0: 53.2%  7.9% 21.2% 17.8%\n",
      "[libx264 @ 0x55e7329f1b40] ref B L0: 80.0% 14.1%  6.0%\n",
      "[libx264 @ 0x55e7329f1b40] ref B L1: 92.8%  7.2%\n",
      "[libx264 @ 0x55e7329f1b40] kb/s:205.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 11534, 156)\n",
      "prediction.shape (1, 11534, 102)\n",
      "full_prediction (11534, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.09857097  0.12303302  1.10126219]\n",
      "  [ 0.04028325  0.06907805  1.12168894]\n",
      "  [ 0.14946124  0.05371319  1.07726059]\n",
      "  ...\n",
      "  [ 0.02070983  0.10840873  0.97835085]\n",
      "  [-0.04113415  0.16420102  1.09517626]\n",
      "  [ 0.05853784  0.2139177   0.6828988 ]]\n",
      "\n",
      " [[ 0.10207625  0.13112091  1.08893726]\n",
      "  [ 0.04276083  0.07529266  1.1044961 ]\n",
      "  [ 0.15234227  0.06248096  1.07712797]\n",
      "  ...\n",
      "  [ 0.01844564  0.11643628  0.95280025]\n",
      "  [-0.06784162  0.13717249  1.11882076]\n",
      "  [ 0.06358875  0.22015925  0.70702866]]\n",
      "\n",
      " [[ 0.09375626  0.12585261  1.10038445]\n",
      "  [ 0.03715602  0.06564707  1.11807606]\n",
      "  [ 0.14839147  0.05884847  1.09013984]\n",
      "  ...\n",
      "  [ 0.00901167  0.11618531  0.96640346]\n",
      "  [-0.01963919  0.18509063  1.07840214]\n",
      "  [ 0.07306668  0.22643033  0.66662953]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.07745691  0.0843572   1.10641775]\n",
      "  [ 0.0087536   0.05311767  1.10885642]\n",
      "  [ 0.11680052  0.01116478  1.12145433]\n",
      "  ...\n",
      "  [ 0.04848738  0.09265622  0.97397337]\n",
      "  [-0.06852028  0.08200148  1.06891403]\n",
      "  [ 0.17307696  0.20648834  0.72754643]]\n",
      "\n",
      " [[ 0.07755832  0.08436921  1.10659299]\n",
      "  [ 0.00891775  0.05321369  1.10756633]\n",
      "  [ 0.11676389  0.01124509  1.12248049]\n",
      "  ...\n",
      "  [ 0.04527339  0.09244686  0.97384868]\n",
      "  [-0.07417235  0.07421044  1.07415096]\n",
      "  [ 0.16966555  0.20765747  0.73544774]]\n",
      "\n",
      " [[ 0.07274227  0.08593377  1.10675535]\n",
      "  [ 0.00453515  0.05545011  1.10710881]\n",
      "  [ 0.11247872  0.01349044  1.12414417]\n",
      "  ...\n",
      "  [ 0.04098187  0.09226796  0.97359238]\n",
      "  [-0.07880089  0.07895464  1.06990997]\n",
      "  [ 0.17082348  0.20297003  0.73368279]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-2fug.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-2fug.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 252 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 248 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-2fug.wav':\n",
      "  Duration: 00:04:48.34, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x561eb1c86780] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x561eb1c86780] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x561eb1c86780] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-2fug_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=345 q=-1.0 Lsize=    5154kB time=00:04:48.34 bitrate= 146.4kbits/s speed= 124x    \n",
      "video:570kB audio:4518kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.303660%\n",
      "[aac @ 0x561eb1c84f80] Qavg: 260.041\n",
      "[libx264 @ 0x561eb1c86780] frame I:4     Avg QP:15.63  size: 13507\n",
      "[libx264 @ 0x561eb1c86780] frame P:227   Avg QP:23.54  size:  1329\n",
      "[libx264 @ 0x561eb1c86780] frame B:569   Avg QP:29.29  size:   399\n",
      "[libx264 @ 0x561eb1c86780] consecutive B-frames:  1.8%  8.5%  5.2% 84.5%\n",
      "[libx264 @ 0x561eb1c86780] mb I  I16..4: 29.5% 46.1% 24.4%\n",
      "[libx264 @ 0x561eb1c86780] mb P  I16..4:  0.0%  0.0%  0.1%  P16..4:  1.0%  1.8%  2.1%  0.0%  0.0%    skip:95.0%\n",
      "[libx264 @ 0x561eb1c86780] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.7%  1.8%  0.9%  direct: 0.3%  skip:95.4%  L0:44.8% L1:41.8% BI:13.4%\n",
      "[libx264 @ 0x561eb1c86780] 8x8 transform intra:45.3% inter:26.4%\n",
      "[libx264 @ 0x561eb1c86780] coded y,uvDC,uvAC intra: 20.6% 3.2% 3.0% inter: 1.3% 0.4% 0.4%\n",
      "[libx264 @ 0x561eb1c86780] i16 v,h,dc,p: 81%  6% 14%  0%\n",
      "[libx264 @ 0x561eb1c86780] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42%  7% 51%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x561eb1c86780] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 32%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x561eb1c86780] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x561eb1c86780] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x561eb1c86780] ref P L0: 55.8%  8.7% 19.7% 15.7%\n",
      "[libx264 @ 0x561eb1c86780] ref B L0: 81.6% 13.5%  4.9%\n",
      "[libx264 @ 0x561eb1c86780] ref B L1: 94.0%  6.0%\n",
      "[libx264 @ 0x561eb1c86780] kb/s:233.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 7898, 156)\n",
      "prediction.shape (1, 7898, 102)\n",
      "full_prediction (7898, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 1.09366775e-01  1.32809713e-01  1.10668740e+00]\n",
      "  [ 4.34905738e-02  9.51070711e-02  1.12508283e+00]\n",
      "  [ 1.47306308e-01  5.14488518e-02  1.10386572e+00]\n",
      "  ...\n",
      "  [ 2.83717066e-02  1.23474352e-01  9.75988841e-01]\n",
      "  [-1.22796774e-01  8.86199772e-02  1.13926897e+00]\n",
      "  [ 9.33865532e-02  2.69454181e-01  7.92993999e-01]]\n",
      "\n",
      " [[ 5.79933226e-02  1.25392467e-01  1.09112880e+00]\n",
      "  [-6.10017776e-03  9.16627347e-02  1.08857200e+00]\n",
      "  [ 9.93176401e-02  5.32404780e-02  1.10283122e+00]\n",
      "  ...\n",
      "  [-1.58296525e-03  1.17699236e-01  9.60107303e-01]\n",
      "  [-1.86576650e-01  3.35307121e-02  1.14412305e+00]\n",
      "  [ 3.76669914e-02  2.18716234e-01  8.01119602e-01]]\n",
      "\n",
      " [[ 6.21366054e-02  1.16735831e-01  1.10568247e+00]\n",
      "  [-1.33749843e-03  8.42808336e-02  1.10228631e+00]\n",
      "  [ 1.06960781e-01  4.75866050e-02  1.13080344e+00]\n",
      "  ...\n",
      "  [ 1.45177096e-02  1.11524761e-01  9.67199659e-01]\n",
      "  [-1.64250627e-01  4.81543317e-02  1.13154016e+00]\n",
      "  [ 8.18960220e-02  1.90539181e-01  7.85876846e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 7.52463043e-02  9.88209397e-02  1.10857675e+00]\n",
      "  [ 5.54692745e-03  6.48865998e-02  1.10879836e+00]\n",
      "  [ 1.14272110e-01  2.39135474e-02  1.11985884e+00]\n",
      "  ...\n",
      "  [ 3.05669308e-02  9.81254056e-02  9.72358799e-01]\n",
      "  [-9.65003073e-02  7.49459192e-02  1.10070167e+00]\n",
      "  [ 1.28569350e-01  2.00667441e-01  7.11287475e-01]]\n",
      "\n",
      " [[ 6.85729831e-02  9.81333852e-02  1.10976586e+00]\n",
      "  [-2.64495611e-04  6.48709238e-02  1.10709319e+00]\n",
      "  [ 1.07800201e-01  2.35477239e-02  1.12324235e+00]\n",
      "  ...\n",
      "  [ 2.41979510e-02  1.01666428e-01  9.68964672e-01]\n",
      "  [-9.90922451e-02  8.83891433e-02  1.09889159e+00]\n",
      "  [ 1.16980046e-01  1.79765075e-01  6.98135352e-01]]\n",
      "\n",
      " [[ 6.51243031e-02  1.00828290e-01  1.10914776e+00]\n",
      "  [-1.33469701e-03  6.74141794e-02  1.10616324e+00]\n",
      "  [ 1.06409751e-01  2.79585123e-02  1.12490544e+00]\n",
      "  ...\n",
      "  [ 1.85806602e-02  1.04752600e-01  9.67842197e-01]\n",
      "  [-1.11034155e-01  8.32139701e-02  1.09969530e+00]\n",
      "  [ 1.11648783e-01  1.87198669e-01  7.12596095e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-4prs.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-4prs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 237 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 233 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-4prs.wav':\n",
      "  Duration: 00:03:17.43, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x565402013040] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x565402013040] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x565402013040] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-4prs_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=477 q=-1.0 Lsize=    3682kB time=00:03:17.43 bitrate= 152.8kbits/s speed= 118x    \n",
      "video:536kB audio:3095kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.406016%\n",
      "[aac @ 0x565402011900] Qavg: 188.133\n",
      "[libx264 @ 0x565402013040] frame I:4     Avg QP:16.89  size: 13286\n",
      "[libx264 @ 0x565402013040] frame P:216   Avg QP:23.34  size:  1272\n",
      "[libx264 @ 0x565402013040] frame B:580   Avg QP:28.97  size:   379\n",
      "[libx264 @ 0x565402013040] consecutive B-frames:  1.6%  3.8%  4.1% 90.5%\n",
      "[libx264 @ 0x565402013040] mb I  I16..4: 25.9% 49.6% 24.5%\n",
      "[libx264 @ 0x565402013040] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.0%  1.9%  2.0%  0.0%  0.0%    skip:94.9%\n",
      "[libx264 @ 0x565402013040] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.7%  1.8%  0.8%  direct: 0.3%  skip:95.3%  L0:45.6% L1:42.2% BI:12.1%\n",
      "[libx264 @ 0x565402013040] 8x8 transform intra:49.6% inter:25.5%\n",
      "[libx264 @ 0x565402013040] coded y,uvDC,uvAC intra: 19.8% 2.6% 2.4% inter: 1.2% 0.4% 0.4%\n",
      "[libx264 @ 0x565402013040] i16 v,h,dc,p: 82%  3% 14%  0%\n",
      "[libx264 @ 0x565402013040] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45%  9% 45%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x565402013040] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 31%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x565402013040] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x565402013040] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x565402013040] ref P L0: 53.1%  8.3% 19.7% 19.0%\n",
      "[libx264 @ 0x565402013040] ref B L0: 79.0% 15.2%  5.8%\n",
      "[libx264 @ 0x565402013040] ref B L1: 92.7%  7.3%\n",
      "[libx264 @ 0x565402013040] kb/s:219.12\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "772d4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8172, 115])\n",
      "test_input (1, 8172, 156)\n",
      "test_target torch.Size([1, 8172, 115])\n",
      "prediction.shape (1, 8172, 102)\n",
      "full_prediction (8172, 102)\n",
      "torch.Size([6989, 115])\n",
      "test_input (1, 6989, 156)\n",
      "test_target torch.Size([1, 6989, 115])\n",
      "prediction.shape (1, 6989, 102)\n",
      "full_prediction (6989, 102)\n",
      "torch.Size([11534, 115])\n",
      "test_input (1, 11534, 156)\n",
      "test_target torch.Size([1, 11534, 115])\n",
      "prediction.shape (1, 11534, 102)\n",
      "full_prediction (11534, 102)\n",
      "torch.Size([7898, 115])\n",
      "test_input (1, 7898, 156)\n",
      "test_target torch.Size([1, 7898, 115])\n",
      "prediction.shape (1, 7898, 102)\n",
      "full_prediction (7898, 102)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],115)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists('./output_prediction/[audio_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/'):\n",
    "            os.makedirs('./output_prediction/[audio_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/')\n",
    "        audio_data_output = open('./output_prediction/[audio_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/prediction_'+\n",
    "                                filecode +'.pkl', 'wb')\n",
    "        pickle.dump(prediction_arr, audio_data_output)\n",
    "        audio_data_output.close()\n",
    "        \n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_val_loss = evaluate_lstm(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee221509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
