{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"./midi_list_symbolic_cross.txt\" #f\"./midi_list.txt\"\n",
    "dataloader = get_dataloader(dataset_name_path, batch_size=20) #[20, 512, 128], [20, 512, 102]\n",
    "dataset = MidiMotionDataSet(dataset_name_path)\n",
    "\n",
    "val_dataset_name_path = f\"./midi_list_symbolic_cross.txt\" #f\"./midi_list_eval.txt\"\n",
    "# val_dataloader = get_val_dataloader(val_dataset_name_path, batch_size=40) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "full_data_path = None\n",
    "with open(\"./midi_list_symbolic_cross.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file]\n",
    "    full_data_path = np.array(lines)\n",
    "\n",
    "val_data_read = np.reshape(full_data_path, (11, 10))\n",
    "# print(val_data_read)\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "# input_size_encoder = 128 #129 #128\n",
    "# input_size_decoder = 115 #102 #24\n",
    "# output_size = 115#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2912b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model): # reset the weight every fold\n",
    "    if isinstance(model, nn.LSTM) or isinstance(model, nn.Linear):\n",
    "        model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 128 #number of features\n",
    "hidden_size = 1024 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 115 #number of output classes\n",
    "batch_size_define = 128#128\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "# model.train()\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 500 #10\n",
    "k_folds = 11\n",
    "cross_valid_results = {}\n",
    "torch.manual_seed(42)\n",
    "\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []\n",
    "\n",
    "#TODO: important cross val record\n",
    "val_time_loss_list = []\n",
    "val_dim_loss_list = []\n",
    "val_mse_loss_list = []\n",
    "val_per_split_list = [] #just mse loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b2811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def time_wise_loss_fn(preds, labels):\n",
    "#     '''\n",
    "#     calculate time-wise loss for motion (along the time axis)\n",
    "#     input: labels[batch, time, dimension(joint*xyz)]\n",
    "#     preds[batch, time , dimension(joint*xyz)]\n",
    "#     output: time loss\n",
    "#     '''\n",
    "#     # points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "#     # points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "#     # [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "#     # [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "#     # [30, 31], [32, 33],  #instrument\n",
    "    \n",
    "#     # print(\"preds.shape\", preds.shape)\n",
    "#     # print(\"labels.shape\", labels.shape)\n",
    "    \n",
    "#     # print(\"preds[9*3:18*3]\", preds[:, :, 9*3:19*3].shape)\n",
    "#     # print(\"labels[9*3:18*3]\", labels[:, :, 9*3:19*3].shape)\n",
    "    \n",
    "#     select_joint_preds = torch.cat((preds[:, :, 9*3:19*3], preds[:, :, 31*3:35*3]), 2)\n",
    "#     select_joint_labels = torch.cat((labels[:, :, 9*3:19*3], labels[:, :, 31*3:35*3]), 2)\n",
    "    \n",
    "#     # print(\"select_joint_preds.shape\", select_joint_preds.shape)\n",
    "#     # # print(select_joint_preds)\n",
    "#     # print(\"select_joint_labels.shape\", select_joint_labels.shape)\n",
    "    \n",
    "#     epsilon = 1e-7\n",
    "#     select_joint_preds = select_joint_preds + epsilon\n",
    "\n",
    "#     labels_transpose = torch.permute(select_joint_labels, (0, 2, 1))#tf.transpose(labels, [0, 2, 1]) # [b, 3, t]\n",
    "#     preds_transpose = torch.permute(select_joint_preds, (0, 2, 1))#tf.transpose(preds, [0, 2, 1]) # [b, 3, t]\n",
    "#     # print(\"labels_transpose.shape\", labels_transpose.shape)\n",
    "#     # print(\"preds_transpose.shape\", preds_transpose.shape)\n",
    "#     # print(\"labels_transpose[:, :, :, None].shape\", labels_transpose[:, :, :, None].shape)\n",
    "#     # print(\"labels_transpose[:, :, None, :].shape\", labels_transpose[:, :, None, :].shape)\n",
    "#     label_diff = labels_transpose[:, :, :, None] - labels_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    \n",
    "#     preds_diff = preds_transpose[:, :, :, None] - preds_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "#     # print(preds_diff.shape)\n",
    "#     time_loss = (preds_diff - label_diff)**2 # [b, 3, t, t]\n",
    "#     time_loss_value = time_loss.mean() #float()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     return time_loss_value\n",
    "    \n",
    "# def dim_wise_loss_fn(preds, labels):\n",
    "#     '''\n",
    "#     calculate dimension-wise loss for motion (along the dimension axis)\n",
    "#     input: labels[batch, time, dimension(joint*xyz)]\n",
    "#     preds[batch, time , dimension(joint*xyz)]\n",
    "#     output: dimension loss\n",
    "#     '''\n",
    "#     select_joint_preds = torch.cat((preds[:, :, 9*3:19*3], preds[:, :, 31*3:35*3]), 2)\n",
    "#     select_joint_labels = torch.cat((labels[:, :, 9*3:19*3], labels[:, :, 31*3:35*3]), 2)\n",
    "\n",
    "#     epsilon = 1e-7\n",
    "#     preds = preds + epsilon\n",
    "    \n",
    "#     label_diff = select_joint_labels[:, :, :, None] - select_joint_labels[:, :, None, :] # [b, t, 3, 3]\n",
    "#     preds_diff = select_joint_preds[:, :, :, None] - select_joint_preds[:, :, None, :] # [b, t, 3, 3]\n",
    "#     dim_loss = (preds_diff - label_diff)**2 # [b, t, 3, 3]\n",
    "#     dim_loss_value = dim_loss.mean() #float()\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "#     return dim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df5bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate time-wise loss for motion (along the time axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: time loss\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    preds = preds + epsilon\n",
    "\n",
    "    labels_transpose = torch.permute(labels, (0, 2, 1))#tf.transpose(labels, [0, 2, 1]) # [b, 3, t]\n",
    "    preds_transpose = torch.permute(preds, (0, 2, 1))#tf.transpose(preds, [0, 2, 1]) # [b, 3, t]\n",
    "    # print(\"labels_transpose.shape\", labels_transpose.shape)\n",
    "    # print(\"preds_transpose.shape\", preds_transpose.shape)\n",
    "    # print(\"labels_transpose[:, :, :, None].shape\", labels_transpose[:, :, :, None].shape)\n",
    "    # print(\"labels_transpose[:, :, None, :].shape\", labels_transpose[:, :, None, :].shape)\n",
    "    label_diff = labels_transpose[:, :, :, None] - labels_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    \n",
    "    preds_diff = preds_transpose[:, :, :, None] - preds_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    # print(preds_diff.shape)\n",
    "    time_loss = (preds_diff - label_diff)**2 # [b, 3, t, t]\n",
    "    time_loss_value = time_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return time_loss_value\n",
    "    \n",
    "def dim_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate dimension-wise loss for motion (along the dimension axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: dimension loss\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    preds = preds + epsilon\n",
    "    \n",
    "    label_diff = labels[:, :, :, None] - labels[:, :, None, :] # [b, t, 3, 3]\n",
    "    preds_diff = preds[:, :, :, None] - preds[:, :, None, :] # [b, t, 3, 3]\n",
    "    dim_loss = (preds_diff - label_diff)**2 # [b, t, 3, 3]\n",
    "    dim_loss_value = dim_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return dim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target):\n",
    "    # target = target.transpose(0, 1)\n",
    "\n",
    "    # print(\"output.shape:\", output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(\"target.shape:\", target.shape) #torch.Size([20, 513, 102])\n",
    "\n",
    "    w1_time = 0.3\n",
    "    w2_dim = 0.3\n",
    "    w3_mse = 0.4\n",
    "\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    time_loss = time_wise_loss_fn(output, target)\n",
    "    dim_loss = dim_wise_loss_fn(output, target)\n",
    "\n",
    "    # print(\"time_loss:\", time_loss)\n",
    "    # print(\"dim_loss:\", dim_loss)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "    val_time_loss_list.append(time_loss.cpu().item())\n",
    "    val_dim_loss_list.append(dim_loss.cpu().item())\n",
    "    val_mse_loss_list.append(mse_loss.cpu().item())\n",
    "\n",
    "    segment_loss = (w1_time * time_loss) + (w2_dim * dim_loss) + (w3_mse * mse_loss)\n",
    "    torch.cuda.empty_cache()\n",
    "    return  segment_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_cross(model, split_count):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    \n",
    "    outputs_save = []\n",
    "    \n",
    "    np.savetxt('./temp_path.txt', val_data_read[split_count], delimiter=\"\\n\", fmt=\"%s\")\n",
    "    # print(val_data_read[split_count])\n",
    "    val_dataloader = get_val_dataloader('./temp_path.txt', batch_size=11)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            # print(\"val inputs.shape:\", inputs.shape)\n",
    "            # print(\"val targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "            outputs_save.append(np.asarray(outputs.cpu()))\n",
    "\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if not os.path.exists(\"./output_eval/\"):\n",
    "        os.makedirs('./output_eval/')\n",
    "\n",
    "    # print(\"counter\", counter)\n",
    "    # print(\"val_data_read[split_count][counter]\", val_data_read[split_count][counter])\n",
    "    val_file_name = val_data_read[split_count][counter].split('/')[2].split('.')[0]\n",
    "\n",
    "    # print(\"val file_name:\", val_file_name)\n",
    "    # print(\"outputs_save length: \", len(outputs_save), \", element shape: \" , outputs_save[0].shape)\n",
    "        \n",
    "    eval_output = open(\"./output_eval/[split_\" + str(split_count) + \"][midi_with_anno][total\" + str(num_epochs) + \"_hs\" + str(hidden_size) +\"]save_\"+ str(loc_dt_format) + \"_l1_loss_\" + str(loss.cpu().item())+\".pkl\", 'wb')\n",
    "    pickle.dump(np.asarray(outputs_save), eval_output)\n",
    "    eval_output.close()\n",
    "    \n",
    "    # print(\"val counter:\", counter)\n",
    "    epoch_val_loss_f1 = valid_running_loss / counter\n",
    "    val_per_split_list.append(epoch_val_loss_f1)\n",
    "    print(\"split_count:\", split_count, \", epoch_val_loss:\", epoch_val_loss_f1)\n",
    "    os.remove(\"./temp_path.txt\")\n",
    "    return #epoch_val_loss_f1\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14342657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "random:  6\n",
      "------------fold no---------6----------------------\n",
      "train_idx: 0 ~ 10999  test_idx: 6000 ~ 6999\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=k_folds)\n",
    "print(kf.get_n_splits(dataset))\n",
    "KFold(n_splits=k_folds, random_state=None, shuffle=False)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     #...TODO\n",
    "split_count = 0\n",
    "random_pick_fold = 6#random.randint(0, 10) #0~10\n",
    "print(\"random: \", random_pick_fold)\n",
    "# for fold,(train_idx, test_idx) in enumerate(kf.split(dataset)): #TODO: random pick 1 fold\n",
    "for (train_idx, test_idx) in itertools.islice(kf.split(dataset), random_pick_fold, random_pick_fold+1):\n",
    "    # print('------------fold no---------{}----------------------'.format(fold))\n",
    "    print('------------fold no---------{}----------------------'.format(random_pick_fold))\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    print(\"train_idx:\", train_idx[0], \"~\", train_idx[-1], \" test_idx:\", test_idx[0], \"~\", test_idx[-1])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=batch_size_define, sampler=train_subsampler) #bs=40:4.49G, bs=128:14.65G\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=batch_size_define, sampler=val_subsampler)\n",
    "    \n",
    "    model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        losses = []\n",
    "        loss = 0\n",
    "        mean_loss = 0\n",
    "        for i, (midi_batch, motion_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            \n",
    "            midi_batch = midi_batch.to(device).float()\n",
    "            motion_batch = motion_batch.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(midi_batch) #midi_batch\n",
    "            # print(\"train inputs.shape:\", midi_batch.shape, torch.isnan(midi_batch).any())\n",
    "            # # print(motion_batch)\n",
    "            # print(\"train targets.shape:\", motion_batch.shape, torch.isnan(motion_batch).any())\n",
    "            # print(\"train outputs.shape:\", output.shape, torch.isnan(output).any())\n",
    "\n",
    "            loss =  F.mse_loss(output, motion_batch)\n",
    "            # loss = customized_mse_loss(output.cpu(), motion_batch.cpu())\n",
    "            # loss = customized_mse_loss(output, motion_batch)\n",
    "            \n",
    "            losses.append(loss.cpu().item()) #.cpu().item()\n",
    "            all_loss_list.append(loss.cpu().item()) #.cpu().item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\") #.cpu().item()\n",
    "\n",
    "        # print(losses, sum(losses), len(losses))\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "        # correct, total = 0, 0\n",
    "        valid_running_loss = 0.0\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (midi_test, motion_test) in enumerate(val_loader):\n",
    "                \n",
    "                inputs = midi_test.to(device).float()\n",
    "                targets = motion_test.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                # print(\"val inputs.shape:\", inputs.shape)\n",
    "                # print(\"val targets.shape:\", targets.shape)\n",
    "                # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "                val_loss =  customized_mse_loss(outputs, targets)\n",
    "                valid_running_loss += val_loss.cpu().item() #.cpu().item()\n",
    "                counter += 1\n",
    "            \n",
    "            epoch_val_loss = valid_running_loss / counter\n",
    "            # print(f\"Epoch {epoch}: val_loss = {epoch_val_loss:.6f}\") #.cpu().item()\n",
    "\n",
    "        avg_loss_list.append(mean_loss) #.cpu().item()\n",
    "        val_loss_per_epoch_list.append(epoch_val_loss) #.cpu().item()\n",
    "\n",
    "        cross_valid_results[0] = epoch_val_loss\n",
    "        \n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        if (epoch+1)%100 == 0:\n",
    "            torch.save({\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':model.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'loss':loss\n",
    "            },  \"./model_save/[midi_with_anno][total\"+str(num_epochs)+ \"_hs\" + str(hidden_size) +\"]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {1} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum_loss = 0.0\n",
    "    for key, value in cross_valid_results.items():\n",
    "        print(f'Fold loss {key}: {value}')\n",
    "        sum_loss += value\n",
    "    print(f'Average vaildation new loss: {sum_loss/len(cross_valid_results.items())}')\n",
    "    \n",
    "    # validation result save\n",
    "    evaluate_lstm_cross(model, split_count)\n",
    "    \n",
    "    split_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f00152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessed_data_save_cross/midi/vio01_Elgar_S1_T1_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Elgar_S1_T2_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Flower_S1_T1_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Flower_S1_T2_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mend_S1_T1_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mend_S1_T2_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mozart1_S1_T1_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mozart1_S1_T2_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mozart2_S1_T1_midi_data.pkl'\n",
      " 'preprocessed_data_save_cross/midi/vio01_Mozart2_S1_T2_midi_data.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(val_data_read[split_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e92038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     # previous_output = torch.zeros(1, 512, 102).to(device)\n",
    "#     losses = []\n",
    "#     for i, (midi_batch, motion_batch) in enumerate(dataloader):\n",
    "#         model.train()\n",
    "        \n",
    "#         midi_batch = midi_batch.to(device).float()\n",
    "#         motion_batch = motion_batch.to(device).float()\n",
    "#         # print(\"midi_batch\", midi_batch.shape)\n",
    "#         # print(\"motion_batch\", motion_batch.shape)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(midi_batch) #midi_batch\n",
    "#         # print(\"output.shape\", output.shape)\n",
    "\n",
    "#         # motion_ground_truth_padding = F.pad(motion_batch, (0,0,0,1), value = 1) #<eot>\n",
    "        \n",
    "#         # loss =  F.mse_loss(output, motion_ground_truth_padding)\n",
    "#         loss =  F.mse_loss(output, motion_batch)\n",
    "#         # loss = customized_mse_loss(output, motion_ground_truth_padding, previous_output, midi_batch)\n",
    "#         # loss = customized_mse_loss(output, motion_batch, previous_output, midi_batch)\n",
    "\n",
    "#         # losses 累計lose\n",
    "#         losses.append(loss.cpu().item())\n",
    "#         all_loss_list.append(loss.cpu().item())\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         mean_loss = sum(losses)/len(losses)\n",
    "\n",
    "#         print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\")\n",
    "\n",
    "#         # scheduler.step(1)\n",
    "#         # previous_output = output\n",
    "\n",
    "#         loc_dt = datetime.datetime.today()\n",
    "#         loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "#     val_loss = evaluate_lstm(model, val_dataloader) #CUDA out of memory\n",
    "#     val_loss_per_epoch_list.append(val_loss)\n",
    "#     print(f\"Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
    "#     # save_best_model(\n",
    "#     #         val_loss, epoch, model, optimizer, loss, loc_dt_format, mean_loss\n",
    "#     #     )\n",
    "#     avg_loss_list.append(mean_loss)\n",
    "#     loc_dt = datetime.datetime.today()\n",
    "#     loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "#     if (epoch+1)%100 == 0:\n",
    "#         torch.save({\n",
    "#             'epoch':epoch,\n",
    "#             'model_state_dict':model.state_dict(),\n",
    "#             'optimizer_state_dict':optimizer.state_dict(),\n",
    "#             'loss':loss\n",
    "#         }, \"./model_save/[100epoch]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16_18-38-43\n",
      "[0.025526684473454953, 0.021438634818047284, 0.020264124958217142, 0.019081735134869812, 0.01743884526565671, 0.015685390018671752, 0.014295653929561376, 0.012623493202775718, 0.011280078426003455, 0.0102624485950917, 0.009682570196315646, 0.008913288353383541, 0.00816170974522829, 0.007740649573504925, 0.007310469665378332, 0.006976729112118483, 0.006527277943119407, 0.006183842932060361, 0.005935565316863358, 0.0055380490280687806, 0.005467426296137274, 0.005208533887192607, 0.005055389522388577, 0.004903105737827719, 0.004688138371892274, 0.004553755823522806, 0.004560190168768167, 0.0044265774976462125, 0.004101523945853114, 0.004132438499480486, 0.003973922420293092, 0.0038474727565422653, 0.0037821531968191264, 0.00381648447457701, 0.003638867824152112, 0.003534855618700385, 0.003579819996468723, 0.003473992940224707, 0.003429808847792447, 0.0032432588896714153, 0.003161046942137182, 0.0032147486976347862, 0.00318135669156909, 0.003066716775391251, 0.0031665406187064947, 0.003115770749282092, 0.002981676558498293, 0.0028841471103951337, 0.003040067976247519, 0.0029812903880141674, 0.0030594845223240554, 0.0026817717640660703, 0.0027680306147783995, 0.002718672631494701, 0.002772178958542645, 0.0026852708760648964, 0.0027052652671933175, 0.0026907329695299268, 0.002579467513225973, 0.0025426072430796923, 0.002663091108575463, 0.0025553039694204928, 0.0027310646092519163, 0.002470170321688056, 0.002414193910267204, 0.0025646236072294415, 0.0024383937349542976, 0.0023763780171982946, 0.0026277500866912305, 0.002442002620175481, 0.002458136611711234, 0.002380366470851004, 0.0023347500164993106, 0.002426371343433857, 0.002319908611383289, 0.0023583419581875206, 0.00238733152449131, 0.00223173725605011, 0.0022508149809204042, 0.0022554740673862398, 0.002282076864410192, 0.009820053912978619, 0.011099696211144329, 0.009263392478600144, 0.015313733568042517, 0.014383371346443892, 0.013934677366167308, 0.013707724630832672, 0.013583195937424897, 0.01315729192495346, 0.012593798901885748, 0.011723705070838333, 0.010701995749399066, 0.009322654454782605, 0.008007698949798941, 0.00782285770252347, 0.02273351871073246, 0.02271312468200922, 0.022319427195191383, 0.022279819470644]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.022341934710741043, 0.020910342037677766, 0.019631483785808087, 0.01862015151977539, 0.016275945700705053, 0.015118395678699017, 0.012828099958598614, 0.01240102481842041, 0.011366632983088494, 0.009805982485413551, 0.00920858870819211, 0.008292627055197954, 0.007763177916407585, 0.007475253131240606, 0.007186812330037356, 0.0063507301732897755, 0.006273358691483736, 0.0057869298085570335, 0.005766898401081562, 0.005401843957602978, 0.005259246274828911, 0.005269725685939193, 0.0053703780155628916, 0.00490913138911128, 0.004485915476456284, 0.004410569660365581, 0.004305616008117795, 0.004601998321712017, 0.004062517644837498, 0.0038234246876090766, 0.004028193913400173, 0.0037956950198858976, 0.004205159224569798, 0.0035850541330873964, 0.0035687966123223304, 0.003352717252448201, 0.0037305692546069622, 0.003887275218963623, 0.003095590030774474, 0.0032597465347498655, 0.0030956838838756082, 0.003212474800646305, 0.0030333582889288664, 0.0029676340389996766, 0.0029525124710053207, 0.0032527816006913783, 0.0028865224746987225, 0.0028027958078309895, 0.003039105588570237, 0.0029855921352282167, 0.002784618870355189, 0.002724527477286756, 0.002747123175300658, 0.002648168670013547, 0.0029721663296222688, 0.002722920677624643, 0.0027006028797477485, 0.002681961313821375, 0.0026560552529990675, 0.0026155604468658567, 0.002737958449870348, 0.0023794124089181424, 0.002660483580082655, 0.0023389145666733386, 0.002339413964189589, 0.0024198439214378597, 0.002375063984654844, 0.0026285604424774647, 0.0025411876225844027, 0.0025998496236279605, 0.002361897409893572, 0.002399134530685842, 0.0023697421513497827, 0.002254900015890598, 0.0021493503609672187, 0.002458079637028277, 0.002171975312754512, 0.002309645477682352, 0.0025298471888527273, 0.0022843141509220006, 0.0022525758342817424, 0.0122551254555583, 0.0100394745208323, 0.009961959321051836, 0.014650956884026527, 0.014245613634586334, 0.013360624559223652, 0.013519111134111882, 0.013232785046100617, 0.012850272536277772, 0.012199897333979607, 0.011218270257115364, 0.009975740481168031, 0.008599374495446682, 0.007277594529092312, 0.00895716129615903, 0.02236464799940586, 0.02264164800941944, 0.022071224465966224, 0.022480432257056236]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d43dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_lambda(epoch):\n",
    "#     # LR to be 0.1 * (1/1+0.01*epoch)\n",
    "#     base_lr = 0.1\n",
    "#     factor = 0.01\n",
    "#     return base_lr/(1+factor*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ec087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137500\n",
      "137500\n",
      "137500\n"
     ]
    }
   ],
   "source": [
    "# val_time_loss_list\n",
    "# val_dim_loss_list\n",
    "# val_mse_loss_list\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_time_loss_list))\n",
    "val_time_loss_list_dataframe = pd.DataFrame(val_time_loss_list)\n",
    "plt.plot(np.array(val_time_loss_list_dataframe.index), np.array(val_time_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_time_loss_training.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_dim_loss_list))\n",
    "val_dim_loss_list_dataframe = pd.DataFrame(val_dim_loss_list)\n",
    "plt.plot(np.array(val_dim_loss_list_dataframe.index), np.array(val_dim_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_dim_loss_training.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "print(len(val_mse_loss_list))\n",
    "val_mse_loss_list_dataframe = pd.DataFrame(val_mse_loss_list)\n",
    "plt.plot(np.array(val_mse_loss_list_dataframe.index), np.array(val_mse_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_mse_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa7c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.022319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.022280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.025527\n",
       "1   0.021439\n",
       "2   0.020264\n",
       "3   0.019082\n",
       "4   0.017439\n",
       "..       ...\n",
       "95  0.007823\n",
       "96  0.022734\n",
       "97  0.022713\n",
       "98  0.022319\n",
       "99  0.022280\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51793ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch_list_dataframe = pd.DataFrame(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_loss_per_epoch_list_dataframe.index), np.array(val_loss_per_epoch_list_dataframe[0]))\n",
    "plt.savefig(\"training_val_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.mid\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.mid\n",
      "(8171, 128)\n",
      "str_name: ./BWV1001/vs1-2fug.mid\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.mid\n",
      "(11537, 128)\n",
      "str_name: ./BWV1001/vs1-3sic.mid\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.mid\n",
      "(6993, 128)\n",
      "str_name: ./BWV1001/vs1-4prs.mid\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.mid\n",
      "(7897, 128)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_midi_path_list = glob.glob(test_datapath + \"*.mid\")\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "for test_midi in test_midi_path_list:\n",
    "    str_name = test_midi\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_midi)\n",
    "    read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_piano_roll_transpose = read_piano_roll.T\n",
    "    print(read_piano_roll_transpose.shape)\n",
    "    test_midi_len = read_piano_roll_transpose.shape[0]\n",
    "    test_data_list.append(read_piano_roll_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 8171, 128)\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81600\n",
      "limit 800\n",
      "[[[ 0.04608331  0.1167841   1.10164711]\n",
      "  [-0.0151464   0.0730022   1.11921511]\n",
      "  [ 0.09651558  0.04537769  1.09833089]\n",
      "  ...\n",
      "  [-0.00760311  0.09581587  0.97720799]\n",
      "  [-0.1643984   0.04809755  1.09718714]\n",
      "  [ 0.04932656  0.25786132  0.78559515]]\n",
      "\n",
      " [[ 0.08576825  0.1224775   1.10904202]\n",
      "  [ 0.02419773  0.0740689   1.13121197]\n",
      "  [ 0.13740781  0.0521704   1.09650776]\n",
      "  ...\n",
      "  [ 0.03013687  0.08870668  0.98692862]\n",
      "  [-0.13628069  0.06812122  1.1067035 ]\n",
      "  [ 0.07719319  0.26611784  0.76942322]]\n",
      "\n",
      " [[ 0.07036386  0.12473609  1.10767565]\n",
      "  [ 0.00942712  0.07547254  1.12948403]\n",
      "  [ 0.12315369  0.05575526  1.09907523]\n",
      "  ...\n",
      "  [ 0.0176168   0.09106798  0.9877883 ]\n",
      "  [-0.12929502  0.09882499  1.09412066]\n",
      "  [ 0.07246154  0.24489112  0.72442762]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.09676237  0.07775354  1.09923462]\n",
      "  [ 0.02941067  0.04121839  1.10947118]\n",
      "  [ 0.1339785  -0.00221853  1.08689789]\n",
      "  ...\n",
      "  [ 0.03260297  0.06919285  0.99590377]\n",
      "  [-0.12682652  0.08395986  1.12819705]\n",
      "  [ 0.05436346  0.23447551  0.73112992]]\n",
      "\n",
      " [[ 0.09423058  0.07728456  1.09881935]\n",
      "  [ 0.02721356  0.04051212  1.10934124]\n",
      "  [ 0.1319823  -0.00223671  1.08740655]\n",
      "  ...\n",
      "  [ 0.03076366  0.06897456  0.99556193]\n",
      "  [-0.12642148  0.08736138  1.13039289]\n",
      "  [ 0.05191163  0.22836354  0.73065124]]\n",
      "\n",
      " [[ 0.09268555  0.07525068  1.09800384]\n",
      "  [ 0.0255759   0.03888191  1.10842142]\n",
      "  [ 0.13028875 -0.00398328  1.0870007 ]\n",
      "  ...\n",
      "  [ 0.03007288  0.06812693  0.99595658]\n",
      "  [-0.1242473   0.09130544  1.12891982]\n",
      "  [ 0.05192526  0.22406916  0.72623507]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-1ada.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-1ada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 200 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 196 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-1ada.wav':\n",
      "  Duration: 00:03:24.29, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55b5f7a3da80] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55b5f7a3da80] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55b5f7a3da80] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-1ada_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=377 q=-1.0 Lsize=    3706kB time=00:03:24.31 bitrate= 148.6kbits/s speed=96.3x    \n",
      "video:451kB audio:3202kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.425175%\n",
      "[aac @ 0x55b5f7a3c340] Qavg: 182.785\n",
      "[libx264 @ 0x55b5f7a3da80] frame I:4     Avg QP:16.63  size: 13742\n",
      "[libx264 @ 0x55b5f7a3da80] frame P:232   Avg QP:22.88  size:  1182\n",
      "[libx264 @ 0x55b5f7a3da80] frame B:564   Avg QP:26.81  size:   235\n",
      "[libx264 @ 0x55b5f7a3da80] consecutive B-frames:  3.5%  5.8%  5.2% 85.5%\n",
      "[libx264 @ 0x55b5f7a3da80] mb I  I16..4: 28.5% 46.8% 24.7%\n",
      "[libx264 @ 0x55b5f7a3da80] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.2%  1.7%  1.8%  0.0%  0.0%    skip:95.2%\n",
      "[libx264 @ 0x55b5f7a3da80] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.8%  1.3%  0.5%  direct: 0.2%  skip:96.1%  L0:42.0% L1:44.4% BI:13.6%\n",
      "[libx264 @ 0x55b5f7a3da80] 8x8 transform intra:47.0% inter:25.3%\n",
      "[libx264 @ 0x55b5f7a3da80] coded y,uvDC,uvAC intra: 18.6% 1.7% 1.4% inter: 1.0% 0.3% 0.3%\n",
      "[libx264 @ 0x55b5f7a3da80] i16 v,h,dc,p: 81%  6% 13%  0%\n",
      "[libx264 @ 0x55b5f7a3da80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  6% 50%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55b5f7a3da80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  1%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55b5f7a3da80] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55b5f7a3da80] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55b5f7a3da80] ref P L0: 65.3% 10.1% 14.3% 10.4%\n",
      "[libx264 @ 0x55b5f7a3da80] ref B L0: 79.4% 16.1%  4.4%\n",
      "[libx264 @ 0x55b5f7a3da80] ref B L1: 92.2%  7.8%\n",
      "[libx264 @ 0x55b5f7a3da80] kb/s:184.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 11537, 128)\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.07508775  0.13088913  1.10047219]\n",
      "  [ 0.01090216  0.09086278  1.11430809]\n",
      "  [ 0.11947788  0.06012221  1.09062425]\n",
      "  ...\n",
      "  [ 0.0127918   0.10670968  0.97393612]\n",
      "  [-0.10701201  0.12522727  1.0990626 ]\n",
      "  [ 0.07286277  0.23009019  0.73992953]]\n",
      "\n",
      " [[ 0.08226182  0.13491943  1.10330889]\n",
      "  [ 0.01580905  0.09698866  1.12143896]\n",
      "  [ 0.1237951   0.06088534  1.0940331 ]\n",
      "  ...\n",
      "  [ 0.01393485  0.10994909  0.9773765 ]\n",
      "  [-0.10486686  0.13716109  1.10295079]\n",
      "  [ 0.07497131  0.24764559  0.76336608]]\n",
      "\n",
      " [[ 0.07067692  0.12041865  1.10004756]\n",
      "  [ 0.00578058  0.0803166   1.1142765 ]\n",
      "  [ 0.1130528   0.04743789  1.08638308]\n",
      "  ...\n",
      "  [ 0.00443767  0.10050353  0.97392026]\n",
      "  [-0.11651404  0.12973592  1.11604772]\n",
      "  [ 0.04366957  0.21513358  0.74396149]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.09990516  0.07075714  1.09871296]\n",
      "  [ 0.03889967  0.03023637  1.10899673]\n",
      "  [ 0.14509241 -0.00514737  1.07984564]\n",
      "  ...\n",
      "  [ 0.03913146  0.08269218  0.99346296]\n",
      "  [-0.11044298  0.08536147  1.05777065]\n",
      "  [ 0.06440771  0.22272782  0.69165746]]\n",
      "\n",
      " [[ 0.10088319  0.0702124   1.09839431]\n",
      "  [ 0.03936806  0.02983783  1.109642  ]\n",
      "  [ 0.14552124 -0.00663401  1.08012882]\n",
      "  ...\n",
      "  [ 0.03939053  0.0820341   0.99405358]\n",
      "  [-0.11003707  0.08798171  1.05825863]\n",
      "  [ 0.06590799  0.22549483  0.68892518]]\n",
      "\n",
      " [[ 0.10097096  0.07313495  1.09807131]\n",
      "  [ 0.0393888   0.0318489   1.10978851]\n",
      "  [ 0.14595501 -0.00350534  1.07927415]\n",
      "  ...\n",
      "  [ 0.03918422  0.08372559  0.99073318]\n",
      "  [-0.11210098  0.08245781  1.05462793]\n",
      "  [ 0.06974236  0.23446791  0.6941183 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-2fug.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-2fug.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 203 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 199 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-2fug.wav':\n",
      "  Duration: 00:04:48.34, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55886bdab780] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55886bdab780] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55886bdab780] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-2fug_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=306 q=-1.0 Lsize=    5040kB time=00:04:48.34 bitrate= 143.2kbits/s speed= 110x    \n",
      "video:456kB audio:4518kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.334020%\n",
      "[aac @ 0x55886bdaa040] Qavg: 260.041\n",
      "[libx264 @ 0x55886bdab780] frame I:4     Avg QP:16.31  size: 13760\n",
      "[libx264 @ 0x55886bdab780] frame P:215   Avg QP:23.13  size:  1269\n",
      "[libx264 @ 0x55886bdab780] frame B:581   Avg QP:27.49  size:   237\n",
      "[libx264 @ 0x55886bdab780] consecutive B-frames:  1.1%  4.8%  4.1% 90.0%\n",
      "[libx264 @ 0x55886bdab780] mb I  I16..4: 30.1% 45.5% 24.4%\n",
      "[libx264 @ 0x55886bdab780] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.1%  1.8%  2.0%  0.0%  0.0%    skip:95.1%\n",
      "[libx264 @ 0x55886bdab780] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.9%  1.3%  0.6%  direct: 0.2%  skip:96.0%  L0:42.3% L1:44.2% BI:13.5%\n",
      "[libx264 @ 0x55886bdab780] 8x8 transform intra:45.1% inter:25.9%\n",
      "[libx264 @ 0x55886bdab780] coded y,uvDC,uvAC intra: 18.7% 1.7% 1.4% inter: 1.0% 0.4% 0.3%\n",
      "[libx264 @ 0x55886bdab780] i16 v,h,dc,p: 81%  7% 12%  0%\n",
      "[libx264 @ 0x55886bdab780] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  8% 49%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55886bdab780] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  1%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55886bdab780] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55886bdab780] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55886bdab780] ref P L0: 61.9%  9.8% 15.9% 12.4%\n",
      "[libx264 @ 0x55886bdab780] ref B L0: 82.8% 13.5%  3.7%\n",
      "[libx264 @ 0x55886bdab780] ref B L1: 92.8%  7.2%\n",
      "[libx264 @ 0x55886bdab780] kb/s:186.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 6993, 128)\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.1044201   0.17592053  1.10376093]\n",
      "  [ 0.03722346  0.13344555  1.13172159]\n",
      "  [ 0.14982808  0.09909627  1.10685501]\n",
      "  ...\n",
      "  [ 0.0391663   0.14051057  0.99219093]\n",
      "  [-0.09072986  0.11124396  1.02348856]\n",
      "  [ 0.15362975  0.36143491  0.81055055]]\n",
      "\n",
      " [[ 0.11235473  0.16795504  1.09472082]\n",
      "  [ 0.05028177  0.12139267  1.1272541 ]\n",
      "  [ 0.16379173  0.0955549   1.09469376]\n",
      "  ...\n",
      "  [ 0.05020171  0.12856747  0.99026225]\n",
      "  [-0.117415    0.02506015  1.04541603]\n",
      "  [ 0.14425641  0.38330576  0.84354923]]\n",
      "\n",
      " [[ 0.1118716   0.15891474  1.10122273]\n",
      "  [ 0.04832573  0.11365109  1.13225636]\n",
      "  [ 0.16126341  0.08649229  1.09679536]\n",
      "  ...\n",
      "  [ 0.05112337  0.12411559  0.9923381 ]\n",
      "  [-0.10377575  0.04663143  1.04415307]\n",
      "  [ 0.15198116  0.36929452  0.83008138]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.1039569   0.10449362  1.10172627]\n",
      "  [ 0.04034858  0.0603335   1.11633537]\n",
      "  [ 0.14994669  0.02869225  1.08611271]\n",
      "  ...\n",
      "  [ 0.04387468  0.08682756  0.98989967]\n",
      "  [-0.12572308  0.03802061  1.07381461]\n",
      "  [ 0.09740232  0.3009949   0.74849806]]\n",
      "\n",
      " [[ 0.10517286  0.10077741  1.10165284]\n",
      "  [ 0.04177163  0.05630533  1.1155828 ]\n",
      "  [ 0.15139464  0.02504008  1.0839552 ]\n",
      "  ...\n",
      "  [ 0.0451168   0.08337979  0.98986695]\n",
      "  [-0.12490761  0.03580884  1.07191823]\n",
      "  [ 0.10005597  0.30185908  0.74530218]]\n",
      "\n",
      " [[ 0.10441837  0.10429645  1.10158918]\n",
      "  [ 0.04086377  0.06020188  1.11627159]\n",
      "  [ 0.15053084  0.0285718   1.08525649]\n",
      "  ...\n",
      "  [ 0.04395893  0.0851011   0.9915295 ]\n",
      "  [-0.12882487  0.03421339  1.07400463]\n",
      "  [ 0.09774897  0.30286217  0.75248072]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-3sic.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-3sic.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 195 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 191 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-3sic.wav':\n",
      "  Duration: 00:02:54.71, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x558b9f596880] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x558b9f596880] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x558b9f596880] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-3sic_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=423 q=-1.0 Lsize=    3227kB time=00:02:54.73 bitrate= 151.3kbits/s speed=92.3x    \n",
      "video:441kB audio:2739kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.482713%\n",
      "[aac @ 0x558b9f595140] Qavg: 180.446\n",
      "[libx264 @ 0x558b9f596880] frame I:4     Avg QP:16.05  size: 13862\n",
      "[libx264 @ 0x558b9f596880] frame P:243   Avg QP:22.76  size:  1145\n",
      "[libx264 @ 0x558b9f596880] frame B:553   Avg QP:25.91  size:   212\n",
      "[libx264 @ 0x558b9f596880] consecutive B-frames:  3.0% 12.8%  5.2% 79.0%\n",
      "[libx264 @ 0x558b9f596880] mb I  I16..4: 27.7% 48.1% 24.2%\n",
      "[libx264 @ 0x558b9f596880] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.1%  1.6%  1.7%  0.0%  0.0%    skip:95.5%\n",
      "[libx264 @ 0x558b9f596880] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.6%  1.1%  0.4%  direct: 0.2%  skip:96.6%  L0:38.7% L1:46.1% BI:15.3%\n",
      "[libx264 @ 0x558b9f596880] 8x8 transform intra:47.0% inter:24.9%\n",
      "[libx264 @ 0x558b9f596880] coded y,uvDC,uvAC intra: 18.7% 2.0% 1.6% inter: 0.9% 0.3% 0.3%\n",
      "[libx264 @ 0x558b9f596880] i16 v,h,dc,p: 78%  8% 14%  0%\n",
      "[libx264 @ 0x558b9f596880] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45%  9% 45%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x558b9f596880] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 32%  7%  1%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x558b9f596880] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x558b9f596880] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x558b9f596880] ref P L0: 67.4% 10.6% 12.9%  9.1%\n",
      "[libx264 @ 0x558b9f596880] ref B L0: 84.9% 11.9%  3.2%\n",
      "[libx264 @ 0x558b9f596880] ref B L1: 93.6%  6.4%\n",
      "[libx264 @ 0x558b9f596880] kb/s:180.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 7897, 128)\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.03183889  0.1168597   1.09480426]\n",
      "  [-0.02952962  0.06953974  1.09973345]\n",
      "  [ 0.08176862  0.04932889  1.09033278]\n",
      "  ...\n",
      "  [-0.01527811  0.09896485  0.96964375]\n",
      "  [-0.13767098  0.12277949  1.0968558 ]\n",
      "  [ 0.04791737  0.20844783  0.69402752]]\n",
      "\n",
      " [[ 0.03085961  0.11913134  1.09537247]\n",
      "  [-0.03139793  0.0717925   1.10751114]\n",
      "  [ 0.07934302  0.050273    1.09193168]\n",
      "  ...\n",
      "  [-0.01804188  0.09878024  0.97573069]\n",
      "  [-0.15912628  0.09366146  1.09787569]\n",
      "  [ 0.0472342   0.23191261  0.72480217]]\n",
      "\n",
      " [[ 0.04217217  0.12353969  1.09874079]\n",
      "  [-0.02082746  0.07724442  1.11377213]\n",
      "  [ 0.09062084  0.053068    1.09531078]\n",
      "  ...\n",
      "  [-0.00743481  0.0952541   0.98210779]\n",
      "  [-0.16332607  0.07668456  1.09162406]\n",
      "  [ 0.05741994  0.26324829  0.73981438]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.07227337  0.10824782  1.10164354]\n",
      "  [ 0.00916799  0.06725591  1.11419616]\n",
      "  [ 0.11764236  0.03474269  1.08783684]\n",
      "  ...\n",
      "  [ 0.01403208  0.08955454  0.99288807]\n",
      "  [-0.15160002  0.08363874  1.10510037]\n",
      "  [ 0.04070687  0.23618259  0.73096374]]\n",
      "\n",
      " [[ 0.07328244  0.10925093  1.1011512 ]\n",
      "  [ 0.00990997  0.06909493  1.11446235]\n",
      "  [ 0.11823794  0.03552591  1.0882437 ]\n",
      "  ...\n",
      "  [ 0.01414607  0.08941969  0.99568096]\n",
      "  [-0.15589708  0.08230013  1.10576496]\n",
      "  [ 0.03910126  0.24115317  0.73838059]]\n",
      "\n",
      " [[ 0.07448795  0.10888133  1.10096059]\n",
      "  [ 0.01103202  0.06895459  1.1144999 ]\n",
      "  [ 0.11915821  0.03471419  1.08851538]\n",
      "  ...\n",
      "  [ 0.01461475  0.08999401  0.99566207]\n",
      "  [-0.15509976  0.07921147  1.10352299]\n",
      "  [ 0.04061045  0.2453462   0.74346981]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-4prs.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-4prs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 208 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 203 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-4prs.wav':\n",
      "  Duration: 00:03:17.43, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x56225966aac0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x56225966aac0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x56225966aac0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-4prs_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=402 q=-1.0 Lsize=    3609kB time=00:03:17.43 bitrate= 149.7kbits/s speed=99.1x    \n",
      "video:463kB audio:3095kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.435992%\n",
      "[aac @ 0x562259669380] Qavg: 188.133\n",
      "[libx264 @ 0x56225966aac0] frame I:4     Avg QP:16.10  size: 13775\n",
      "[libx264 @ 0x56225966aac0] frame P:208   Avg QP:23.13  size:  1247\n",
      "[libx264 @ 0x56225966aac0] frame B:588   Avg QP:28.86  size:   269\n",
      "[libx264 @ 0x56225966aac0] consecutive B-frames:  0.6%  3.2%  2.6% 93.5%\n",
      "[libx264 @ 0x56225966aac0] mb I  I16..4: 28.7% 46.7% 24.6%\n",
      "[libx264 @ 0x56225966aac0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.1%  1.8%  2.0%  0.0%  0.0%    skip:95.0%\n",
      "[libx264 @ 0x56225966aac0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.9%  1.5%  0.7%  direct: 0.2%  skip:95.7%  L0:43.7% L1:43.7% BI:12.6%\n",
      "[libx264 @ 0x56225966aac0] 8x8 transform intra:47.2% inter:26.7%\n",
      "[libx264 @ 0x56225966aac0] coded y,uvDC,uvAC intra: 18.3% 1.6% 1.4% inter: 1.0% 0.4% 0.3%\n",
      "[libx264 @ 0x56225966aac0] i16 v,h,dc,p: 81%  6% 12%  0%\n",
      "[libx264 @ 0x56225966aac0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  6% 50%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x56225966aac0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  1%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x56225966aac0] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x56225966aac0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x56225966aac0] ref P L0: 53.4%  7.6% 18.7% 20.3%\n",
      "[libx264 @ 0x56225966aac0] ref B L0: 79.2% 15.0%  5.7%\n",
      "[libx264 @ 0x56225966aac0] ref B L1: 91.8%  8.2%\n",
      "[libx264 @ 0x56225966aac0] kb/s:189.19\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8171, 115])\n",
      "test_input (1, 8171, 128)\n",
      "test_target torch.Size([1, 8171, 115])\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n",
      "torch.Size([11537, 115])\n",
      "test_input (1, 11537, 128)\n",
      "test_target torch.Size([1, 11537, 115])\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "torch.Size([6993, 115])\n",
      "test_input (1, 6993, 128)\n",
      "test_target torch.Size([1, 6993, 115])\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "torch.Size([7897, 115])\n",
      "test_input (1, 7897, 128)\n",
      "test_target torch.Size([1, 7897, 115])\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],115)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/'):\n",
    "            os.makedirs('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/')\n",
    "        midi_data_output = open('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/prediction_'+\n",
    "                                filecode +'.pkl', 'wb')\n",
    "        pickle.dump(prediction_arr, midi_data_output)\n",
    "        midi_data_output.close()\n",
    "        \n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_val_loss = evaluate_lstm(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee221509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
