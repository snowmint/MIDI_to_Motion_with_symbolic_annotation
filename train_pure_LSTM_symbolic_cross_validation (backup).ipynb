{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "self.piece_count:  110\n",
      "dataset_len:  11000\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"./midi_list_symbolic_cross.txt\" #f\"./midi_list.txt\"\n",
    "dataloader = get_dataloader(dataset_name_path, batch_size=8) #[20, 512, 128], [20, 512, 102]\n",
    "dataset = MidiMotionDataSet(dataset_name_path)\n",
    "\n",
    "val_dataset_name_path = f\"./midi_list_symbolic_cross.txt\" #f\"./midi_list_eval.txt\"\n",
    "# val_dataloader = get_val_dataloader(val_dataset_name_path, batch_size=40) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "full_data_path = None\n",
    "with open(\"./midi_list_symbolic_cross.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file]\n",
    "    full_data_path = np.array(lines)\n",
    "\n",
    "val_data_read = np.reshape(full_data_path, (11, 10))\n",
    "# print(val_data_read)\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "# input_size_encoder = 128 #129 #128\n",
    "# input_size_decoder = 115 #102 #24\n",
    "# output_size = 115#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2912b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model): # reset the weight every fold\n",
    "    if isinstance(model, nn.LSTM) or isinstance(model, nn.Linear):\n",
    "        model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 128 #number of features\n",
    "hidden_size = 1024 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 115 #number of output classes\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "# model.train()\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 100 #10\n",
    "k_folds = 11\n",
    "cross_valid_results = {}\n",
    "torch.manual_seed(42)\n",
    "\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []\n",
    "\n",
    "#TODO: important cross val record\n",
    "val_time_loss_list = []\n",
    "val_dim_loss_list = []\n",
    "val_mse_loss_list = []\n",
    "val_per_split_list = [] #just mse loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df5bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate time-wise loss for motion (along the time axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: time loss\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    preds = preds + epsilon\n",
    "\n",
    "    labels_transpose = torch.permute(labels, (0, 2, 1))#tf.transpose(labels, [0, 2, 1]) # [b, 3, t]\n",
    "    preds_transpose = torch.permute(preds, (0, 2, 1))#tf.transpose(preds, [0, 2, 1]) # [b, 3, t]\n",
    "    # print(\"labels_transpose.shape\", labels_transpose.shape)\n",
    "    # print(\"preds_transpose.shape\", preds_transpose.shape)\n",
    "    # print(\"labels_transpose[:, :, :, None].shape\", labels_transpose[:, :, :, None].shape)\n",
    "    # print(\"labels_transpose[:, :, None, :].shape\", labels_transpose[:, :, None, :].shape)\n",
    "    label_diff = labels_transpose[:, :, :, None] - labels_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    \n",
    "    preds_diff = preds_transpose[:, :, :, None] - preds_transpose [:, :, None, :] # [b, 3, t, t]\n",
    "    # print(preds_diff.shape)\n",
    "    time_loss = (preds_diff - label_diff)**2 # [b, 3, t, t]\n",
    "    time_loss_value = time_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return time_loss_value\n",
    "    \n",
    "def dim_wise_loss_fn(preds, labels):\n",
    "    '''\n",
    "    calculate dimension-wise loss for motion (along the dimension axis)\n",
    "    input: labels[batch, time, dimension(joint*xyz)]\n",
    "    preds[batch, time , dimension(joint*xyz)]\n",
    "    output: dimension loss\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    preds = preds + epsilon\n",
    "    \n",
    "    label_diff = labels[:, :, :, None] - labels[:, :, None, :] # [b, t, 3, 3]\n",
    "    preds_diff = preds[:, :, :, None] - preds[:, :, None, :] # [b, t, 3, 3]\n",
    "    dim_loss = (preds_diff - label_diff)**2 # [b, t, 3, 3]\n",
    "    dim_loss_value = dim_loss.mean() #float()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return dim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target):\n",
    "    # target = target.transpose(0, 1)\n",
    "\n",
    "    # print(\"output.shape:\", output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(\"target.shape:\", target.shape) #torch.Size([20, 513, 102])\n",
    "\n",
    "    w1_time = 0.3\n",
    "    w2_dim = 0.3\n",
    "    w3_mse = 0.4\n",
    "\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    time_loss = time_wise_loss_fn(output, target)\n",
    "    dim_loss = dim_wise_loss_fn(output, target)\n",
    "\n",
    "    # print(\"time_loss:\", time_loss)\n",
    "    # print(\"dim_loss:\", dim_loss)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "    val_time_loss_list.append(time_loss.cpu().item())\n",
    "    val_dim_loss_list.append(dim_loss.cpu().item())\n",
    "    val_mse_loss_list.append(mse_loss.cpu().item())\n",
    "\n",
    "    segment_loss = (w1_time * time_loss) + (w2_dim * dim_loss) + (w3_mse * mse_loss)\n",
    "    torch.cuda.empty_cache()\n",
    "    return  segment_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_cross(model, split_count):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    \n",
    "    outputs_save = []\n",
    "    \n",
    "    np.savetxt('./temp_path.txt', val_data_read[split_count], delimiter=\"\\n\", fmt=\"%s\")\n",
    "    # print(val_data_read[split_count])\n",
    "    val_dataloader = get_val_dataloader('./temp_path.txt', batch_size=11)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            # print(\"val inputs.shape:\", inputs.shape)\n",
    "            # print(\"val targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "            outputs_save.append(np.asarray(outputs.cpu()))\n",
    "\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if not os.path.exists(\"./output_eval/\"):\n",
    "        os.makedirs('./output_eval/')\n",
    "\n",
    "    # print(\"counter\", counter)\n",
    "    # print(\"val_data_read[split_count][counter]\", val_data_read[split_count][counter])\n",
    "    val_file_name = val_data_read[split_count][counter].split('/')[2].split('.')[0]\n",
    "\n",
    "    # print(\"val file_name:\", val_file_name)\n",
    "    # print(\"outputs_save length: \", len(outputs_save), \", element shape: \" , outputs_save[0].shape)\n",
    "        \n",
    "    eval_output = open(\"./output_eval/[split_\" + str(split_count) + \"][midi_with_anno][total\" + str(num_epochs) + \"_hs\" + str(hidden_size) +\"]save_\"+ str(loc_dt_format) + \"_l1_loss_\" + str(loss.cpu().item())+\".pkl\", 'wb')\n",
    "    pickle.dump(np.asarray(outputs_save), eval_output)\n",
    "    eval_output.close()\n",
    "    \n",
    "    # print(\"val counter:\", counter)\n",
    "    epoch_val_loss_f1 = valid_running_loss / counter\n",
    "    val_per_split_list.append(epoch_val_loss_f1)\n",
    "    print(\"split_count:\", split_count, \", epoch_val_loss:\", epoch_val_loss_f1)\n",
    "    os.remove(\"./temp_path.txt\")\n",
    "    return #epoch_val_loss_f1\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14342657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "random:  4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142736/2139084907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_pick_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# for fold,(train_idx, test_idx) in enumerate(kf.split(dataset)): #TODO: random pick 1 fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_pick_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# print('------------fold no---------{}----------------------'.format(fold))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------fold no---------{}----------------------'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_pick_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=k_folds)\n",
    "print(kf.get_n_splits(dataset))\n",
    "KFold(n_splits=k_folds, random_state=None, shuffle=False)\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     #...TODO\n",
    "split_count = 0\n",
    "random_pick_fold = random.randint(0, 10) #0~10\n",
    "print(\"random: \", random_pick_fold)\n",
    "for fold,(train_idx, test_idx) in enumerate(kf.split(dataset)): #TODO: random pick 1 fold\n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    print(\"train_idx:\", train_idx[0], \"~\", train_idx[-1], \" test_idx:\", test_idx[0], \"~\", test_idx[-1])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=8, sampler=train_subsampler) #bs=40:4.49G, bs=128:14.65G\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "                        dataset,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False,\n",
    "                        batch_size=8, sampler=val_subsampler)\n",
    "    \n",
    "    model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        losses = []\n",
    "        loss = 0\n",
    "        mean_loss = 0\n",
    "        for i, (midi_batch, motion_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            \n",
    "            midi_batch = midi_batch.to(device).float()\n",
    "            motion_batch = motion_batch.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(midi_batch) #midi_batch\n",
    "            # print(\"train inputs.shape:\", midi_batch.shape, torch.isnan(midi_batch).any())\n",
    "            # # print(motion_batch)\n",
    "            # print(\"train targets.shape:\", motion_batch.shape, torch.isnan(motion_batch).any())\n",
    "            # print(\"train outputs.shape:\", output.shape, torch.isnan(output).any())\n",
    "\n",
    "            # loss =  F.mse_loss(output, motion_batch)\n",
    "            # loss = customized_mse_loss(output.cpu(), motion_batch.cpu())\n",
    "            loss = customized_mse_loss(output, motion_batch)\n",
    "            \n",
    "            losses.append(loss.cpu().item()) #.cpu().item()\n",
    "            all_loss_list.append(loss.cpu().item()) #.cpu().item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\") #.cpu().item()\n",
    "\n",
    "        # print(losses, sum(losses), len(losses))\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "        # correct, total = 0, 0\n",
    "        valid_running_loss = 0.0\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (midi_test, motion_test) in enumerate(val_loader):\n",
    "                \n",
    "                inputs = midi_test.to(device).float()\n",
    "                targets = motion_test.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                # print(\"val inputs.shape:\", inputs.shape)\n",
    "                # print(\"val targets.shape:\", targets.shape)\n",
    "                # print(\"val outputs.shape:\", outputs.shape)\n",
    "\n",
    "                val_loss =  customized_mse_loss(outputs, targets)\n",
    "                valid_running_loss += val_loss.cpu().item() #.cpu().item()\n",
    "                counter += 1\n",
    "            \n",
    "            epoch_val_loss = valid_running_loss / counter\n",
    "            # print(f\"Epoch {epoch}: val_loss = {epoch_val_loss:.6f}\") #.cpu().item()\n",
    "\n",
    "        avg_loss_list.append(mean_loss) #.cpu().item()\n",
    "        val_loss_per_epoch_list.append(epoch_val_loss) #.cpu().item()\n",
    "\n",
    "        cross_valid_results[fold] = epoch_val_loss\n",
    "        \n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        if (epoch+1)%100 == 0:\n",
    "            torch.save({\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':model.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'loss':loss\n",
    "            },  \"./model_save/[midi_with_anno][total\"+str(num_epochs)+ \"_hs\" + str(hidden_size) +\"]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum_loss = 0.0\n",
    "    for key, value in cross_valid_results.items():\n",
    "        print(f'Fold loss {key}: {value}')\n",
    "        sum_loss += value\n",
    "    print(f'Average vaildation new loss: {sum_loss/len(cross_valid_results.items())}')\n",
    "    \n",
    "    # validation result save\n",
    "    evaluate_lstm_cross(model, split_count)\n",
    "    \n",
    "    split_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e92038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     # previous_output = torch.zeros(1, 512, 102).to(device)\n",
    "#     losses = []\n",
    "#     for i, (midi_batch, motion_batch) in enumerate(dataloader):\n",
    "#         model.train()\n",
    "        \n",
    "#         midi_batch = midi_batch.to(device).float()\n",
    "#         motion_batch = motion_batch.to(device).float()\n",
    "#         # print(\"midi_batch\", midi_batch.shape)\n",
    "#         # print(\"motion_batch\", motion_batch.shape)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(midi_batch) #midi_batch\n",
    "#         # print(\"output.shape\", output.shape)\n",
    "\n",
    "#         # motion_ground_truth_padding = F.pad(motion_batch, (0,0,0,1), value = 1) #<eot>\n",
    "        \n",
    "#         # loss =  F.mse_loss(output, motion_ground_truth_padding)\n",
    "#         loss =  F.mse_loss(output, motion_batch)\n",
    "#         # loss = customized_mse_loss(output, motion_ground_truth_padding, previous_output, midi_batch)\n",
    "#         # loss = customized_mse_loss(output, motion_batch, previous_output, midi_batch)\n",
    "\n",
    "#         # losses 累計lose\n",
    "#         losses.append(loss.cpu().item())\n",
    "#         all_loss_list.append(loss.cpu().item())\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         mean_loss = sum(losses)/len(losses)\n",
    "\n",
    "#         print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\")\n",
    "\n",
    "#         # scheduler.step(1)\n",
    "#         # previous_output = output\n",
    "\n",
    "#         loc_dt = datetime.datetime.today()\n",
    "#         loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "#     val_loss = evaluate_lstm(model, val_dataloader) #CUDA out of memory\n",
    "#     val_loss_per_epoch_list.append(val_loss)\n",
    "#     print(f\"Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
    "#     # save_best_model(\n",
    "#     #         val_loss, epoch, model, optimizer, loss, loc_dt_format, mean_loss\n",
    "#     #     )\n",
    "#     avg_loss_list.append(mean_loss)\n",
    "#     loc_dt = datetime.datetime.today()\n",
    "#     loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "#     if (epoch+1)%100 == 0:\n",
    "#         torch.save({\n",
    "#             'epoch':epoch,\n",
    "#             'model_state_dict':model.state_dict(),\n",
    "#             'optimizer_state_dict':optimizer.state_dict(),\n",
    "#             'loss':loss\n",
    "#         }, \"./model_save/[100epoch]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14_16-33-14\n",
      "[0.028956809107214213, 0.02900429619476199, 0.029244605258107185, 0.028834903914481402, 0.029323842100799084, 0.029359927907586097, 0.028954434435814618, 0.029166191596537827, 0.029162976112216712, 0.028837952252477407, 0.029094887372106314]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.022863045521080493, 0.022591257356107234, 0.02265377711504698, 0.02310947358608246, 0.022645045630633832, 0.022554774172604083, 0.022957211136817934, 0.022894382737576963, 0.02252921000123024, 0.023516938537359238, 0.02348352946341038]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d43dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_lambda(epoch):\n",
    "#     # LR to be 0.1 * (1/1+0.01*epoch)\n",
    "#     base_lr = 0.1\n",
    "#     factor = 0.01\n",
    "#     return base_lr/(1+factor*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.029360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.028954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.029166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.028838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.029095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.028957\n",
       "1   0.029004\n",
       "2   0.029245\n",
       "3   0.028835\n",
       "4   0.029324\n",
       "5   0.029360\n",
       "6   0.028954\n",
       "7   0.029166\n",
       "8   0.029163\n",
       "9   0.028838\n",
       "10  0.029095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51793ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch_list_dataframe = pd.DataFrame(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_loss_per_epoch_list_dataframe.index), np.array(val_loss_per_epoch_list_dataframe[0]))\n",
    "plt.savefig(\"training_val_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.mid\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.mid\n",
      "(8171, 128)\n",
      "str_name: ./BWV1001/vs1-2fug.mid\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.mid\n",
      "(11537, 128)\n",
      "str_name: ./BWV1001/vs1-3sic.mid\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.mid\n",
      "(6993, 128)\n",
      "str_name: ./BWV1001/vs1-4prs.mid\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.mid\n",
      "(7897, 128)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_midi_path_list = glob.glob(test_datapath + \"*.mid\")\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "for test_midi in test_midi_path_list:\n",
    "    str_name = test_midi\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_midi)\n",
    "    read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_piano_roll_transpose = read_piano_roll.T\n",
    "    print(read_piano_roll_transpose.shape)\n",
    "    test_midi_len = read_piano_roll_transpose.shape[0]\n",
    "    test_data_list.append(read_piano_roll_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 8171, 128)\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81600\n",
      "limit 800\n",
      "[[[ 0.01066413  0.08593887  0.60282156]\n",
      "  [-0.01280998 -0.00583635  0.61125532]\n",
      "  [ 0.04083589  0.00393716  0.59273705]\n",
      "  ...\n",
      "  [-0.03701151  0.01846465  0.55291889]\n",
      "  [-0.10076261 -0.01230686  0.6193606 ]\n",
      "  [ 0.01776977  0.15142721  0.46714631]]\n",
      "\n",
      " [[ 0.03879211  0.14804189  1.0754324 ]\n",
      "  [-0.00892204  0.04889368  1.09128056]\n",
      "  [ 0.09629098  0.02398731  1.06272302]\n",
      "  ...\n",
      "  [-0.02065109  0.07489548  0.97945682]\n",
      "  [-0.16371697  0.03421995  1.0937458 ]\n",
      "  [ 0.0439385   0.28116199  0.78792391]]\n",
      "\n",
      " [[ 0.07446319  0.14656338  1.23176453]\n",
      "  [ 0.01926645  0.10105406  1.24883649]\n",
      "  [ 0.14248177  0.05786384  1.22012243]\n",
      "  ...\n",
      "  [ 0.01223802  0.11877581  1.10784171]\n",
      "  [-0.16243598  0.07758166  1.2417346 ]\n",
      "  [ 0.07986818  0.30376053  0.86332349]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.08605392  0.12892547  1.09026489]\n",
      "  [ 0.01502454  0.07597429  1.11031756]\n",
      "  [ 0.12479843  0.05232498  1.09718392]\n",
      "  ...\n",
      "  [ 0.02310273  0.09360582  0.98372654]\n",
      "  [-0.12351809  0.08709976  1.10302112]\n",
      "  [ 0.09554765  0.25461343  0.73918078]]\n",
      "\n",
      " [[ 0.08603416  0.12892033  1.09026978]\n",
      "  [ 0.01501235  0.07596166  1.11031947]\n",
      "  [ 0.12478679  0.05231085  1.09718732]\n",
      "  ...\n",
      "  [ 0.02309683  0.09359702  0.98373041]\n",
      "  [-0.12352684  0.08711229  1.10304592]\n",
      "  [ 0.09552491  0.25458014  0.73917965]]\n",
      "\n",
      " [[ 0.08602062  0.12891422  1.09027538]\n",
      "  [ 0.01500199  0.07595643  1.11031995]\n",
      "  [ 0.12477796  0.05230277  1.09718738]\n",
      "  ...\n",
      "  [ 0.02309411  0.09359143  0.98373184]\n",
      "  [-0.12353045  0.08712455  1.10306714]\n",
      "  [ 0.09550464  0.25455087  0.73917452]]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14619/4008130450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_datapath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_music_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".mid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./video_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilecode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_test_predict.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow_list_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilecode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ow_list[0:900]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# print(\"prediction.shape\", prediction.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprediction_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow_list_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14619/2017062779.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(audio_path, plot_path, prediction, sample_time, fps, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#audio_path, plot_path,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_render_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'new_temp_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# # #merge with wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14619/2401099320.py\u001b[0m in \u001b[0;36mtest_render_animation\u001b[0;34m(fps, output, azim, prediction, ground_truth)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mFFwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFMpegWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-vcodec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'libx264'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFFwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.gif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagemagick'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mgrab_frame\u001b[0;34m(self, **savefig_kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Save the figure data to the sink, using the frame format and dpi.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         self.fig.savefig(self._proc.stdin, format=self.frame_format,\n\u001b[0m\u001b[1;32m    352\u001b[0m                          dpi=self.dpi, **savefig_kwargs)\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2317\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2320\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 **kwargs)\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_raw\u001b[0;34m(self, filename_or_obj, *args)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    435\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2837\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   2838\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   2839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# Then rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_axis_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3089\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3092\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mxs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verts3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36mproj_transform\u001b[0;34m(xs, ys, zs, M)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mTransform\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprojection\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vec_pad_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_proj_transform_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36m_vec_pad_ones\u001b[0;34m(xs, ys, zs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_vec_pad_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mones_like\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sinica/lib/python3.9/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones_like\u001b[0;34m(a, dtype, order, subok, shape)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \"\"\"\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mempty_like\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8171, 115])\n",
      "test_input (1, 8171, 128)\n",
      "test_target torch.Size([1, 8171, 115])\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n",
      "torch.Size([11537, 115])\n",
      "test_input (1, 11537, 128)\n",
      "test_target torch.Size([1, 11537, 115])\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "torch.Size([6993, 115])\n",
      "test_input (1, 6993, 128)\n",
      "test_target torch.Size([1, 6993, 115])\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "torch.Size([7897, 115])\n",
      "test_input (1, 7897, 128)\n",
      "test_target torch.Size([1, 7897, 115])\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],115)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/'):\n",
    "            os.makedirs('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/')\n",
    "        midi_data_output = open('./output_prediction/[midi_with_anno]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/prediction_'+\n",
    "                                filecode +'.pkl', 'wb')\n",
    "        pickle.dump(prediction_arr, midi_data_output)\n",
    "        midi_data_output.close()\n",
    "        \n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_val_loss = evaluate_lstm(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee221509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
