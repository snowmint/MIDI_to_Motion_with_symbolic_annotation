{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import pretty_midi\n",
    "from midiutil.MidiFile import MIDIFile\n",
    "from music21 import *\n",
    "from io import open\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "import librosa\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "import scipy\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/local/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "# torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_fps = 40 #40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_performer = \"vio01\"\n",
    "performaer_list = [\"vio01\"] #, \"vio02\", \"vio03\", \"vio04\", \"vio05\"\n",
    "test_pieces = ['Elgar_S1_T1', 'Flower_S1_T1']\n",
    "# test_pieces = ['Elgar_S1_T1', 'Elgar_S1_T2',\n",
    "#                    'Flower_S1_T1', 'Flower_S1_T2',\n",
    "#                    'Mend_S1_T1', 'Mend_S1_T2',\n",
    "#                    'Mozart1_S1_T1', 'Mozart1_S1_T2',\n",
    "#                    'Mozart2_S1_T1', 'Mozart2_S1_T2']\n",
    "# piece_list = [\"Bach1_S1_T1\", \"Bach1_S1_T2\", \"Bach2_S1_T1\", \"Bach2_S1_T2\", \"Bach2_S2_T1\", \"Bach2_S2_T2\", \"Beeth1_S1_T1\", \"Beeth1_S1_T2\", \"Beeth2_S1_T1\", \"Beeth2_S1_T2\", \"Elgar_S1_T1\", \"Elgar_S1_T2\", \"Flower_S1_T1\", \"Flower_S1_T2\", \"Mend_S1_T1\", \"Mend_S1_T2\", \"Mozart1_S1_T1\", \"Mozart1_S1_T2\", \"Mozart2_S1_T1\", \"Mozart2_S1_T2\", \"Wind_S1_T1\", \"Wind_S1_T2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UoE_mocap_path = \"./UoE_violin_midi/performance_motion/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    # Get the piano roll representation of the MIDI file\n",
    "    # fs = 40\n",
    "    piano_roll = midi_data.get_piano_roll(fs=change_fps) #40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll\n",
    "\n",
    "def audio_preprocess(audio_path, specific_fps):\n",
    "    n_fft = 4096\n",
    "    hop = int(44000/specific_fps)  # 1102.5 -> 40fps #882 -> 50fps\n",
    "    y, sr = librosa.load(audio_path, sr=44000)  # 44000 for divide 40\n",
    "    print(\"y.shape\", y.shape)\n",
    "    print(\"sample rate: \", sr)\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop, n_mfcc=13)\n",
    "    y = np.where(y == 0, 1e-10, y)\n",
    "    energy = np.log(librosa.feature.rms(\n",
    "        y=y, frame_length=n_fft, hop_length=hop, center=True))\n",
    "    mfcc_energy = np.vstack((mfcc, energy))\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_energy)\n",
    "\n",
    "    sgram = librosa.stft(y, n_fft=n_fft, hop_length=hop)\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(\n",
    "        S=sgram_mag, sr=sr)\n",
    "\n",
    "    print(\"mfcc_energy\", mfcc_energy.shape)\n",
    "    print(\"mfcc_delta\", mfcc_delta.shape)\n",
    "    print(\"mel_scale_sgram\", mel_scale_sgram.shape)\n",
    "\n",
    "    aud = np.vstack((mfcc_energy, mfcc_delta, mel_scale_sgram)).T\n",
    "\n",
    "    print(\"hop:\", hop)\n",
    "    print(\"aud:\", aud.shape)\n",
    "    return aud\n",
    "\n",
    "def read_motion(motion_path):\n",
    "    file = open(motion_path, 'rb')\n",
    "    motion_data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    return motion_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len of midi data: 7355\n",
      "midi data shape:  (7355, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape (8291800,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 7539)\n",
      "mfcc_delta (14, 7539)\n",
      "mel_scale_sgram (128, 7539)\n",
      "hop: 1100\n",
      "aud: (7539, 156)\n",
      "seq_len of audio data: 7539\n",
      "audio data shape:  (7539, 156)\n",
      "seq_len of motion data: 7524\n",
      "motion data shape:  (7524, 115)\n",
      "[cut]midi data shape:  (7355, 128)\n",
      "[cut]audio data shape:  (7355, 156)\n",
      "[cut]motion data shape:  (7355, 115)\n",
      "========\n",
      "seq_len of midi data: 4618\n",
      "midi data shape:  (4618, 128)\n",
      "y.shape (5247880,)\n",
      "sample rate:  44000\n",
      "mfcc_energy (14, 4771)\n",
      "mfcc_delta (14, 4771)\n",
      "mel_scale_sgram (128, 4771)\n",
      "hop: 1100\n",
      "aud: (4771, 156)\n",
      "seq_len of audio data: 4771\n",
      "audio data shape:  (4771, 156)\n",
      "seq_len of motion data: 4695\n",
      "motion data shape:  (4695, 115)\n",
      "[cut]midi data shape:  (4618, 128)\n",
      "[cut]audio data shape:  (4618, 156)\n",
      "[cut]motion data shape:  (4618, 115)\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "UoE_violin_midi_path = \"./UoE_violin_midi/violin_midi/vio01/\"\n",
    "UoE_violin_audio_path = \"./UoE_violin_midi/performance_audio/vio01/\"\n",
    "UoE_violin_motion_path = \"./preprocessed_data_save_cross/motion/\"\n",
    "#midi_path_list = glob.glob(UoE_violin_midi_path + \"/\" + this_performer + \"/*.mid\")\n",
    "\n",
    "piano_roll_dictionary = {}\n",
    "piano_roll_dictionary[this_performer] = {}\n",
    "piano_roll_length_list = []\n",
    "\n",
    "audio_dictionary = {}\n",
    "audio_dictionary[this_performer] = {}\n",
    "audio_len_list = []\n",
    "\n",
    "motion_dictionary = {}\n",
    "motion_dictionary[this_performer] = {}\n",
    "motion_len_list = []\n",
    "\n",
    "for name_code in test_pieces:#midi_path_list:\n",
    "    # read MIDI\n",
    "    read_piano_roll = read_midi(UoE_violin_midi_path + \"vio01_\" + name_code + \".mid\")\n",
    "    midi_len = len(read_piano_roll[0])\n",
    "    print(\"seq_len of midi data:\", len(read_piano_roll[0]))\n",
    "    piano_roll_length_list.append(len(read_piano_roll[0]))\n",
    "    print(\"midi data shape: \", read_piano_roll.T.shape)\n",
    "\n",
    "    # read Audio\n",
    "    read_audio_mfcc = audio_preprocess(UoE_violin_audio_path + \"vio01_\" + name_code + \".wav\", change_fps)\n",
    "    audio_len = len(read_audio_mfcc)\n",
    "    print(\"seq_len of audio data:\", len(read_audio_mfcc))\n",
    "    audio_len_list.append(len(read_audio_mfcc))\n",
    "    print(\"audio data shape: \", read_audio_mfcc.shape)\n",
    "    \n",
    "    # read Motion\n",
    "    motion_input = read_motion(UoE_violin_motion_path + \"vio01_\" + name_code + \"_motion_data.pkl\")\n",
    "    motion_len = len(motion_input)\n",
    "    print(\"seq_len of motion data:\", len(motion_input))\n",
    "    motion_len_list.append(len(motion_input))\n",
    "    print(\"motion data shape: \", motion_input.shape)\n",
    "    \n",
    "    cut_len = min(midi_len, audio_len, motion_len)\n",
    "\n",
    "    piano_roll_dictionary[this_performer][name_code] = read_piano_roll.T[:cut_len]\n",
    "    audio_dictionary[this_performer][name_code] = read_audio_mfcc[:cut_len]\n",
    "    motion_dictionary[this_performer][name_code] = motion_input[:cut_len]\n",
    "    \n",
    "    print(\"[cut]midi data shape: \", piano_roll_dictionary[this_performer][name_code].shape)\n",
    "    print(\"[cut]audio data shape: \", audio_dictionary[this_performer][name_code].shape)\n",
    "    print(\"[cut]motion data shape: \", motion_dictionary[this_performer][name_code].shape)\n",
    "    \n",
    "    print(\"========\")\n",
    "    # read_mfcc_transpose = read_audio_mfcc\n",
    "    # audio_len = len(read_mfcc_transpose)\n",
    "\n",
    "# print(piano_roll_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_joint_dict = {\"RFHD_X\":0,\"RFHD_Y\":1,\"RFHD_Z\":2, # head\n",
    "              \"LFHD_X\":3,\"LFHD_Y\":4,\"LFHD_Z\":5,\n",
    "              \"RBHD_X\":6,\"RBHD_Y\":7,\"RBHD_Z\":8,\n",
    "              \"LBHD_X\":9,\"LBHD_Y\":10,\"LBHD_Z\":11,\n",
    "              \"C7_X\":12,\"C7_Y\":13,\"C7_Z\":14,\n",
    "              \"T10_X\":15,\"T10_Y\":16,\"T10_Z\":17,\n",
    "              \"CLAV_X\":18,\"CLAV_Y\":19,\"CLAV_Z\":20,\n",
    "              \"STRN_X\":21,\"STRN_Y\":22,\"STRN_Z\":23,\n",
    "              \"RSHO_X\":24,\"RSHO_Y\":25,\"RSHO_Z\":26,\n",
    "              \"RELB_X\":27,\"RELB_Y\":28,\"RELB_Z\":29,\n",
    "              \"RWRA_X\":30,\"RWRA_Y\":31,\"RWRA_Z\":32,\n",
    "              \"RWRB_X\":33,\"RWRB_Y\":34,\"RWRB_Z\":35,\n",
    "              \"RFIN_X\":36,\"RFIN_Y\":37,\"RFIN_Z\":38,\n",
    "              \"LSHO_X\":39,\"LSHO_Y\":40,\"LSHO_Z\":41,\n",
    "              \"LELB_X\":42,\"LELB_Y\":43,\"LELB_Z\":44,\n",
    "              \"LWRA_X\":45,\"LWRA_Y\":46,\"LWRA_Z\":47,\n",
    "              \"LWRB_X\":48,\"LWRB_Y\":49,\"LWRB_Z\":50,\n",
    "              \"LFIN_X\":51,\"LFIN_Y\":52,\"LFIN_Z\":53,\n",
    "              \"RASI_X\":54,\"RASI_Y\":55,\"RASI_Z\":56,#(18*3) left waist\n",
    "              \"LASI_X\":57,\"LASI_Y\":58,\"LASI_Z\":59,#(19*3) right waist\n",
    "              \"RPSI_X\":60,\"RPSI_Y\":61,\"RPSI_Z\":62,\n",
    "              \"LPSI_X\":63,\"LPSI_Y\":64,\"LPSI_Z\":65,\n",
    "              \"RKNE_X\":66,\"RKNE_Y\":67,\"RKNE_Z\":68,\n",
    "              \"RHEE_X\":69,\"RHEE_Y\":70,\"RHEE_Z\":71,\n",
    "              \"RTOE_X\":72,\"RTOE_Y\":73,\"RTOE_Z\":74,\n",
    "              \"RANK_X\":75,\"RANK_Y\":76,\"RANK_Z\":77,\n",
    "              \"LKNE_X\":78,\"LKNE_Y\":79,\"LKNE_Z\":80,\n",
    "              \"LHEE_X\":81,\"LHEE_Y\":82,\"LHEE_Z\":83,\n",
    "              \"LTOE_X\":84,\"LTOE_Y\":85,\"LTOE_Z\":86,\n",
    "              \"LANK_X\":87,\"LANK_Y\":88,\"LANK_Z\":89, #29*3\n",
    "              \"Rightant_X\":90,\"Rightant_Y\":91,\"Rightant_Z\":92,\n",
    "              \"Rightpost_X\":93,\"Rightpost_Y\":94,\"Rightpost_Z\":95,\n",
    "              \"Leftant_X\":96,\"Leftant_Y\":97,\"Leftant_Z\":98,\n",
    "              \"Leftpost_X\":99,\"Leftpost_Y\":100,\"Leftpost_Z\":101}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling frequency: piano->250, violin->120\n",
    "sf = 120 #violin\n",
    "# sf = 250 #piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wav(audio_path, plot_path, prediction, sample_time, fps, name): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    input_audio = ffmpeg.input(audio_path)\n",
    "    \n",
    "    if \"Flower\" in name:\n",
    "        isExisting = os.path.exists('./out_tempclip_' + name + '.wav')\n",
    "        if isExisting != True:\n",
    "            audio_cut = input_audio.audio.filter('atrim', start=64, end=84)\n",
    "            audio_output = ffmpeg.output(audio_cut, 'out_tempclip_' + name + '.wav')\n",
    "            ffmpeg.run(audio_output)\n",
    "        input_audio = ffmpeg.input('./out_tempclip_' + name + '.wav')\n",
    "    \n",
    "    if \"Elgar\" in name:\n",
    "        isExisting = os.path.exists('./out_tempclip_' + name + '.wav')\n",
    "        if isExisting != True:\n",
    "            audio_cut = input_audio.audio.filter('atrim', start=103, end=123) #, start=30, end=60\n",
    "            audio_output = ffmpeg.output(audio_cut, './out_tempclip_' + name + '.wav')\n",
    "            ffmpeg.run(audio_output)\n",
    "        input_audio = ffmpeg.input('./out_tempclip_' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model): # reset the weight every fold\n",
    "    if isinstance(model, nn.LSTM) or isinstance(model, nn.Linear):\n",
    "        model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size_midi = 128\n",
    "input_size_audio = 156#156+128 #number of features\n",
    "input_size_both = 284\n",
    "\n",
    "hidden_size = 1024 #1024 #512 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "\n",
    "output_dim_with_anno = 115 #number of output classes\n",
    "output_dim_no_anno = 102\n",
    "\n",
    "batch_size_define_with_anno = 20#128\n",
    "batch_size_define_no_anno = 128\n",
    "\n",
    "learning_rate = 0.001#0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model_path, input_size, output_dim, test_data, filecode, loss_type):\n",
    "    model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(checkpoint['model_state_dict'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    data_format = \"\"\n",
    "    if input_size == 128:\n",
    "        data_format = \"MIDI\"\n",
    "    if input_size == 156:\n",
    "        data_format = \"Audio\"\n",
    "    if input_size == 284:\n",
    "        data_format = \"Both\"\n",
    "    \n",
    "    NoY = \"\"\n",
    "    if output_dim == 102:\n",
    "        NoY = \"no\"\n",
    "    if output_dim == 115:\n",
    "        NoY = \"yes\"\n",
    "    \n",
    "    num_epochs = 0\n",
    "    if loss_type == \"mse\":\n",
    "        num_epochs = 500\n",
    "    if loss_type == \"new\":\n",
    "        num_epochs = 300\n",
    "    \n",
    "    full_prediction = pd.DataFrame()\n",
    "    num_count = 0\n",
    "    # read midi\n",
    "    # test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "    # for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_data[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        # UoE_violin_midi_path = \"./UoE_violin_midi/violin_midi/vio01/\"\n",
    "        # if data_format == \"MIDI\":\n",
    "        #     # MIDI input\n",
    "        #     plot(UoE_violin_midi_path + \"vio01_\" + filecode + \".mid\", \"./[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")video_\" + filecode + \"_predict_hs\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch\"+\".mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # else:\n",
    "        # wav input\n",
    "        \n",
    "        if \"Elgar\" in filecode:#4120\n",
    "            plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")video_\" + filecode + \"_predict_hs\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch\"+\".mp4\", Row_list_prediction[4120:4920], None, 40, filecode) #ow_list[0:900]\n",
    "\n",
    "        if \"Flower\" in filecode:#2560\n",
    "            plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")video_\" + filecode + \"_predict_hs\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch\"+\".mp4\", Row_list_prediction[2560:3360], None, 40, filecode) #ow_list[0:900]\n",
    "        \n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists(\"./save_prediction/[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")\"+str(num_layers)+\"LSTM_hidden\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch/\"):\n",
    "            os.makedirs(\"./save_prediction/[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")\"+str(num_layers)+\"LSTM_hidden\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch/\")\n",
    "        both_data_output = open(\"./save_prediction/[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")\"+str(num_layers)+\"LSTM_hidden\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch/prediction_\"+\n",
    "                                filecode +\".pkl\", 'wb')\n",
    "        pickle.dump(prediction_arr, both_data_output)\n",
    "        both_data_output.close()\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "    # model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./no_anno_model_save/[midi_no_anno][total300_hs1024]LSTM_save_epoch_299_2023-09-01_06-18-09.tar\n",
      "new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('lstm.weight_ih_l0', tensor([[ 7.0600e-03, -3.0621e-02, -6.3491e-03,  ..., -1.2402e-02,\n",
      "          2.6364e-02, -1.1718e-05],\n",
      "        [ 2.3990e-02, -8.1953e-04,  2.0643e-02,  ...,  8.4266e-03,\n",
      "          7.3693e-04, -2.0229e-02],\n",
      "        [-3.0530e-02, -1.5380e-02,  2.8527e-02,  ...,  1.6522e-03,\n",
      "          1.8220e-02,  1.1862e-02],\n",
      "        ...,\n",
      "        [ 2.2387e-02, -1.7220e-02,  2.3143e-02,  ...,  1.8405e-02,\n",
      "          2.1236e-02, -1.6784e-02],\n",
      "        [-1.5422e-02, -5.6844e-03,  1.3451e-03,  ..., -1.9124e-02,\n",
      "          1.4527e-02, -3.9209e-03],\n",
      "        [-5.6012e-04, -1.8845e-02,  2.0255e-02,  ...,  6.3918e-04,\n",
      "          2.1597e-02,  5.5955e-03]], device='cuda:0')), ('lstm.weight_hh_l0', tensor([[ 0.3526, -0.4451,  0.2492,  ...,  0.2224,  0.2192, -0.4368],\n",
      "        [ 0.0503,  0.2439,  0.2582,  ...,  0.0911, -0.1098,  0.4041],\n",
      "        [ 0.1968,  0.4012,  0.1053,  ..., -0.3714, -0.3238,  0.0288],\n",
      "        ...,\n",
      "        [ 0.1233,  0.4862,  0.0470,  ..., -0.4186, -0.3679,  0.3941],\n",
      "        [ 0.5114, -0.5781, -0.3610,  ...,  0.0506, -0.0549, -0.2167],\n",
      "        [ 0.3014, -0.2664, -0.7994,  ...,  0.4219,  0.1999,  0.0153]],\n",
      "       device='cuda:0')), ('lstm.bias_ih_l0', tensor([-0.4185, -0.5541, -0.2440,  ..., -0.3926, -0.4819, -0.3721],\n",
      "       device='cuda:0')), ('lstm.bias_hh_l0', tensor([-0.4152, -0.5402, -0.2085,  ..., -0.3950, -0.4443, -0.3683],\n",
      "       device='cuda:0')), ('fc_1.weight', tensor([[-0.0052,  0.0094,  0.0086,  ..., -0.0022,  0.0056,  0.0192],\n",
      "        [ 0.0057,  0.0014, -0.0212,  ..., -0.0004, -0.0058,  0.0190],\n",
      "        [ 0.0010,  0.0014, -0.0006,  ...,  0.0009,  0.0004,  0.0016],\n",
      "        ...,\n",
      "        [-0.0352,  0.0497,  0.0477,  ...,  0.0014, -0.0470,  0.0421],\n",
      "        [ 0.0005,  0.0270,  0.0419,  ...,  0.0095, -0.0399,  0.0574],\n",
      "        [ 0.0003, -0.0485, -0.0322,  ..., -0.0013,  0.0654,  0.0107]],\n",
      "       device='cuda:0')), ('fc_1.bias', tensor([-1.4435e-02,  1.5378e-02,  7.3739e-01, -3.4399e-02,  6.4046e-03,\n",
      "         3.8385e-01, -1.3234e-03,  2.7464e-02,  3.5493e-01, -1.0865e-02,\n",
      "        -5.2126e-03,  3.4235e-01,  1.6921e-02, -4.2039e-04,  2.8240e-01,\n",
      "         3.5146e-02,  1.1209e-02,  2.4219e-01,  8.0590e-03,  3.7975e-02,\n",
      "         3.0166e-01,  1.2131e-02,  6.8413e-02,  2.5022e-01,  4.3529e-02,\n",
      "         4.1307e-02,  3.1449e-01,  3.4477e-02,  8.1918e-02,  2.8726e-01,\n",
      "        -4.0514e-02,  5.5154e-02,  2.7609e-01, -2.1104e-02,  8.9288e-02,\n",
      "         2.8529e-01, -7.0091e-02,  6.4701e-02,  2.8594e-01, -7.0780e-02,\n",
      "         2.8714e-03,  3.3656e-01, -1.1210e-01, -5.5712e-03,  2.5498e-01,\n",
      "        -1.0437e-01,  4.1270e-02,  3.0589e-01, -1.1598e-01,  8.3149e-02,\n",
      "         2.9653e-01, -1.2764e-01,  7.4992e-02,  2.7121e-01, -1.6931e-03,\n",
      "         4.7336e-02,  2.0965e-01, -2.4999e-02,  3.2213e-02,  2.1626e-01,\n",
      "         2.1429e-02, -2.3340e-02,  1.7529e-01,  2.1874e-02, -1.5063e-02,\n",
      "         2.0343e-01,  6.2730e-02,  2.2260e-02,  9.5243e-02,  6.2557e-02,\n",
      "         8.8062e-03,  5.4064e-03,  7.8831e-02,  4.4088e-02, -1.0080e-02,\n",
      "         7.5383e-02,  6.4242e-03, -5.3734e-03, -3.7302e-02,  2.9666e-02,\n",
      "         1.0772e-01,  2.2154e-02,  8.2440e-03,  1.2903e-02, -6.9831e-03,\n",
      "         3.8469e-02, -3.0107e-03, -1.4417e-03, -2.0249e-03, -3.5617e-05,\n",
      "        -9.4926e-02,  6.2445e-02,  2.2744e-01, -6.1342e-02,  3.0795e-02,\n",
      "         3.9120e-01, -9.7220e-02, -3.5309e-02,  3.2471e-01, -4.6361e-02,\n",
      "         9.6022e-02,  2.4891e-01], device='cuda:0'))])\n",
      "test_input (1, 7355, 128)\n",
      "prediction.shape (1, 7355, 102)\n",
      "full_prediction (7355, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[-0.03423595  0.15100197  1.09899513]\n",
      "  [-0.10140814  0.11292978  1.09419153]\n",
      "  [ 0.01253282  0.0856245   1.11727378]\n",
      "  ...\n",
      "  [-0.0496264   0.1117392   0.96761832]\n",
      "  [-0.27923927  0.07345951  1.15467665]\n",
      "  [-0.02159637  0.20885612  0.81274632]]\n",
      "\n",
      " [[-0.03432689  0.1471211   1.09992704]\n",
      "  [-0.10163548  0.10931212  1.0948312 ]\n",
      "  [ 0.012746    0.08207072  1.12128196]\n",
      "  ...\n",
      "  [-0.04643083  0.10905655  0.9682555 ]\n",
      "  [-0.27821529  0.06747381  1.14994369]\n",
      "  [-0.01659018  0.20459273  0.81467793]]\n",
      "\n",
      " [[-0.03434053  0.14686289  1.09975473]\n",
      "  [-0.10111938  0.10866117  1.0935748 ]\n",
      "  [ 0.01335797  0.08271144  1.12152836]\n",
      "  ...\n",
      "  [-0.04564035  0.10899507  0.96801881]\n",
      "  [-0.27308956  0.06917404  1.14754579]\n",
      "  [-0.01515433  0.20864725  0.81389753]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01430075  0.10455467  1.09944061]\n",
      "  [-0.05019228  0.06523223  1.10748634]\n",
      "  [ 0.06111851  0.03739681  1.09521649]\n",
      "  ...\n",
      "  [-0.0259296   0.09245886  0.97384039]\n",
      "  [-0.12440876  0.13722004  1.06571618]\n",
      "  [ 0.06475103  0.17005451  0.67897753]]\n",
      "\n",
      " [[ 0.01249146  0.10292622  1.09922723]\n",
      "  [-0.05254075  0.06431827  1.10625253]\n",
      "  [ 0.0585889   0.03521226  1.09490619]\n",
      "  ...\n",
      "  [-0.02697802  0.09131444  0.97357765]\n",
      "  [-0.1197595   0.13731888  1.05656937]\n",
      "  [ 0.07129871  0.17062727  0.67011926]]\n",
      "\n",
      " [[ 0.01217005  0.10218153  1.09912536]\n",
      "  [-0.05307099  0.06391026  1.10558269]\n",
      "  [ 0.0579277   0.03408223  1.09476922]\n",
      "  ...\n",
      "  [-0.02694822  0.09114496  0.97367904]\n",
      "  [-0.11490642  0.13652004  1.04634384]\n",
      "  [ 0.07911608  0.172977    0.66135082]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from './UoE_violin_midi/performance_audio/vio01/vio01_Elgar_S1_T1.wav':\n",
      "  Duration: 00:03:08.45, bitrate: 705 kb/s\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (pcm_s16le) -> atrim\n",
      "  atrim -> Stream #0:0 (pcm_s16le)\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to './out_tempclip_Elgar_S1_T1.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 pcm_s16le\n",
      "size=    1723kB time=00:02:03.00 bitrate= 114.7kbits/s speed=8.71e+03x    \n",
      "video:0kB audio:1723kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004422%\n",
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_Elgar_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 103 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 432x288, 100 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './out_tempclip_Elgar_S1_T1.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, bitrate: 705 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55a3b448b540] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55a3b448b540] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55a3b448b540] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './[MIDI_no_anno](new)video_Elgar_S1_T1_predict_hs1024_300epoch.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x288, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=0.0 q=-1.0 Lsize=     425kB time=00:00:20.01 bitrate= 173.8kbits/s speed=72.9x    \n",
      "video:234kB audio:170kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.203767%\n",
      "[aac @ 0x55a3b4489cc0] Qavg: 185.591\n",
      "[libx264 @ 0x55a3b448b540] frame I:4     Avg QP:13.73  size:  7632\n",
      "[libx264 @ 0x55a3b448b540] frame P:316   Avg QP:22.72  size:   554\n",
      "[libx264 @ 0x55a3b448b540] frame B:480   Avg QP:22.92  size:    69\n",
      "[libx264 @ 0x55a3b448b540] consecutive B-frames: 14.6% 13.5%  7.9% 64.0%\n",
      "[libx264 @ 0x55a3b448b540] mb I  I16..4: 54.0% 18.4% 27.6%\n",
      "[libx264 @ 0x55a3b448b540] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.6%  1.4%  1.7%  0.0%  0.0%    skip:95.2%\n",
      "[libx264 @ 0x55a3b448b540] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.0%  0.4%  0.2%  direct: 0.3%  skip:98.1%  L0:27.4% L1:41.0% BI:31.6%\n",
      "[libx264 @ 0x55a3b448b540] 8x8 transform intra:18.0% inter:17.1%\n",
      "[libx264 @ 0x55a3b448b540] coded y,uvDC,uvAC intra: 22.0% 2.4% 1.9% inter: 1.2% 0.5% 0.4%\n",
      "[libx264 @ 0x55a3b448b540] i16 v,h,dc,p: 85%  5% 10%  0%\n",
      "[libx264 @ 0x55a3b448b540] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45%  8% 47%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55a3b448b540] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 31% 13%  2%  6%  3%  3%  3%  4%\n",
      "[libx264 @ 0x55a3b448b540] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55a3b448b540] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55a3b448b540] ref P L0: 83.5% 10.3%  4.2%  2.0%\n",
      "[libx264 @ 0x55a3b448b540] ref B L0: 90.9%  6.7%  2.4%\n",
      "[libx264 @ 0x55a3b448b540] ref B L1: 97.8%  2.2%\n",
      "[libx264 @ 0x55a3b448b540] kb/s:95.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./no_anno_model_save/[midi_no_anno][total300_hs1024]LSTM_save_epoch_299_2023-09-01_06-18-09.tar\n",
      "new\n",
      "OrderedDict([('lstm.weight_ih_l0', tensor([[ 7.0600e-03, -3.0621e-02, -6.3491e-03,  ..., -1.2402e-02,\n",
      "          2.6364e-02, -1.1718e-05],\n",
      "        [ 2.3990e-02, -8.1953e-04,  2.0643e-02,  ...,  8.4266e-03,\n",
      "          7.3693e-04, -2.0229e-02],\n",
      "        [-3.0530e-02, -1.5380e-02,  2.8527e-02,  ...,  1.6522e-03,\n",
      "          1.8220e-02,  1.1862e-02],\n",
      "        ...,\n",
      "        [ 2.2387e-02, -1.7220e-02,  2.3143e-02,  ...,  1.8405e-02,\n",
      "          2.1236e-02, -1.6784e-02],\n",
      "        [-1.5422e-02, -5.6844e-03,  1.3451e-03,  ..., -1.9124e-02,\n",
      "          1.4527e-02, -3.9209e-03],\n",
      "        [-5.6012e-04, -1.8845e-02,  2.0255e-02,  ...,  6.3918e-04,\n",
      "          2.1597e-02,  5.5955e-03]], device='cuda:0')), ('lstm.weight_hh_l0', tensor([[ 0.3526, -0.4451,  0.2492,  ...,  0.2224,  0.2192, -0.4368],\n",
      "        [ 0.0503,  0.2439,  0.2582,  ...,  0.0911, -0.1098,  0.4041],\n",
      "        [ 0.1968,  0.4012,  0.1053,  ..., -0.3714, -0.3238,  0.0288],\n",
      "        ...,\n",
      "        [ 0.1233,  0.4862,  0.0470,  ..., -0.4186, -0.3679,  0.3941],\n",
      "        [ 0.5114, -0.5781, -0.3610,  ...,  0.0506, -0.0549, -0.2167],\n",
      "        [ 0.3014, -0.2664, -0.7994,  ...,  0.4219,  0.1999,  0.0153]],\n",
      "       device='cuda:0')), ('lstm.bias_ih_l0', tensor([-0.4185, -0.5541, -0.2440,  ..., -0.3926, -0.4819, -0.3721],\n",
      "       device='cuda:0')), ('lstm.bias_hh_l0', tensor([-0.4152, -0.5402, -0.2085,  ..., -0.3950, -0.4443, -0.3683],\n",
      "       device='cuda:0')), ('fc_1.weight', tensor([[-0.0052,  0.0094,  0.0086,  ..., -0.0022,  0.0056,  0.0192],\n",
      "        [ 0.0057,  0.0014, -0.0212,  ..., -0.0004, -0.0058,  0.0190],\n",
      "        [ 0.0010,  0.0014, -0.0006,  ...,  0.0009,  0.0004,  0.0016],\n",
      "        ...,\n",
      "        [-0.0352,  0.0497,  0.0477,  ...,  0.0014, -0.0470,  0.0421],\n",
      "        [ 0.0005,  0.0270,  0.0419,  ...,  0.0095, -0.0399,  0.0574],\n",
      "        [ 0.0003, -0.0485, -0.0322,  ..., -0.0013,  0.0654,  0.0107]],\n",
      "       device='cuda:0')), ('fc_1.bias', tensor([-1.4435e-02,  1.5378e-02,  7.3739e-01, -3.4399e-02,  6.4046e-03,\n",
      "         3.8385e-01, -1.3234e-03,  2.7464e-02,  3.5493e-01, -1.0865e-02,\n",
      "        -5.2126e-03,  3.4235e-01,  1.6921e-02, -4.2039e-04,  2.8240e-01,\n",
      "         3.5146e-02,  1.1209e-02,  2.4219e-01,  8.0590e-03,  3.7975e-02,\n",
      "         3.0166e-01,  1.2131e-02,  6.8413e-02,  2.5022e-01,  4.3529e-02,\n",
      "         4.1307e-02,  3.1449e-01,  3.4477e-02,  8.1918e-02,  2.8726e-01,\n",
      "        -4.0514e-02,  5.5154e-02,  2.7609e-01, -2.1104e-02,  8.9288e-02,\n",
      "         2.8529e-01, -7.0091e-02,  6.4701e-02,  2.8594e-01, -7.0780e-02,\n",
      "         2.8714e-03,  3.3656e-01, -1.1210e-01, -5.5712e-03,  2.5498e-01,\n",
      "        -1.0437e-01,  4.1270e-02,  3.0589e-01, -1.1598e-01,  8.3149e-02,\n",
      "         2.9653e-01, -1.2764e-01,  7.4992e-02,  2.7121e-01, -1.6931e-03,\n",
      "         4.7336e-02,  2.0965e-01, -2.4999e-02,  3.2213e-02,  2.1626e-01,\n",
      "         2.1429e-02, -2.3340e-02,  1.7529e-01,  2.1874e-02, -1.5063e-02,\n",
      "         2.0343e-01,  6.2730e-02,  2.2260e-02,  9.5243e-02,  6.2557e-02,\n",
      "         8.8062e-03,  5.4064e-03,  7.8831e-02,  4.4088e-02, -1.0080e-02,\n",
      "         7.5383e-02,  6.4242e-03, -5.3734e-03, -3.7302e-02,  2.9666e-02,\n",
      "         1.0772e-01,  2.2154e-02,  8.2440e-03,  1.2903e-02, -6.9831e-03,\n",
      "         3.8469e-02, -3.0107e-03, -1.4417e-03, -2.0249e-03, -3.5617e-05,\n",
      "        -9.4926e-02,  6.2445e-02,  2.2744e-01, -6.1342e-02,  3.0795e-02,\n",
      "         3.9120e-01, -9.7220e-02, -3.5309e-02,  3.2471e-01, -4.6361e-02,\n",
      "         9.6022e-02,  2.4891e-01], device='cuda:0'))])\n",
      "test_input (1, 4618, 128)\n",
      "prediction.shape (1, 4618, 102)\n",
      "full_prediction (4618, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[-1.23501197e-03  1.09783851e-01  1.10122154e+00]\n",
      "  [-6.69903830e-02  7.52236098e-02  1.09781132e+00]\n",
      "  [ 4.29736897e-02  4.50049564e-02  1.11316333e+00]\n",
      "  ...\n",
      "  [-2.79838219e-02  8.75811428e-02  9.67228806e-01]\n",
      "  [-2.30790913e-01  8.25535953e-02  1.14875362e+00]\n",
      "  [ 1.56468153e-02  1.90595746e-01  8.07166553e-01]]\n",
      "\n",
      " [[-1.91688538e-04  1.08106583e-01  1.10119281e+00]\n",
      "  [-6.59171641e-02  7.35508949e-02  1.09768507e+00]\n",
      "  [ 4.38779071e-02  4.31986824e-02  1.11232541e+00]\n",
      "  ...\n",
      "  [-2.72394568e-02  8.69066566e-02  9.67243528e-01]\n",
      "  [-2.27402374e-01  8.39005858e-02  1.14612052e+00]\n",
      "  [ 1.88324265e-02  1.90559581e-01  8.04185843e-01]]\n",
      "\n",
      " [[ 9.94844362e-04  1.06278628e-01  1.10117636e+00]\n",
      "  [-6.46766573e-02  7.17040524e-02  1.09762744e+00]\n",
      "  [ 4.49503139e-02  4.12565283e-02  1.11143563e+00]\n",
      "  ...\n",
      "  [-2.64158957e-02  8.62147585e-02  9.67247403e-01]\n",
      "  [-2.23772824e-01  8.51576924e-02  1.14312897e+00]\n",
      "  [ 2.23065875e-02  1.90558434e-01  8.00945437e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.34027186e-02  1.03798002e-01  1.09990457e+00]\n",
      "  [-2.97209006e-02  6.78046197e-02  1.10404251e+00]\n",
      "  [ 8.01161900e-02  3.94499525e-02  1.10071919e+00]\n",
      "  ...\n",
      "  [-3.51776369e-03  9.17598680e-02  9.71900439e-01]\n",
      "  [-1.88574746e-01  8.75900835e-02  1.16623197e+00]\n",
      "  [ 3.40530202e-02  1.98610604e-01  8.16052771e-01]]\n",
      "\n",
      " [[ 3.46661061e-02  1.04509547e-01  1.10007653e+00]\n",
      "  [-2.87619811e-02  6.86589405e-02  1.10393021e+00]\n",
      "  [ 8.10447931e-02  3.98964845e-02  1.10143266e+00]\n",
      "  ...\n",
      "  [-3.05323675e-03  9.21412855e-02  9.71871889e-01]\n",
      "  [-1.92890897e-01  8.18461180e-02  1.16975079e+00]\n",
      "  [ 3.11968867e-02  1.99529693e-01  8.21752167e-01]]\n",
      "\n",
      " [[ 3.22924592e-02  1.26704723e-01  1.10049663e+00]\n",
      "  [-3.27263549e-02  9.41609442e-02  1.11114237e+00]\n",
      "  [ 7.63121024e-02  5.90843745e-02  1.10953603e+00]\n",
      "  ...\n",
      "  [-8.18611961e-03  1.04279235e-01  9.75968933e-01]\n",
      "  [-2.07578361e-01  8.74730647e-02  1.16589234e+00]\n",
      "  [ 3.68606597e-02  2.26773247e-01  8.39528298e-01]]]\n"
     ]
    }
   ],
   "source": [
    "no_anno_model_path = \"./no_anno_model_save/\"\n",
    "with_anno_model_path = \"./with_anno_model_save/\"\n",
    "\n",
    "no_anno_model_path_list = glob.glob(no_anno_model_path + \"*.tar\")\n",
    "\n",
    "\n",
    "for eval_model_path in no_anno_model_path_list:\n",
    "    for filecode in test_pieces:\n",
    "        #[audio_no_anno][total300_hs1024]LSTM_save_epoch_299_2023-09-01_23-05-02\n",
    "        # eval_path.split(' ', )\n",
    "        print(eval_model_path)\n",
    "        input_size = 0\n",
    "        if ('midi' in eval_model_path):\n",
    "            input_size = 128\n",
    "            test_data = piano_roll_dictionary[this_performer][filecode]\n",
    "        if ('audio' in eval_model_path):\n",
    "            input_size = 156\n",
    "            test_data = audio_dictionary[this_performer][filecode]\n",
    "        if ('both' in eval_model_path):\n",
    "            input_size = 284\n",
    "            test_data = np.concatenate(\n",
    "            (piano_roll_dictionary[this_performer][filecode], audio_dictionary[this_performer][filecode]), axis=1)\n",
    "            # test_data = motion_dictionary[this_performer][filecode]\n",
    "        \n",
    "        output_dim = 0\n",
    "        if ('no_anno' in eval_model_path):\n",
    "            output_dim = 102\n",
    "        if ('with_anno' in eval_model_path):\n",
    "            output_dim = 115\n",
    "        \n",
    "        loss_type = \"\"\n",
    "        if (\"total500\" in eval_model_path):\n",
    "            loss_type = \"mse\"\n",
    "        if (\"total300\" in eval_model_path):\n",
    "            loss_type = \"new\"\n",
    "        print(loss_type)\n",
    "\n",
    "        model_predict(eval_model_path, input_size, output_dim, test_data, filecode, loss_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('lstm.weight_ih_l0', tensor([[ 7.0600e-03, -3.0621e-02, -6.3491e-03,  ..., -1.2402e-02,\n",
      "          2.6364e-02, -1.1718e-05],\n",
      "        [ 2.3990e-02, -8.1953e-04,  2.0643e-02,  ...,  8.4266e-03,\n",
      "          7.3693e-04, -2.0229e-02],\n",
      "        [-3.0530e-02, -1.5380e-02,  2.8527e-02,  ...,  1.6522e-03,\n",
      "          1.8220e-02,  1.1862e-02],\n",
      "        ...,\n",
      "        [-2.2005e-03, -1.4138e-02,  2.1567e-02,  ...,  2.6931e-02,\n",
      "         -1.0656e-02, -1.4090e-04],\n",
      "        [ 2.9328e-02, -1.1218e-02, -1.4724e-02,  ...,  2.3250e-02,\n",
      "         -1.9489e-02,  3.0060e-02],\n",
      "        [ 1.2342e-02, -2.9460e-02, -1.1747e-02,  ..., -1.9196e-03,\n",
      "         -6.8986e-03,  1.2311e-02]], device='cuda:0')), ('lstm.weight_hh_l0', tensor([[ 0.1561, -0.0902,  0.1600,  ..., -0.6004,  0.2462,  0.2367],\n",
      "        [-0.1749, -0.0397, -0.1754,  ..., -0.5262, -0.1405,  0.0111],\n",
      "        [ 0.0782, -0.5275, -0.3311,  ..., -0.2035,  0.1834, -0.1874],\n",
      "        ...,\n",
      "        [ 0.3344,  0.0308, -0.1157,  ...,  0.4482,  0.1918,  0.1961],\n",
      "        [ 0.5499, -0.0707,  0.0223,  ..., -0.5491, -0.2239,  0.0959],\n",
      "        [-0.1558,  0.1234, -0.2236,  ..., -0.1990, -0.3211, -0.1784]],\n",
      "       device='cuda:0')), ('lstm.bias_ih_l0', tensor([-0.5335, -0.1986, -0.3921,  ...,  0.1757, -0.4288, -0.2714],\n",
      "       device='cuda:0')), ('lstm.bias_hh_l0', tensor([-0.4999, -0.2067, -0.4046,  ...,  0.1573, -0.4434, -0.2794],\n",
      "       device='cuda:0')), ('fc_1.weight', tensor([[ 4.6197e-04,  2.9074e-03, -2.9800e-03,  ..., -3.2482e-03,\n",
      "          1.5260e-03,  1.2800e-03],\n",
      "        [-4.7157e-03,  1.8379e-03, -1.2531e-05,  ..., -2.5207e-03,\n",
      "         -4.3189e-03, -1.3574e-03],\n",
      "        [ 4.7253e-04, -3.5265e-04,  7.2932e-04,  ...,  2.7874e-04,\n",
      "         -3.2586e-04, -2.0523e-04],\n",
      "        ...,\n",
      "        [-5.6370e-02,  7.6858e-03,  1.3675e-02,  ..., -6.2693e-03,\n",
      "         -4.1647e-02, -7.1181e-02],\n",
      "        [ 6.7894e-04,  2.9038e-02,  3.1504e-03,  ...,  1.2581e-03,\n",
      "         -2.7846e-02, -5.1408e-02],\n",
      "        [-3.3607e-03,  2.2855e-03, -1.0097e-02,  ...,  3.4355e-03,\n",
      "          7.1389e-03,  3.3341e-03]], device='cuda:0')), ('fc_1.bias', tensor([-3.0586e-02,  2.2564e-02,  9.6705e-01, -4.7686e-02, -2.4660e-02,\n",
      "         7.4857e-01,  2.2591e-02, -1.6698e-03,  6.9880e-01, -2.1663e-02,\n",
      "        -4.8560e-02,  6.4733e-01,  1.9825e-02, -8.9681e-03,  5.0660e-01,\n",
      "         4.3248e-02,  4.2473e-03,  4.0097e-01,  1.7655e-02,  5.3660e-02,\n",
      "         5.6444e-01,  2.4536e-02,  9.8576e-02,  3.9045e-01,  8.2722e-02,\n",
      "         3.2203e-02,  5.1976e-01,  1.2976e-01,  4.2981e-02,  4.2725e-01,\n",
      "         4.8878e-02,  6.6011e-02,  3.5200e-01,  7.2668e-02,  9.1003e-02,\n",
      "         3.3346e-01,  3.8823e-02,  8.5535e-02,  3.4366e-01, -7.5982e-02,\n",
      "        -4.3331e-02,  5.5250e-01, -1.0846e-01, -1.1916e-02,  4.3718e-01,\n",
      "        -1.4686e-01,  3.7534e-02,  4.9069e-01, -1.2750e-01,  6.3126e-02,\n",
      "         5.0638e-01, -1.5169e-01,  7.3053e-02,  4.8910e-01,  6.7933e-02,\n",
      "         1.0519e-01,  3.8146e-01, -2.7881e-02,  8.7096e-02,  3.5714e-01,\n",
      "         5.3218e-02,  1.6169e-02,  3.3867e-01,  1.2930e-02,  2.6026e-02,\n",
      "         3.4751e-01,  9.9817e-02,  6.4847e-02,  2.0445e-01,  8.6038e-02,\n",
      "         8.0941e-03, -1.1298e-02,  1.3498e-01,  6.3219e-02, -1.6580e-02,\n",
      "         1.1347e-01,  1.3477e-02,  2.4588e-02,  1.8384e-03,  2.8075e-02,\n",
      "         1.8809e-01,  2.8801e-02, -1.4154e-02, -2.8216e-02, -2.6049e-02,\n",
      "         7.6155e-02, -1.4975e-02,  8.3131e-05,  1.5179e-04, -1.5344e-04,\n",
      "        -1.6371e-01,  8.5163e-02,  4.2423e-01, -7.4262e-02,  5.5062e-02,\n",
      "         6.5310e-01, -6.9879e-02,  1.0185e-01,  5.4038e-01,  3.1585e-02,\n",
      "         7.2506e-02,  2.6954e-01, -1.7508e-02,  3.9448e-01,  2.3775e-01,\n",
      "         7.9196e-04,  3.6231e-05, -4.2942e-03, -9.2317e-05,  4.6570e-02,\n",
      "         1.7082e-02,  2.0044e-01,  1.0027e-01,  8.1465e-02,  7.0068e-04],\n",
      "       device='cuda:0'))])\n",
      "test_input (1, 7355, 128)\n",
      "prediction.shape (1, 7355, 102)\n",
      "full_prediction (7355, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 5.82222193e-02  1.14193328e-01  1.09808329e+00]\n",
      "  [-3.34984437e-03  7.03085363e-02  1.10147974e+00]\n",
      "  [ 1.04733303e-01  4.67921980e-02  1.08197699e+00]\n",
      "  ...\n",
      "  [-1.11050904e-05  9.17987302e-02  9.69005978e-01]\n",
      "  [-1.30188376e-01  1.10524409e-01  1.06914047e+00]\n",
      "  [ 7.81428292e-02  2.44901523e-01  7.43024504e-01]]\n",
      "\n",
      " [[ 8.08118284e-02  1.34314060e-01  1.09959344e+00]\n",
      "  [ 1.76250823e-02  8.91127810e-02  1.11908863e+00]\n",
      "  [ 1.26869828e-01  6.37748763e-02  1.09021745e+00]\n",
      "  ...\n",
      "  [ 1.45427529e-02  1.07499532e-01  9.69674444e-01]\n",
      "  [-9.45912823e-02  1.64893687e-01  1.08692989e+00]\n",
      "  [ 6.49664849e-02  2.33168036e-01  7.54981732e-01]]\n",
      "\n",
      " [[ 8.49689618e-02  1.27203733e-01  1.09896061e+00]\n",
      "  [ 2.31101662e-02  8.18422660e-02  1.11854718e+00]\n",
      "  [ 1.32287875e-01  5.71312457e-02  1.08791444e+00]\n",
      "  ...\n",
      "  [ 1.57242455e-02  1.01463981e-01  9.72073233e-01]\n",
      "  [-9.87636298e-02  1.36199504e-01  1.08772842e+00]\n",
      "  [ 7.36054257e-02  2.40028605e-01  7.41049564e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.27098349e-02  9.59512889e-02  1.09999195e+00]\n",
      "  [-2.45309025e-02  5.68239428e-02  1.10602102e+00]\n",
      "  [ 8.50439519e-02  2.45272554e-02  1.09175942e+00]\n",
      "  ...\n",
      "  [-1.04882685e-03  8.03742409e-02  9.70305359e-01]\n",
      "  [-1.72276855e-01  5.71302548e-02  1.13662860e+00]\n",
      "  [ 8.66873860e-02  2.33328283e-01  8.11793125e-01]]\n",
      "\n",
      " [[ 4.56057042e-02  9.55445394e-02  1.09995917e+00]\n",
      "  [-2.17158571e-02  5.66627048e-02  1.10599778e+00]\n",
      "  [ 8.77250358e-02  2.40223669e-02  1.09199057e+00]\n",
      "  ...\n",
      "  [ 1.48884603e-03  8.04583877e-02  9.70392859e-01]\n",
      "  [-1.66737333e-01  6.10249117e-02  1.13344333e+00]\n",
      "  [ 9.34872478e-02  2.35720441e-01  8.08810568e-01]]\n",
      "\n",
      " [[ 4.78251092e-02  9.46372449e-02  1.09991620e+00]\n",
      "  [-1.96244102e-02  5.60703203e-02  1.10587451e+00]\n",
      "  [ 8.96094143e-02  2.29331478e-02  1.09195796e+00]\n",
      "  ...\n",
      "  [ 3.43879056e-03  8.03526267e-02  9.70509565e-01]\n",
      "  [-1.61476359e-01  6.39736205e-02  1.12878571e+00]\n",
      "  [ 9.97606888e-02  2.38627076e-01  8.05431283e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_Elgar_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 104 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 432x288, 100 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './UoE_violin_midi/performance_audio/vio01/vio01_Elgar_S1_T1.wav':\n",
      "  Duration: 00:03:08.45, bitrate: 705 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55638dda6580] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55638dda6580] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55638dda6580] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './[MIDI_yes_anno](new)video_Elgar_S1_T1_predict_hs1024_300epoch.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x288, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=0.0 q=-1.0 Lsize=    1881kB time=00:03:08.45 bitrate=  81.8kbits/s speed= 242x    \n",
      "video:236kB audio:1596kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.672151%\n",
      "[aac @ 0x55638dda4e40] Qavg: 111.078\n",
      "[libx264 @ 0x55638dda6580] frame I:4     Avg QP:12.83  size:  7542\n",
      "[libx264 @ 0x55638dda6580] frame P:314   Avg QP:22.87  size:   528\n",
      "[libx264 @ 0x55638dda6580] frame B:482   Avg QP:22.92  size:    93\n",
      "[libx264 @ 0x55638dda6580] consecutive B-frames: 11.6% 20.0% 12.4% 56.0%\n",
      "[libx264 @ 0x55638dda6580] mb I  I16..4: 61.5% 10.8% 27.7%\n",
      "[libx264 @ 0x55638dda6580] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.7%  1.4%  1.6%  0.0%  0.0%    skip:95.4%\n",
      "[libx264 @ 0x55638dda6580] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.1%  0.7%  0.4%  direct: 0.3%  skip:97.7%  L0:33.5% L1:41.6% BI:25.0%\n",
      "[libx264 @ 0x55638dda6580] 8x8 transform intra:10.7% inter:19.4%\n",
      "[libx264 @ 0x55638dda6580] coded y,uvDC,uvAC intra: 22.4% 2.3% 2.0% inter: 1.3% 0.4% 0.4%\n",
      "[libx264 @ 0x55638dda6580] i16 v,h,dc,p: 89%  2%  9%  0%\n",
      "[libx264 @ 0x55638dda6580] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 52% 11% 36%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55638dda6580] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 31% 13%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55638dda6580] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55638dda6580] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55638dda6580] ref P L0: 80.0%  9.0%  6.6%  4.4%\n",
      "[libx264 @ 0x55638dda6580] ref B L0: 88.8%  8.0%  3.3%\n",
      "[libx264 @ 0x55638dda6580] ref B L1: 96.9%  3.1%\n",
      "[libx264 @ 0x55638dda6580] kb/s:96.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('lstm.weight_ih_l0', tensor([[ 7.0600e-03, -3.0621e-02, -6.3491e-03,  ..., -1.2402e-02,\n",
      "          2.6364e-02, -1.1718e-05],\n",
      "        [ 2.3990e-02, -8.1953e-04,  2.0643e-02,  ...,  8.4266e-03,\n",
      "          7.3693e-04, -2.0229e-02],\n",
      "        [-3.0530e-02, -1.5380e-02,  2.8527e-02,  ...,  1.6522e-03,\n",
      "          1.8220e-02,  1.1862e-02],\n",
      "        ...,\n",
      "        [-2.2005e-03, -1.4138e-02,  2.1567e-02,  ...,  2.6931e-02,\n",
      "         -1.0656e-02, -1.4090e-04],\n",
      "        [ 2.9328e-02, -1.1218e-02, -1.4724e-02,  ...,  2.3250e-02,\n",
      "         -1.9489e-02,  3.0060e-02],\n",
      "        [ 1.2342e-02, -2.9460e-02, -1.1747e-02,  ..., -1.9196e-03,\n",
      "         -6.8986e-03,  1.2311e-02]], device='cuda:0')), ('lstm.weight_hh_l0', tensor([[ 0.1561, -0.0902,  0.1600,  ..., -0.6004,  0.2462,  0.2367],\n",
      "        [-0.1749, -0.0397, -0.1754,  ..., -0.5262, -0.1405,  0.0111],\n",
      "        [ 0.0782, -0.5275, -0.3311,  ..., -0.2035,  0.1834, -0.1874],\n",
      "        ...,\n",
      "        [ 0.3344,  0.0308, -0.1157,  ...,  0.4482,  0.1918,  0.1961],\n",
      "        [ 0.5499, -0.0707,  0.0223,  ..., -0.5491, -0.2239,  0.0959],\n",
      "        [-0.1558,  0.1234, -0.2236,  ..., -0.1990, -0.3211, -0.1784]],\n",
      "       device='cuda:0')), ('lstm.bias_ih_l0', tensor([-0.5335, -0.1986, -0.3921,  ...,  0.1757, -0.4288, -0.2714],\n",
      "       device='cuda:0')), ('lstm.bias_hh_l0', tensor([-0.4999, -0.2067, -0.4046,  ...,  0.1573, -0.4434, -0.2794],\n",
      "       device='cuda:0')), ('fc_1.weight', tensor([[ 4.6197e-04,  2.9074e-03, -2.9800e-03,  ..., -3.2482e-03,\n",
      "          1.5260e-03,  1.2800e-03],\n",
      "        [-4.7157e-03,  1.8379e-03, -1.2531e-05,  ..., -2.5207e-03,\n",
      "         -4.3189e-03, -1.3574e-03],\n",
      "        [ 4.7253e-04, -3.5265e-04,  7.2932e-04,  ...,  2.7874e-04,\n",
      "         -3.2586e-04, -2.0523e-04],\n",
      "        ...,\n",
      "        [-5.6370e-02,  7.6858e-03,  1.3675e-02,  ..., -6.2693e-03,\n",
      "         -4.1647e-02, -7.1181e-02],\n",
      "        [ 6.7894e-04,  2.9038e-02,  3.1504e-03,  ...,  1.2581e-03,\n",
      "         -2.7846e-02, -5.1408e-02],\n",
      "        [-3.3607e-03,  2.2855e-03, -1.0097e-02,  ...,  3.4355e-03,\n",
      "          7.1389e-03,  3.3341e-03]], device='cuda:0')), ('fc_1.bias', tensor([-3.0586e-02,  2.2564e-02,  9.6705e-01, -4.7686e-02, -2.4660e-02,\n",
      "         7.4857e-01,  2.2591e-02, -1.6698e-03,  6.9880e-01, -2.1663e-02,\n",
      "        -4.8560e-02,  6.4733e-01,  1.9825e-02, -8.9681e-03,  5.0660e-01,\n",
      "         4.3248e-02,  4.2473e-03,  4.0097e-01,  1.7655e-02,  5.3660e-02,\n",
      "         5.6444e-01,  2.4536e-02,  9.8576e-02,  3.9045e-01,  8.2722e-02,\n",
      "         3.2203e-02,  5.1976e-01,  1.2976e-01,  4.2981e-02,  4.2725e-01,\n",
      "         4.8878e-02,  6.6011e-02,  3.5200e-01,  7.2668e-02,  9.1003e-02,\n",
      "         3.3346e-01,  3.8823e-02,  8.5535e-02,  3.4366e-01, -7.5982e-02,\n",
      "        -4.3331e-02,  5.5250e-01, -1.0846e-01, -1.1916e-02,  4.3718e-01,\n",
      "        -1.4686e-01,  3.7534e-02,  4.9069e-01, -1.2750e-01,  6.3126e-02,\n",
      "         5.0638e-01, -1.5169e-01,  7.3053e-02,  4.8910e-01,  6.7933e-02,\n",
      "         1.0519e-01,  3.8146e-01, -2.7881e-02,  8.7096e-02,  3.5714e-01,\n",
      "         5.3218e-02,  1.6169e-02,  3.3867e-01,  1.2930e-02,  2.6026e-02,\n",
      "         3.4751e-01,  9.9817e-02,  6.4847e-02,  2.0445e-01,  8.6038e-02,\n",
      "         8.0941e-03, -1.1298e-02,  1.3498e-01,  6.3219e-02, -1.6580e-02,\n",
      "         1.1347e-01,  1.3477e-02,  2.4588e-02,  1.8384e-03,  2.8075e-02,\n",
      "         1.8809e-01,  2.8801e-02, -1.4154e-02, -2.8216e-02, -2.6049e-02,\n",
      "         7.6155e-02, -1.4975e-02,  8.3131e-05,  1.5179e-04, -1.5344e-04,\n",
      "        -1.6371e-01,  8.5163e-02,  4.2423e-01, -7.4262e-02,  5.5062e-02,\n",
      "         6.5310e-01, -6.9879e-02,  1.0185e-01,  5.4038e-01,  3.1585e-02,\n",
      "         7.2506e-02,  2.6954e-01, -1.7508e-02,  3.9448e-01,  2.3775e-01,\n",
      "         7.9196e-04,  3.6231e-05, -4.2942e-03, -9.2317e-05,  4.6570e-02,\n",
      "         1.7082e-02,  2.0044e-01,  1.0027e-01,  8.1465e-02,  7.0068e-04],\n",
      "       device='cuda:0'))])\n",
      "test_input (1, 4618, 128)\n",
      "prediction.shape (1, 4618, 102)\n",
      "full_prediction (4618, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 5.82222193e-02  1.14193328e-01  1.09808329e+00]\n",
      "  [-3.34984437e-03  7.03085363e-02  1.10147974e+00]\n",
      "  [ 1.04733303e-01  4.67921980e-02  1.08197699e+00]\n",
      "  ...\n",
      "  [-1.11050904e-05  9.17987302e-02  9.69005978e-01]\n",
      "  [-1.30188376e-01  1.10524409e-01  1.06914047e+00]\n",
      "  [ 7.81428292e-02  2.44901523e-01  7.43024504e-01]]\n",
      "\n",
      " [[ 8.08118284e-02  1.34314060e-01  1.09959344e+00]\n",
      "  [ 1.76250823e-02  8.91127810e-02  1.11908863e+00]\n",
      "  [ 1.26869828e-01  6.37748763e-02  1.09021745e+00]\n",
      "  ...\n",
      "  [ 1.45427529e-02  1.07499532e-01  9.69674444e-01]\n",
      "  [-9.45912823e-02  1.64893687e-01  1.08692989e+00]\n",
      "  [ 6.49664849e-02  2.33168036e-01  7.54981732e-01]]\n",
      "\n",
      " [[ 8.49689618e-02  1.27203733e-01  1.09896061e+00]\n",
      "  [ 2.31101662e-02  8.18422660e-02  1.11854718e+00]\n",
      "  [ 1.32287875e-01  5.71312457e-02  1.08791444e+00]\n",
      "  ...\n",
      "  [ 1.57242455e-02  1.01463981e-01  9.72073233e-01]\n",
      "  [-9.87636298e-02  1.36199504e-01  1.08772842e+00]\n",
      "  [ 7.36054257e-02  2.40028605e-01  7.41049564e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.32091954e-01  1.06420197e-01  1.10147140e+00]\n",
      "  [ 6.91165999e-02  7.34052360e-02  1.11430058e+00]\n",
      "  [ 1.75558075e-01  3.76037210e-02  1.10075006e+00]\n",
      "  ...\n",
      "  [ 8.67513195e-02  8.32882077e-02  9.78719568e-01]\n",
      "  [-8.38126615e-02  4.13065031e-02  1.04311064e+00]\n",
      "  [ 2.10663483e-01  3.01903993e-01  8.47333944e-01]]\n",
      "\n",
      " [[ 1.32938161e-01  1.05740525e-01  1.10136840e+00]\n",
      "  [ 7.07583874e-02  7.15261549e-02  1.11471722e+00]\n",
      "  [ 1.77526951e-01  3.74305621e-02  1.09925703e+00]\n",
      "  ...\n",
      "  [ 8.67833123e-02  8.25494304e-02  9.78680289e-01]\n",
      "  [-8.26187134e-02  4.02141474e-02  1.04649726e+00]\n",
      "  [ 2.09335551e-01  3.02489758e-01  8.41424322e-01]]\n",
      "\n",
      " [[ 1.35776222e-01  1.05751291e-01  1.10136960e+00]\n",
      "  [ 7.40485489e-02  7.09892735e-02  1.11562798e+00]\n",
      "  [ 1.80992842e-01  3.77145186e-02  1.09933940e+00]\n",
      "  ...\n",
      "  [ 8.90737325e-02  8.18261057e-02  9.79269123e-01]\n",
      "  [-7.98484832e-02  3.90435532e-02  1.04764787e+00]\n",
      "  [ 2.11159512e-01  3.06006163e-01  8.39687860e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_Flower_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 101 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 432x288, 97 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './UoE_violin_midi/performance_audio/vio01/vio01_Flower_S1_T1.wav':\n",
      "  Duration: 00:01:59.27, bitrate: 705 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x561085e74800] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x561085e74800] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x561085e74800] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './[MIDI_yes_anno](new)video_Flower_S1_T1_predict_hs1024_300epoch.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x288, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=0.0 q=-1.0 Lsize=    1274kB time=00:01:59.28 bitrate=  87.5kbits/s speed= 209x    \n",
      "video:226kB audio:1010kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.014230%\n",
      "[aac @ 0x561085e3d780] Qavg: 111.427\n",
      "[libx264 @ 0x561085e74800] frame I:4     Avg QP:13.46  size:  7593\n",
      "[libx264 @ 0x561085e74800] frame P:318   Avg QP:22.90  size:   501\n",
      "[libx264 @ 0x561085e74800] frame B:478   Avg QP:21.96  size:    87\n",
      "[libx264 @ 0x561085e74800] consecutive B-frames: 12.6% 19.2% 11.6% 56.5%\n",
      "[libx264 @ 0x561085e74800] mb I  I16..4: 65.0%  7.5% 27.6%\n",
      "[libx264 @ 0x561085e74800] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.7%  1.3%  1.5%  0.0%  0.0%    skip:95.5%\n",
      "[libx264 @ 0x561085e74800] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.0%  0.7%  0.3%  direct: 0.2%  skip:97.8%  L0:35.4% L1:43.3% BI:21.2%\n",
      "[libx264 @ 0x561085e74800] 8x8 transform intra:7.4% inter:19.4%\n",
      "[libx264 @ 0x561085e74800] coded y,uvDC,uvAC intra: 22.8% 2.6% 2.1% inter: 1.2% 0.4% 0.3%\n",
      "[libx264 @ 0x561085e74800] i16 v,h,dc,p: 89%  2%  9%  0%\n",
      "[libx264 @ 0x561085e74800] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 14% 42%  0%  0%  0%  0%  1%  1%\n",
      "[libx264 @ 0x561085e74800] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 30% 13%  2%  6%  4%  3%  3%  3%\n",
      "[libx264 @ 0x561085e74800] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x561085e74800] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x561085e74800] ref P L0: 81.3%  8.8%  5.9%  4.1%\n",
      "[libx264 @ 0x561085e74800] ref B L0: 89.3%  7.7%  3.0%\n",
      "[libx264 @ 0x561085e74800] ref B L1: 96.7%  3.3%\n",
      "[libx264 @ 0x561085e74800] kb/s:92.42\n"
     ]
    }
   ],
   "source": [
    "with_anno_model_path_list = glob.glob(with_anno_model_path + \"*.tar\")\n",
    "\n",
    "for eval_model_path in with_anno_model_path_list:\n",
    "    for filecode in test_pieces:\n",
    "        #[audio_no_anno][total300_hs1024]LSTM_save_epoch_299_2023-09-01_23-05-02\n",
    "        # eval_path.split(' ', )\n",
    "        input_size = 0\n",
    "        if ('midi' in eval_model_path):\n",
    "            input_size = 128\n",
    "            test_data = piano_roll_dictionary[this_performer][filecode]\n",
    "        if ('audio' in eval_model_path):\n",
    "            input_size = 156\n",
    "            test_data = audio_dictionary[this_performer][filecode]\n",
    "        if ('both' in eval_model_path):\n",
    "            input_size = 284\n",
    "            test_data = np.concatenate(\n",
    "            (piano_roll_dictionary[this_performer][filecode], audio_dictionary[this_performer][filecode]), axis=1)\n",
    "            # test_data = motion_dictionary[this_performer][filecode]\n",
    "        \n",
    "        output_dim = 0\n",
    "        if ('no_anno' in eval_model_path):\n",
    "            output_dim = 102\n",
    "        if ('with_anno' in eval_model_path):\n",
    "            output_dim = 115\n",
    "        \n",
    "        loss_type = \"\"\n",
    "        if ('total500' in eval_model_path):\n",
    "            loss_type = \"mse\"\n",
    "        if ('total300' in eval_model_path):\n",
    "            loss_type = \"new\"\n",
    "            \n",
    "        model_predict(eval_model_path, input_size, output_dim, test_data, filecode, loss_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7355, 102)\n",
      "7355\n",
      "81600\n",
      "limit 800\n",
      "[[[ 9.86281581e-02  1.00470039e-01  1.10000000e+00]\n",
      "  [ 2.96077901e-02  7.49391786e-02  1.10371394e+00]\n",
      "  [ 1.32824395e-01  2.55640088e-02  1.10631972e+00]\n",
      "  ...\n",
      "  [ 4.50791465e-02  8.51754456e-02  9.78756378e-01]\n",
      "  [ 1.96899723e-01  4.01596611e-01  4.98375456e-01]\n",
      "  [ 2.23522187e-01  9.47548453e-03  5.25989232e-01]]\n",
      "\n",
      " [[ 1.02621756e-01  1.01007444e-01  1.10000000e+00]\n",
      "  [ 3.36823543e-02  7.54023837e-02  1.10808862e+00]\n",
      "  [ 1.37051871e-01  2.58389306e-02  1.10369123e+00]\n",
      "  ...\n",
      "  [ 4.38427516e-02  8.61169294e-02  9.81801927e-01]\n",
      "  [ 2.46030692e-01  3.91626588e-01  3.59772227e-01]\n",
      "  [ 2.13969448e-01 -5.51447519e-03  5.47534202e-01]]\n",
      "\n",
      " [[ 1.02246885e-01  1.01015463e-01  1.10000000e+00]\n",
      "  [ 3.33377646e-02  7.49792436e-02  1.10680424e+00]\n",
      "  [ 1.36790920e-01  2.58455707e-02  1.10440325e+00]\n",
      "  ...\n",
      "  [ 4.52149511e-02  8.58205556e-02  9.80856451e-01]\n",
      "  [ 2.33580462e-01  3.94652409e-01  3.97129584e-01]\n",
      "  [ 2.16638927e-01 -1.55837459e-03  5.40953702e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.80110726e-02  1.32958513e-01  1.10000000e+00]\n",
      "  [-2.87701380e-02  1.00274358e-01  1.10611406e+00]\n",
      "  [ 8.13832776e-02  6.34894204e-02  1.11110016e+00]\n",
      "  ...\n",
      "  [-1.53490603e-03  1.11577840e-01  9.72914135e-01]\n",
      "  [-1.88818898e-01  1.03365563e-01  1.14343709e+00]\n",
      "  [ 5.77504160e-02  2.10204790e-01  8.06784445e-01]]\n",
      "\n",
      " [[ 4.06915171e-02  1.32026501e-01  1.10000000e+00]\n",
      "  [-2.60819846e-02  9.95101676e-02  1.10620628e+00]\n",
      "  [ 8.38974536e-02  6.24680245e-02  1.11052654e+00]\n",
      "  ...\n",
      "  [ 7.46003511e-04  1.12440137e-01  9.73365157e-01]\n",
      "  [-1.84337360e-01  1.04597289e-01  1.13923314e+00]\n",
      "  [ 6.39475008e-02  2.11601805e-01  8.04230644e-01]]\n",
      "\n",
      " [[ 4.33268273e-02  1.31092679e-01  1.10000000e+00]\n",
      "  [-2.34614824e-02  9.87692127e-02  1.10620951e+00]\n",
      "  [ 8.63183021e-02  6.14292799e-02  1.10994977e+00]\n",
      "  ...\n",
      "  [ 3.04298946e-03  1.11030321e-01  9.73144154e-01]\n",
      "  [-1.79386511e-01  1.06535874e-01  1.13483889e+00]\n",
      "  [ 7.03927119e-02  2.12999693e-01  8.01327272e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_Elgar_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 97 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 432x288, 93 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './UoE_violin_midi/performance_audio/vio01/vio01_Elgar_S1_T1.wav':\n",
      "  Duration: 00:03:08.45, bitrate: 705 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5640bf3329c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5640bf3329c0] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5640bf3329c0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './[ground_truth_40fps]video_Elgar_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x288, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=0.0 q=-1.0 Lsize=    1866kB time=00:03:08.45 bitrate=  81.1kbits/s speed= 246x    \n",
      "video:221kB audio:1596kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.686356%\n",
      "[aac @ 0x5640bf331280] Qavg: 111.078\n",
      "[libx264 @ 0x5640bf3329c0] frame I:4     Avg QP:12.93  size:  7712\n",
      "[libx264 @ 0x5640bf3329c0] frame P:321   Avg QP:22.73  size:   538\n",
      "[libx264 @ 0x5640bf3329c0] frame B:475   Avg QP:20.42  size:    46\n",
      "[libx264 @ 0x5640bf3329c0] consecutive B-frames: 16.5% 11.5%  4.5% 67.5%\n",
      "[libx264 @ 0x5640bf3329c0] mb I  I16..4: 64.3%  8.2% 27.5%\n",
      "[libx264 @ 0x5640bf3329c0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.7%  1.5%  1.5%  0.0%  0.0%    skip:95.3%\n",
      "[libx264 @ 0x5640bf3329c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.5%  0.2%  0.1%  direct: 0.2%  skip:99.0%  L0:20.7% L1:40.6% BI:38.7%\n",
      "[libx264 @ 0x5640bf3329c0] 8x8 transform intra:8.3% inter:16.1%\n",
      "[libx264 @ 0x5640bf3329c0] coded y,uvDC,uvAC intra: 22.3% 2.2% 2.1% inter: 1.1% 0.5% 0.4%\n",
      "[libx264 @ 0x5640bf3329c0] i16 v,h,dc,p: 88%  3%  8%  0%\n",
      "[libx264 @ 0x5640bf3329c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 16% 38%  0%  0%  1%  0%  0%  1%\n",
      "[libx264 @ 0x5640bf3329c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 31% 13%  2%  6%  4%  3%  3%  3%\n",
      "[libx264 @ 0x5640bf3329c0] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x5640bf3329c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5640bf3329c0] ref P L0: 86.1%  9.1%  2.7%  2.0%\n",
      "[libx264 @ 0x5640bf3329c0] ref B L0: 90.2%  8.6%  1.2%\n",
      "[libx264 @ 0x5640bf3329c0] ref B L1: 99.5%  0.5%\n",
      "[libx264 @ 0x5640bf3329c0] kb/s:90.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4618, 102)\n",
      "4618\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.1141281   0.10652966  1.1       ]\n",
      "  [ 0.04563127  0.08174538  1.10540524]\n",
      "  [ 0.14732255  0.03212557  1.10010427]\n",
      "  ...\n",
      "  [ 0.06134782  0.09651684  0.96821612]\n",
      "  [ 0.31142773  0.39869451  0.58343764]\n",
      "  [ 0.22211321  0.00909644  0.51137118]]\n",
      "\n",
      " [[ 0.12898226  0.0995697   1.1       ]\n",
      "  [ 0.05765211  0.0824332   1.10218621]\n",
      "  [ 0.1529517   0.020031    1.09768721]\n",
      "  ...\n",
      "  [ 0.07945836  0.10205438  0.96581072]\n",
      "  [ 0.43814217  0.35751215  0.56315185]\n",
      "  [ 0.21876066 -0.0130861   0.50862323]]\n",
      "\n",
      " [[ 0.12570022  0.10170834  1.1       ]\n",
      "  [ 0.05491018  0.08326911  1.103131  ]\n",
      "  [ 0.1513396   0.02321888  1.09877958]\n",
      "  ...\n",
      "  [ 0.07454732  0.10077074  0.96672434]\n",
      "  [ 0.40025401  0.37318804  0.56915765]\n",
      "  [ 0.22087523 -0.0052466   0.50962083]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.16276921  0.12214388  1.1       ]\n",
      "  [ 0.09925985  0.08583837  1.11760585]\n",
      "  [ 0.21124088  0.05367069  1.10895512]\n",
      "  ...\n",
      "  [ 0.11151492  0.0859464   0.97512394]\n",
      "  [-0.05878035  0.02725975  1.0450201 ]\n",
      "  [ 0.20943512  0.30211409  0.83576967]]\n",
      "\n",
      " [[ 0.16395419  0.12104628  1.1       ]\n",
      "  [ 0.10027272  0.08524351  1.11760473]\n",
      "  [ 0.21205909  0.05255993  1.10866936]\n",
      "  ...\n",
      "  [ 0.11222083  0.08584057  0.97516928]\n",
      "  [-0.05700791  0.02850891  1.04458415]\n",
      "  [ 0.21140911  0.30298313  0.8354559 ]]\n",
      "\n",
      " [[ 0.16497033  0.120288    1.1       ]\n",
      "  [ 0.10125353  0.08447276  1.11746173]\n",
      "  [ 0.212734    0.05132922  1.1081264 ]\n",
      "  ...\n",
      "  [ 0.11287339  0.0856632   0.97502649]\n",
      "  [-0.05502173  0.03001431  1.04399451]\n",
      "  [ 0.21353482  0.30386788  0.83499642]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_Flower_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 93 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 432x288, 90 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from './UoE_violin_midi/performance_audio/vio01/vio01_Flower_S1_T1.wav':\n",
      "  Duration: 00:01:59.27, bitrate: 705 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x564a52b21100] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x564a52b21100] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x564a52b21100] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './[ground_truth_40fps]video_Flower_S1_T1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 432x288, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=0.0 q=-1.0 Lsize=    1260kB time=00:01:59.28 bitrate=  86.5kbits/s speed= 211x    \n",
      "video:213kB audio:1010kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.008438%\n",
      "[aac @ 0x564a52b2b2c0] Qavg: 111.427\n",
      "[libx264 @ 0x564a52b21100] frame I:4     Avg QP:13.19  size:  7631\n",
      "[libx264 @ 0x564a52b21100] frame P:350   Avg QP:22.86  size:   486\n",
      "[libx264 @ 0x564a52b21100] frame B:446   Avg QP:19.06  size:    37\n",
      "[libx264 @ 0x564a52b21100] consecutive B-frames: 21.8% 10.5%  3.8% 64.0%\n",
      "[libx264 @ 0x564a52b21100] mb I  I16..4: 64.9%  7.7% 27.5%\n",
      "[libx264 @ 0x564a52b21100] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.7%  1.4%  1.4%  0.0%  0.0%    skip:95.5%\n",
      "[libx264 @ 0x564a52b21100] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.3%  0.1%  0.1%  direct: 0.2%  skip:99.3%  L0:15.2% L1:45.4% BI:39.3%\n",
      "[libx264 @ 0x564a52b21100] 8x8 transform intra:7.6% inter:16.8%\n",
      "[libx264 @ 0x564a52b21100] coded y,uvDC,uvAC intra: 22.3% 2.0% 1.8% inter: 1.2% 0.4% 0.4%\n",
      "[libx264 @ 0x564a52b21100] i16 v,h,dc,p: 89%  2%  9%  0%\n",
      "[libx264 @ 0x564a52b21100] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 16% 40%  0%  0%  0%  0%  0%  1%\n",
      "[libx264 @ 0x564a52b21100] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 36% 31% 13%  2%  6%  4%  3%  2%  3%\n",
      "[libx264 @ 0x564a52b21100] i8c dc,h,v,p: 99%  1%  1%  0%\n",
      "[libx264 @ 0x564a52b21100] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x564a52b21100] ref P L0: 85.6%  9.5%  3.0%  1.9%\n",
      "[libx264 @ 0x564a52b21100] ref B L0: 94.4%  2.6%  3.0%\n",
      "[libx264 @ 0x564a52b21100] ref B L1: 99.0%  1.0%\n",
      "[libx264 @ 0x564a52b21100] kb/s:86.91\n"
     ]
    }
   ],
   "source": [
    "for filecode in test_pieces:\n",
    "    ground_truth = pd.DataFrame(motion_dictionary[this_performer][filecode][:, :102])\n",
    "    print(ground_truth.shape)\n",
    "    \n",
    "    Row_list_prediction =[]\n",
    "    \n",
    "    # Iterate over each row\n",
    "    for index, rows in ground_truth.iterrows():\n",
    "        #fill nan\n",
    "        rows = rows.fillna(0)\n",
    "        # Create list for the current row\n",
    "        my_list = rows.values.tolist()\n",
    "        # print(my_list)\n",
    "        \n",
    "        my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "        # append the list to the final list\n",
    "        Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "    print(len(Row_list_prediction))\n",
    "    \n",
    "    if \"Elgar\" in filecode:#4120\n",
    "        plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[ground_truth_40fps]video_\" + filecode + \".mp4\", Row_list_prediction[4120:4920], None, 40, filecode)\n",
    "        # plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")video_\" + filecode + \"_predict_hs\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch\"+\".mp4\", Row_list_prediction[4120:4920], None, 40, filecode) #ow_list[0:900]\n",
    "\n",
    "    if \"Flower\" in filecode:#2560\n",
    "        plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[ground_truth_40fps]video_\" + filecode + \".mp4\", Row_list_prediction[2560:3360], None, 40, filecode)\n",
    "        # plot_wav(UoE_violin_audio_path + \"vio01_\" + filecode + \".wav\", \"./[\" + data_format + \"_\" + NoY + \"_anno](\" + loss_type + \")video_\" + filecode + \"_predict_hs\"+str(hidden_size)+'_'+str(num_epochs)+\"epoch\"+\".mp4\", Row_list_prediction[2560:3360], None, 40, filecode) #ow_list[0:900]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sinica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af62e6ceaa22ecc9f260af1a27a267a6f5d740390ae55af98f787b231774a8a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
